[2022-06-20 23:02:25,848] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-20 23:02:25,863] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-20 23:02:25,863] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 23:02:25,863] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 23:02:25,863] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 23:02:25,880] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-20 23:02:25,885] {standard_task_runner.py:52} INFO - Started process 8807 to run task
[2022-06-20 23:02:25,889] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '517', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmps2h0kfmr', '--error-file', '/tmp/tmpy5b5w1zt']
[2022-06-20 23:02:25,890] {standard_task_runner.py:80} INFO - Job 517: Subtask create_tables_stages.criar_Stage_Time
[2022-06-20 23:02:25,954] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 23:02:26,039] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-20 23:02:26,052] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 23:02:26,058] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-20 23:02:26,061] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-20 23:02:26,134] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T020225, end_date=20220621T020226
[2022-06-20 23:02:26,181] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 23:02:26,241] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-21 01:35:32,232] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:35:32,257] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:35:32,257] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:35:32,257] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 01:35:32,258] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:35:32,284] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 01:35:32,302] {standard_task_runner.py:52} INFO - Started process 24512 to run task
[2022-06-21 01:35:32,312] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '535', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp5bt49znk', '--error-file', '/tmp/tmprwfjhoe6']
[2022-06-21 01:35:32,313] {standard_task_runner.py:80} INFO - Job 535: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 01:35:32,434] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 01:35:32,608] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 01:35:32,635] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 01:35:32,650] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 01:35:32,656] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 01:35:32,696] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T043532, end_date=20220621T043532
[2022-06-21 01:35:32,767] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 01:35:32,896] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 01:39:06,399] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:39:06,472] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:39:06,472] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:39:06,473] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 01:39:06,473] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:39:06,509] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 01:39:06,525] {standard_task_runner.py:52} INFO - Started process 26425 to run task
[2022-06-21 01:39:06,545] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '550', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpi3wq6th6', '--error-file', '/tmp/tmpx9dalb8y']
[2022-06-21 01:39:06,546] {standard_task_runner.py:80} INFO - Job 550: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 01:39:06,676] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 01:39:06,820] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 01:39:06,843] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 01:39:06,851] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 01:39:06,852] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 01:39:06,968] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T043906, end_date=20220621T043906
[2022-06-21 01:39:07,034] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 01:39:07,175] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 01:43:16,732] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:43:16,759] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:43:16,760] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:43:16,760] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 01:43:16,760] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:43:16,789] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 01:43:16,803] {standard_task_runner.py:52} INFO - Started process 28375 to run task
[2022-06-21 01:43:16,811] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '570', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpnrd9laoj', '--error-file', '/tmp/tmprdv3h8ah']
[2022-06-21 01:43:16,812] {standard_task_runner.py:80} INFO - Job 570: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 01:43:16,937] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 01:43:17,114] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 01:43:17,149] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 01:43:17,159] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 01:43:17,161] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 01:43:17,235] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T044316, end_date=20220621T044317
[2022-06-21 01:43:17,303] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 01:43:17,421] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 01:50:20,988] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:50:21,021] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:50:21,022] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:50:21,022] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 01:50:21,023] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:50:21,060] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 01:50:21,074] {standard_task_runner.py:52} INFO - Started process 30856 to run task
[2022-06-21 01:50:21,081] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '591', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp1nmwdmdy', '--error-file', '/tmp/tmpyn2w39u3']
[2022-06-21 01:50:21,082] {standard_task_runner.py:80} INFO - Job 591: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 01:50:21,197] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 01:50:21,368] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 01:50:21,389] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 01:50:21,399] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 01:50:21,400] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 01:50:21,436] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T045020, end_date=20220621T045021
[2022-06-21 01:50:21,495] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 01:50:21,581] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 01:53:29,331] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:53:29,362] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:53:29,363] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:53:29,363] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 01:53:29,363] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:53:29,391] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 01:53:29,403] {standard_task_runner.py:52} INFO - Started process 33982 to run task
[2022-06-21 01:53:29,409] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '607', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp3k39nk60', '--error-file', '/tmp/tmp2umz27wx']
[2022-06-21 01:53:29,410] {standard_task_runner.py:80} INFO - Job 607: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 01:53:29,509] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 01:53:29,887] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 01:53:29,919] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 01:53:29,930] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 01:53:29,932] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 01:53:30,113] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T045329, end_date=20220621T045330
[2022-06-21 01:53:30,226] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 01:53:30,441] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 01:55:20,154] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:55:20,180] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:55:20,180] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:55:20,180] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 01:55:20,181] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:55:20,203] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 01:55:20,217] {standard_task_runner.py:52} INFO - Started process 35442 to run task
[2022-06-21 01:55:20,223] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '617', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp1xvm9sy4', '--error-file', '/tmp/tmpdfcrpv4l']
[2022-06-21 01:55:20,224] {standard_task_runner.py:80} INFO - Job 617: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 01:55:20,333] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 01:55:20,474] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 01:55:20,501] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 01:55:20,507] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 01:55:20,508] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 01:55:20,577] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T045520, end_date=20220621T045520
[2022-06-21 01:55:20,638] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 01:55:20,807] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:00:57,014] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:00:57,060] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:00:57,061] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:00:57,061] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:00:57,061] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:00:57,101] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:00:57,119] {standard_task_runner.py:52} INFO - Started process 37664 to run task
[2022-06-21 02:00:57,129] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '627', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpap234odn', '--error-file', '/tmp/tmpu_g50gcf']
[2022-06-21 02:00:57,130] {standard_task_runner.py:80} INFO - Job 627: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:00:57,274] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:00:57,463] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:00:57,489] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 02:00:57,497] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 02:00:57,501] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 02:00:57,625] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T050057, end_date=20220621T050057
[2022-06-21 02:00:57,709] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:00:57,815] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:04:15,068] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:04:15,101] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:04:15,101] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:04:15,101] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:04:15,101] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:04:15,127] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:04:15,141] {standard_task_runner.py:52} INFO - Started process 39773 to run task
[2022-06-21 02:04:15,150] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '633', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpnwszgaj6', '--error-file', '/tmp/tmp4vu52ymx']
[2022-06-21 02:04:15,151] {standard_task_runner.py:80} INFO - Job 633: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:04:15,267] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:04:15,439] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:04:15,466] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 02:04:15,473] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 02:04:15,557] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T050415, end_date=20220621T050415
[2022-06-21 02:04:15,604] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:04:15,719] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:12:05,767] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:12:05,822] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:12:05,823] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:12:05,823] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:12:05,823] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:12:05,858] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:12:05,873] {standard_task_runner.py:52} INFO - Started process 45115 to run task
[2022-06-21 02:12:05,884] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp5mly98ii', '--error-file', '/tmp/tmpeu6h3obt']
[2022-06-21 02:12:05,885] {standard_task_runner.py:80} INFO - Job 8: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:12:06,000] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:12:06,156] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:12:06,292] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 86, in get_conn
    conn = deepcopy(self.connection or self.get_connection(conn_id))
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/models/connection.py", line 430, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `***` isn't defined
[2022-06-21 02:12:06,300] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T051205, end_date=20220621T051206
[2022-06-21 02:12:06,322] {standard_task_runner.py:92} ERROR - Failed to execute job 8 for task create_tables_stages.criar_Stage_Time (The conn_id `***` isn't defined; 45115)
[2022-06-21 02:12:06,376] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-21 02:12:06,462] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:14:03,440] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:14:03,469] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:14:03,470] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:14:03,470] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:14:03,470] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:14:03,496] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:14:03,511] {standard_task_runner.py:52} INFO - Started process 46367 to run task
[2022-06-21 02:14:03,517] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp23mcnmvc', '--error-file', '/tmp/tmp578w8rdk']
[2022-06-21 02:14:03,518] {standard_task_runner.py:80} INFO - Job 15: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:14:03,640] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:14:03,837] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:14:03,858] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 02:14:03,866] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 02:14:03,867] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 02:14:03,951] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T051403, end_date=20220621T051403
[2022-06-21 02:14:04,012] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:14:04,126] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:16:48,444] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:16:48,474] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:16:48,474] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:16:48,474] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:16:48,474] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:16:48,502] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:16:48,520] {standard_task_runner.py:52} INFO - Started process 48118 to run task
[2022-06-21 02:16:48,536] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '32', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpt62y6dl_', '--error-file', '/tmp/tmpn3qxi_p0']
[2022-06-21 02:16:48,537] {standard_task_runner.py:80} INFO - Job 32: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:16:48,675] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:16:48,854] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:16:48,880] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 02:16:48,891] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 02:16:48,892] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 02:16:48,977] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T051648, end_date=20220621T051648
[2022-06-21 02:16:49,070] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:16:49,188] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:18:39,909] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:18:39,938] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:18:39,939] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:18:39,939] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:18:39,939] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:18:39,966] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:18:39,979] {standard_task_runner.py:52} INFO - Started process 49791 to run task
[2022-06-21 02:18:39,986] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '50', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpxz2yhxg1', '--error-file', '/tmp/tmppa2nmscv']
[2022-06-21 02:18:39,987] {standard_task_runner.py:80} INFO - Job 50: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:18:40,103] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:18:40,284] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:18:40,309] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 02:18:40,316] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 02:18:40,318] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 02:18:40,410] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T051839, end_date=20220621T051840
[2022-06-21 02:18:40,481] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:18:40,613] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:24:17,932] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:24:17,968] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:24:17,968] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:24:17,968] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:24:17,969] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:24:18,004] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:24:18,028] {standard_task_runner.py:52} INFO - Started process 52085 to run task
[2022-06-21 02:24:18,037] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '65', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpl0xyh1jw', '--error-file', '/tmp/tmp68mz1u4a']
[2022-06-21 02:24:18,037] {standard_task_runner.py:80} INFO - Job 65: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:24:18,170] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:24:18,318] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:24:18,339] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 02:24:18,348] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 02:24:18,350] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 02:24:18,459] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T052417, end_date=20220621T052418
[2022-06-21 02:24:18,534] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:24:18,655] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:42:12,699] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:42:12,732] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:42:12,733] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:42:12,733] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:42:12,733] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:42:12,759] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:42:12,772] {standard_task_runner.py:52} INFO - Started process 55648 to run task
[2022-06-21 02:42:12,780] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '84', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp__7_ghxj', '--error-file', '/tmp/tmp_zk6cmat']
[2022-06-21 02:42:12,781] {standard_task_runner.py:80} INFO - Job 84: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:42:12,897] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:42:13,080] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:42:13,106] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 02:42:13,116] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 02:42:13,118] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 02:42:13,190] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T054212, end_date=20220621T054213
[2022-06-21 02:42:13,277] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:42:13,428] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:44:12,510] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:44:12,546] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:44:12,546] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:44:12,546] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:44:12,546] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:44:12,572] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:44:12,588] {standard_task_runner.py:52} INFO - Started process 57892 to run task
[2022-06-21 02:44:12,601] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '105', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpl0hauwwd', '--error-file', '/tmp/tmpq7_a2pyx']
[2022-06-21 02:44:12,602] {standard_task_runner.py:80} INFO - Job 105: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:44:12,837] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:44:13,112] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:44:13,136] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 02:44:13,151] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 02:44:13,230] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T054412, end_date=20220621T054413
[2022-06-21 02:44:13,346] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:44:13,507] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:51:09,312] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:51:09,339] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:51:09,339] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:51:09,340] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:51:09,340] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:51:09,366] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:51:09,380] {standard_task_runner.py:52} INFO - Started process 60320 to run task
[2022-06-21 02:51:09,386] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '119', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpcgsptnny', '--error-file', '/tmp/tmp0cluqdf5']
[2022-06-21 02:51:09,387] {standard_task_runner.py:80} INFO - Job 119: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:51:09,522] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:51:09,769] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:51:09,826] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 02:51:09,853] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 02:51:09,862] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-21 02:51:09,931] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T055109, end_date=20220621T055109
[2022-06-21 02:51:10,010] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:51:10,118] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:52:45,950] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:52:45,975] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:52:45,975] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:52:45,975] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:52:45,975] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:52:45,995] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:52:46,007] {standard_task_runner.py:52} INFO - Started process 62141 to run task
[2022-06-21 02:52:46,013] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '138', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpjmfkeypu', '--error-file', '/tmp/tmpemgxtuk7']
[2022-06-21 02:52:46,014] {standard_task_runner.py:80} INFO - Job 138: Subtask create_tables_stages.criar_Stage_Time
[2022-06-21 02:52:46,103] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:52:46,260] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:52:46,282] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-21 02:52:46,290] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                ordernumber INT NOT NULL,               
                orderdate date NOT NULL,
                requireddate date NOT NULL,
                shippedDate date
                    )
            , parameters: None
[2022-06-21 02:52:46,325] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220620T000000, start_date=20220621T055245, end_date=20220621T055246
[2022-06-21 02:52:46,385] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:52:46,504] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
