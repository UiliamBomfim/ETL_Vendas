[2022-06-20 23:02:34,263] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-20 23:02:34,277] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-20 23:02:34,277] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 23:02:34,277] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 23:02:34,277] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 23:02:34,294] {taskinstance.py:1378} INFO - Executing <Task(PythonOperator): load_fato> on 2022-06-20 00:00:00+00:00
[2022-06-20 23:02:34,300] {standard_task_runner.py:52} INFO - Started process 9281 to run task
[2022-06-20 23:02:34,305] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'load_fato', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '529', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpmn0t2xhv', '--error-file', '/tmp/tmpvke20coz']
[2022-06-20 23:02:34,306] {standard_task_runner.py:80} INFO - Job 529: Subtask load_fato
[2022-06-20 23:02:34,370] {task_command.py:370} INFO - Running <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 23:02:34,449] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=load_fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-20 23:02:38,862] {python.py:173} INFO - Done. Returned value was: None
[2022-06-20 23:02:38,878] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=load_fato, execution_date=20220620T000000, start_date=20220621T020234, end_date=20220621T020238
[2022-06-20 23:02:38,927] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 23:02:38,973] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 01:39:17,832] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:39:17,854] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:39:17,855] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:39:17,855] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 01:39:17,855] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:39:17,876] {taskinstance.py:1378} INFO - Executing <Task(PythonOperator): load_fato> on 2022-06-20 00:00:00+00:00
[2022-06-21 01:39:17,886] {standard_task_runner.py:52} INFO - Started process 27079 to run task
[2022-06-21 01:39:17,892] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'load_fato', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '565', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpw7lm74wx', '--error-file', '/tmp/tmpxzu8zth1']
[2022-06-21 01:39:17,893] {standard_task_runner.py:80} INFO - Job 565: Subtask load_fato
[2022-06-21 01:39:17,976] {task_command.py:370} INFO - Running <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 01:39:18,085] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=load_fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 01:39:18,104] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1705, in _execute_context
    self.dialect.do_execute(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 716, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column o.quantityordered does not exist
LINE 1: ...dernumber = o.ordernumber and f.quantityordered = o.quantity...
                                                             ^
HINT:  Perhaps you meant to reference the column "f.quantityordered".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/uiliam/airflow/dags/functions.py", line 138, in load_Fato
    df_ft = pd.read_sql_query('select distinct c.id_customers, p.id_products, t.id_time, e.id_emp, \
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/pandas/io/sql.py", line 399, in read_sql_query
    return pandas_sql.read_query(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/pandas/io/sql.py", line 1557, in read_query
    result = self.execute(*args)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/pandas/io/sql.py", line 1402, in execute
    return self.connectable.execution_options().execute(*args, **kwargs)
  File "<string>", line 2, in execute
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py", line 390, in warned
    return fn(*args, **kwargs)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3037, in execute
    return connection.execute(statement, *multiparams, **params)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1185, in execute
    return self._exec_driver_sql(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1484, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1748, in _execute_context
    self._handle_dbapi_exception(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1929, in _handle_dbapi_exception
    util.raise_(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1705, in _execute_context
    self.dialect.do_execute(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 716, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column o.quantityordered does not exist
LINE 1: ...dernumber = o.ordernumber and f.quantityordered = o.quantity...
                                                             ^
HINT:  Perhaps you meant to reference the column "f.quantityordered".

[SQL: select distinct c.id_customers, p.id_products, t.id_time, e.id_emp,             f.quantityordered, f.priceeach, f.buyprice             from stg_fato f             left join dm_products p             on   f.productcode = p.productcode             left join dm_orderd o             on f.ordernumber = o.ordernumber and f.quantityordered = o.quantityordered and f.orderLineNumber = o.orderLineNumber            left join dm_time t            on f.ordernumber = t.ordernumber            left join dm_customers c             on f.customernumber = c.customernumber             left join dm_emp e            on f.employeenumber = e.employeenumber            order by id_time]
(Background on this error at: http://sqlalche.me/e/14/f405)
[2022-06-21 01:39:18,126] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=load_fato, execution_date=20220620T000000, start_date=20220621T043917, end_date=20220621T043918
[2022-06-21 01:39:18,147] {standard_task_runner.py:92} ERROR - Failed to execute job 565 for task load_fato ((psycopg2.errors.UndefinedColumn) column o.quantityordered does not exist
LINE 1: ...dernumber = o.ordernumber and f.quantityordered = o.quantity...
                                                             ^
HINT:  Perhaps you meant to reference the column "f.quantityordered".

[SQL: select distinct c.id_customers, p.id_products, t.id_time, e.id_emp,             f.quantityordered, f.priceeach, f.buyprice             from stg_fato f             left join dm_products p             on   f.productcode = p.productcode             left join dm_orderd o             on f.ordernumber = o.ordernumber and f.quantityordered = o.quantityordered and f.orderLineNumber = o.orderLineNumber            left join dm_time t            on f.ordernumber = t.ordernumber            left join dm_customers c             on f.customernumber = c.customernumber             left join dm_emp e            on f.employeenumber = e.employeenumber            order by id_time]
(Background on this error at: http://sqlalche.me/e/14/f405); 27079)
[2022-06-21 01:39:18,183] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-21 01:39:18,233] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 01:43:26,706] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:43:26,729] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 01:43:26,730] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:43:26,730] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 01:43:26,730] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 01:43:26,751] {taskinstance.py:1378} INFO - Executing <Task(PythonOperator): load_fato> on 2022-06-20 00:00:00+00:00
[2022-06-21 01:43:26,759] {standard_task_runner.py:52} INFO - Started process 28941 to run task
[2022-06-21 01:43:26,765] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'load_fato', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '583', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpq19nqmfh', '--error-file', '/tmp/tmpybojkzhq']
[2022-06-21 01:43:26,765] {standard_task_runner.py:80} INFO - Job 583: Subtask load_fato
[2022-06-21 01:43:26,854] {task_command.py:370} INFO - Running <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 01:43:26,964] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=load_fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 01:43:27,257] {python.py:173} INFO - Done. Returned value was: None
[2022-06-21 01:43:27,282] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=load_fato, execution_date=20220620T000000, start_date=20220621T044326, end_date=20220621T044327
[2022-06-21 01:43:27,337] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 01:43:27,397] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:16:59,536] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:16:59,560] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:16:59,560] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:16:59,560] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:16:59,560] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:16:59,582] {taskinstance.py:1378} INFO - Executing <Task(PythonOperator): load_fato> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:16:59,594] {standard_task_runner.py:52} INFO - Started process 48719 to run task
[2022-06-21 02:16:59,599] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'load_fato', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp7evh7tsb', '--error-file', '/tmp/tmpjx2i1ntj']
[2022-06-21 02:16:59,600] {standard_task_runner.py:80} INFO - Job 44: Subtask load_fato
[2022-06-21 02:16:59,687] {task_command.py:370} INFO - Running <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:16:59,800] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=load_fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:16:59,815] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1705, in _execute_context
    self.dialect.do_execute(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 716, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.SyntaxError: syntax error at or near "."
LINE 1: ...ducts, t.id_time, e.id_emp, o.id_ordd            f.quantityo...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/uiliam/airflow/dags/functions.py", line 138, in load_Fato
    df_ft = pd.read_sql_query('select distinct c.id_customers, p.id_products, t.id_time, e.id_emp, o.id_ordd\
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/pandas/io/sql.py", line 399, in read_sql_query
    return pandas_sql.read_query(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/pandas/io/sql.py", line 1557, in read_query
    result = self.execute(*args)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/pandas/io/sql.py", line 1402, in execute
    return self.connectable.execution_options().execute(*args, **kwargs)
  File "<string>", line 2, in execute
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py", line 390, in warned
    return fn(*args, **kwargs)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 3037, in execute
    return connection.execute(statement, *multiparams, **params)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1185, in execute
    return self._exec_driver_sql(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1484, in _exec_driver_sql
    ret = self._execute_context(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1748, in _execute_context
    self._handle_dbapi_exception(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1929, in _handle_dbapi_exception
    util.raise_(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1705, in _execute_context
    self.dialect.do_execute(
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 716, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.SyntaxError) syntax error at or near "."
LINE 1: ...ducts, t.id_time, e.id_emp, o.id_ordd            f.quantityo...
                                                             ^

[SQL: select distinct c.id_customers, p.id_products, t.id_time, e.id_emp, o.id_ordd            f.quantityordered, f.priceeach, f.buyprice             from stg_fato f             left join dm_products p             on   f.productcode = p.productcode             left join dm_orderd o             on f.ordernumber = o.ordernumber             left join dm_time t            on f.ordernumber = t.ordernumber            left join dm_customers c             on f.customernumber = c.customernumber             left join dm_emp e            on f.employeenumber = e.employeenumber            order by id_time]
(Background on this error at: http://sqlalche.me/e/14/f405)
[2022-06-21 02:16:59,833] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=load_fato, execution_date=20220620T000000, start_date=20220621T051659, end_date=20220621T051659
[2022-06-21 02:16:59,853] {standard_task_runner.py:92} ERROR - Failed to execute job 44 for task load_fato ((psycopg2.errors.SyntaxError) syntax error at or near "."
LINE 1: ...ducts, t.id_time, e.id_emp, o.id_ordd            f.quantityo...
                                                             ^

[SQL: select distinct c.id_customers, p.id_products, t.id_time, e.id_emp, o.id_ordd            f.quantityordered, f.priceeach, f.buyprice             from stg_fato f             left join dm_products p             on   f.productcode = p.productcode             left join dm_orderd o             on f.ordernumber = o.ordernumber             left join dm_time t            on f.ordernumber = t.ordernumber            left join dm_customers c             on f.customernumber = c.customernumber             left join dm_emp e            on f.employeenumber = e.employeenumber            order by id_time]
(Background on this error at: http://sqlalche.me/e/14/f405); 48719)
[2022-06-21 02:16:59,891] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-21 02:16:59,946] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:18:52,250] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:18:52,271] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:18:52,272] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:18:52,272] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:18:52,272] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:18:52,294] {taskinstance.py:1378} INFO - Executing <Task(PythonOperator): load_fato> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:18:52,305] {standard_task_runner.py:52} INFO - Started process 50402 to run task
[2022-06-21 02:18:52,311] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'load_fato', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '62', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp2dmxt8u2', '--error-file', '/tmp/tmpvk4cmxwl']
[2022-06-21 02:18:52,312] {standard_task_runner.py:80} INFO - Job 62: Subtask load_fato
[2022-06-21 02:18:52,408] {task_command.py:370} INFO - Running <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:18:52,522] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=load_fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:18:55,284] {python.py:173} INFO - Done. Returned value was: None
[2022-06-21 02:18:55,305] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=load_fato, execution_date=20220620T000000, start_date=20220621T051852, end_date=20220621T051855
[2022-06-21 02:18:55,374] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:18:55,426] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:24:30,100] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:24:30,122] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:24:30,123] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:24:30,123] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:24:30,123] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:24:30,143] {taskinstance.py:1378} INFO - Executing <Task(PythonOperator): load_fato> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:24:30,153] {standard_task_runner.py:52} INFO - Started process 52706 to run task
[2022-06-21 02:24:30,158] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'load_fato', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '80', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpu596qbw_', '--error-file', '/tmp/tmpyxb7cm39']
[2022-06-21 02:24:30,159] {standard_task_runner.py:80} INFO - Job 80: Subtask load_fato
[2022-06-21 02:24:30,243] {task_command.py:370} INFO - Running <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:24:30,350] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=load_fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:24:30,752] {python.py:173} INFO - Done. Returned value was: None
[2022-06-21 02:24:30,774] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=load_fato, execution_date=20220620T000000, start_date=20220621T052430, end_date=20220621T052430
[2022-06-21 02:24:30,811] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:24:30,864] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:42:23,619] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:42:23,642] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:42:23,642] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:42:23,642] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:42:23,642] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:42:23,664] {taskinstance.py:1378} INFO - Executing <Task(PythonOperator): load_fato> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:42:23,675] {standard_task_runner.py:52} INFO - Started process 56275 to run task
[2022-06-21 02:42:23,681] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'load_fato', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '98', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpwpa9_1th', '--error-file', '/tmp/tmpca8ce7co']
[2022-06-21 02:42:23,682] {standard_task_runner.py:80} INFO - Job 98: Subtask load_fato
[2022-06-21 02:42:23,771] {task_command.py:370} INFO - Running <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:42:23,882] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=load_fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:42:37,288] {python.py:173} INFO - Done. Returned value was: None
[2022-06-21 02:42:37,310] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=load_fato, execution_date=20220620T000000, start_date=20220621T054223, end_date=20220621T054237
[2022-06-21 02:42:37,384] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:42:37,424] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:51:22,044] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:51:22,066] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:51:22,067] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:51:22,067] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:51:22,067] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:51:22,087] {taskinstance.py:1378} INFO - Executing <Task(PythonOperator): load_fato> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:51:22,100] {standard_task_runner.py:52} INFO - Started process 60983 to run task
[2022-06-21 02:51:22,105] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'load_fato', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '133', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpeq_2_od8', '--error-file', '/tmp/tmp8jzvftuw']
[2022-06-21 02:51:22,106] {standard_task_runner.py:80} INFO - Job 133: Subtask load_fato
[2022-06-21 02:51:22,207] {task_command.py:370} INFO - Running <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:51:22,329] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=load_fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:51:32,607] {python.py:173} INFO - Done. Returned value was: None
[2022-06-21 02:51:32,634] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=load_fato, execution_date=20220620T000000, start_date=20220621T055122, end_date=20220621T055132
[2022-06-21 02:51:32,682] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:51:32,733] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-21 02:52:55,155] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:52:55,179] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [queued]>
[2022-06-21 02:52:55,179] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:52:55,179] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-21 02:52:55,179] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-21 02:52:55,200] {taskinstance.py:1378} INFO - Executing <Task(PythonOperator): load_fato> on 2022-06-20 00:00:00+00:00
[2022-06-21 02:52:55,208] {standard_task_runner.py:52} INFO - Started process 62643 to run task
[2022-06-21 02:52:55,213] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'load_fato', 'scheduled__2022-06-20T00:00:00+00:00', '--job-id', '151', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpwwqqdgy2', '--error-file', '/tmp/tmpohvpe__w']
[2022-06-21 02:52:55,213] {standard_task_runner.py:80} INFO - Job 151: Subtask load_fato
[2022-06-21 02:52:55,293] {task_command.py:370} INFO - Running <TaskInstance: sales.load_fato scheduled__2022-06-20T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-21 02:52:55,392] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=load_fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-20T00:00:00+00:00
[2022-06-21 02:52:55,771] {python.py:173} INFO - Done. Returned value was: None
[2022-06-21 02:52:55,791] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=load_fato, execution_date=20220620T000000, start_date=20220621T055255, end_date=20220621T055255
[2022-06-21 02:52:55,826] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-21 02:52:55,875] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
