[2022-06-19 23:39:46,867] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:39:46,894] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:39:46,894] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:39:46,894] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-19 23:39:46,894] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:39:46,916] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-19 23:39:46,928] {standard_task_runner.py:52} INFO - Started process 28172 to run task
[2022-06-19 23:39:46,934] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '194', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp6f4mqrfr', '--error-file', '/tmp/tmpqc_9n7z8']
[2022-06-19 23:39:46,935] {standard_task_runner.py:80} INFO - Job 194: Subtask create_tables_stages.criar_Stage_Products
[2022-06-19 23:39:47,033] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-19 23:39:47,209] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-19 23:39:47,232] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-19 23:39:47,248] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-19 23:39:47,249] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-19 23:39:47,292] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T023946, end_date=20220620T023947
[2022-06-19 23:39:47,347] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-19 23:39:47,459] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-19 23:42:09,713] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:42:09,741] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:42:09,741] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:42:09,742] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-19 23:42:09,742] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:42:09,771] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-19 23:42:09,784] {standard_task_runner.py:52} INFO - Started process 30260 to run task
[2022-06-19 23:42:09,791] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '213', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp1rlahepo', '--error-file', '/tmp/tmpyi6xqmr2']
[2022-06-19 23:42:09,791] {standard_task_runner.py:80} INFO - Job 213: Subtask create_tables_stages.criar_Stage_Products
[2022-06-19 23:42:09,923] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-19 23:42:10,113] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-19 23:42:10,138] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-19 23:42:10,164] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-19 23:42:10,169] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-19 23:42:10,218] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T024209, end_date=20220620T024210
[2022-06-19 23:42:10,334] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-19 23:42:10,532] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-19 23:48:41,508] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:48:41,535] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:48:41,535] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:48:41,535] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-19 23:48:41,536] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:48:41,562] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-19 23:48:41,574] {standard_task_runner.py:52} INFO - Started process 32828 to run task
[2022-06-19 23:48:41,580] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '226', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpa1a41mgv', '--error-file', '/tmp/tmp29v772gg']
[2022-06-19 23:48:41,581] {standard_task_runner.py:80} INFO - Job 226: Subtask create_tables_stages.criar_Stage_Products
[2022-06-19 23:48:41,679] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-19 23:48:41,852] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-19 23:48:41,878] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-19 23:48:41,887] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-19 23:48:41,889] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-19 23:48:41,939] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T024841, end_date=20220620T024841
[2022-06-19 23:48:41,996] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-19 23:48:42,135] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:03:58,426] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:03:58,455] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:03:58,456] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:03:58,456] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:03:58,456] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:03:58,490] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:03:58,505] {standard_task_runner.py:52} INFO - Started process 35983 to run task
[2022-06-20 00:03:58,513] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '244', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpzj838tpe', '--error-file', '/tmp/tmpkanpcuj3']
[2022-06-20 00:03:58,514] {standard_task_runner.py:80} INFO - Job 244: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:03:58,675] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:03:58,861] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:03:58,900] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:03:58,906] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:03:58,909] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:03:58,954] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T030358, end_date=20220620T030358
[2022-06-20 00:03:59,013] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:03:59,107] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:05:08,197] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:05:08,227] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:05:08,227] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:05:08,227] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:05:08,228] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:05:08,253] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:05:08,271] {standard_task_runner.py:52} INFO - Started process 37285 to run task
[2022-06-20 00:05:08,280] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '256', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp3dbdaj4u', '--error-file', '/tmp/tmpbh4ugefc']
[2022-06-20 00:05:08,281] {standard_task_runner.py:80} INFO - Job 256: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:05:08,383] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:05:08,570] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:05:08,599] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:05:08,609] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:05:08,611] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:05:08,647] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T030508, end_date=20220620T030508
[2022-06-20 00:05:08,738] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:05:08,843] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:06:58,886] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:06:58,910] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:06:58,910] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:06:58,910] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:06:58,910] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:06:58,933] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:06:58,946] {standard_task_runner.py:52} INFO - Started process 38864 to run task
[2022-06-20 00:06:58,952] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '266', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp8cs6oaos', '--error-file', '/tmp/tmpal5lhphd']
[2022-06-20 00:06:58,952] {standard_task_runner.py:80} INFO - Job 266: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:06:59,054] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:06:59,208] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:06:59,227] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:06:59,233] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:06:59,235] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:06:59,262] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T030658, end_date=20220620T030659
[2022-06-20 00:06:59,326] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:06:59,419] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:25:32,972] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:25:32,995] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:25:32,995] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:25:32,995] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:25:32,995] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:25:33,020] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:25:33,034] {standard_task_runner.py:52} INFO - Started process 42819 to run task
[2022-06-20 00:25:33,040] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '284', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpccythxg9', '--error-file', '/tmp/tmpzd7yu7zu']
[2022-06-20 00:25:33,040] {standard_task_runner.py:80} INFO - Job 284: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:25:33,146] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:25:33,288] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:25:33,306] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:25:33,312] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:25:33,314] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:25:33,337] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T032532, end_date=20220620T032533
[2022-06-20 00:25:33,414] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:25:33,496] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:26:28,812] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:26:28,853] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:26:28,853] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:26:28,854] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:26:28,854] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:26:28,887] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:26:28,905] {standard_task_runner.py:52} INFO - Started process 44130 to run task
[2022-06-20 00:26:28,920] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '300', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpow39a76a', '--error-file', '/tmp/tmpe8obgfj4']
[2022-06-20 00:26:28,921] {standard_task_runner.py:80} INFO - Job 300: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:26:29,047] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:26:29,250] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:26:29,279] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:26:29,293] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:26:29,295] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:26:29,391] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T032628, end_date=20220620T032629
[2022-06-20 00:26:29,491] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:26:29,614] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:29:31,685] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:29:31,707] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:29:31,707] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:29:31,708] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:29:31,708] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:29:31,731] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:29:31,742] {standard_task_runner.py:52} INFO - Started process 45845 to run task
[2022-06-20 00:29:31,746] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '314', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpbxpkvgmn', '--error-file', '/tmp/tmpvmtk3r4u']
[2022-06-20 00:29:31,747] {standard_task_runner.py:80} INFO - Job 314: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:29:31,839] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:29:31,986] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:29:32,005] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:29:32,013] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:29:32,014] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:29:32,039] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T032931, end_date=20220620T032932
[2022-06-20 00:29:32,079] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:29:32,204] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:30:44,934] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:30:44,954] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:30:44,955] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:30:44,955] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:30:44,955] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:30:44,976] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:30:44,988] {standard_task_runner.py:52} INFO - Started process 47253 to run task
[2022-06-20 00:30:44,993] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '330', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpgrvbvpub', '--error-file', '/tmp/tmpj2kor_bo']
[2022-06-20 00:30:44,994] {standard_task_runner.py:80} INFO - Job 330: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:30:45,093] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:30:45,249] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:30:45,266] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:30:45,273] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:30:45,275] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:30:45,301] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T033044, end_date=20220620T033045
[2022-06-20 00:30:45,374] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:30:45,486] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:32:33,060] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:32:33,087] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:32:33,087] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:32:33,087] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:32:33,087] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:32:33,110] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:32:33,124] {standard_task_runner.py:52} INFO - Started process 48943 to run task
[2022-06-20 00:32:33,131] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '346', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp0e23eddb', '--error-file', '/tmp/tmp_ikxhgtj']
[2022-06-20 00:32:33,132] {standard_task_runner.py:80} INFO - Job 346: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:32:33,277] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:32:33,483] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:32:33,506] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:32:33,515] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:32:33,517] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:32:33,559] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T033233, end_date=20220620T033233
[2022-06-20 00:32:33,632] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:32:33,770] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:34:14,453] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:34:14,484] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:34:14,484] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:34:14,484] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:34:14,484] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:34:14,512] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:34:14,527] {standard_task_runner.py:52} INFO - Started process 50547 to run task
[2022-06-20 00:34:14,537] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '361', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp2akt5dra', '--error-file', '/tmp/tmpnull29bw']
[2022-06-20 00:34:14,538] {standard_task_runner.py:80} INFO - Job 361: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:34:14,697] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:34:14,863] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:34:14,890] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:34:14,900] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:34:14,902] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:34:14,938] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T033414, end_date=20220620T033414
[2022-06-20 00:34:14,995] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:34:15,098] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:46:08,207] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:46:08,240] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:46:08,241] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:46:08,241] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:46:08,241] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:46:08,281] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:46:08,299] {standard_task_runner.py:52} INFO - Started process 53715 to run task
[2022-06-20 00:46:08,313] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '377', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpdl8bb_2_', '--error-file', '/tmp/tmpw_em2__q']
[2022-06-20 00:46:08,314] {standard_task_runner.py:80} INFO - Job 377: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:46:08,434] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:46:08,618] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:46:08,652] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:46:08,666] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:46:08,667] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:46:08,705] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T034608, end_date=20220620T034608
[2022-06-20 00:46:08,762] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:46:08,874] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:51:28,093] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:51:28,125] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:51:28,126] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:51:28,126] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:51:28,126] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:51:28,157] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:51:28,173] {standard_task_runner.py:52} INFO - Started process 56268 to run task
[2022-06-20 00:51:28,184] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '394', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmppi92yo2u', '--error-file', '/tmp/tmp34zoit2n']
[2022-06-20 00:51:28,185] {standard_task_runner.py:80} INFO - Job 394: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:51:28,321] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:51:28,541] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:51:28,565] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:51:28,581] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:51:28,584] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:51:28,660] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T035128, end_date=20220620T035128
[2022-06-20 00:51:28,714] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:51:28,819] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:56:50,534] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:56:50,577] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:56:50,577] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:56:50,577] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:56:50,577] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:56:50,619] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:56:50,637] {standard_task_runner.py:52} INFO - Started process 58373 to run task
[2022-06-20 00:56:50,648] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '406', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpryd9cilp', '--error-file', '/tmp/tmpaw_y59cz']
[2022-06-20 00:56:50,650] {standard_task_runner.py:80} INFO - Job 406: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 00:56:50,782] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:56:50,974] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:56:51,000] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:56:51,012] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 00:56:51,020] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 00:56:51,130] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T035650, end_date=20220620T035651
[2022-06-20 00:56:51,189] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:56:51,305] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:00:51,553] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:00:51,581] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:00:51,582] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:00:51,582] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:00:51,582] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:00:51,613] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:00:51,632] {standard_task_runner.py:52} INFO - Started process 60349 to run task
[2022-06-20 01:00:51,639] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '426', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpvjm51z2g', '--error-file', '/tmp/tmpik01o084']
[2022-06-20 01:00:51,640] {standard_task_runner.py:80} INFO - Job 426: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:00:51,767] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:00:51,958] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:00:51,982] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:00:51,999] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 01:00:52,001] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:00:52,099] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T040051, end_date=20220620T040052
[2022-06-20 01:00:52,183] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:00:52,320] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:03:16,957] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:03:17,008] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:03:17,009] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:03:17,009] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:03:17,009] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:03:17,062] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:03:17,096] {standard_task_runner.py:52} INFO - Started process 62566 to run task
[2022-06-20 01:03:17,113] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '444', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpec6_z7p1', '--error-file', '/tmp/tmpf6jo6u_h']
[2022-06-20 01:03:17,114] {standard_task_runner.py:80} INFO - Job 444: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:03:17,312] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:03:17,632] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:03:17,652] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:03:17,660] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 01:03:17,661] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:03:17,697] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T040316, end_date=20220620T040317
[2022-06-20 01:03:17,771] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:03:17,859] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:04:38,081] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:04:38,115] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:04:38,117] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:04:38,117] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:04:38,118] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:04:38,152] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:04:38,176] {standard_task_runner.py:52} INFO - Started process 64192 to run task
[2022-06-20 01:04:38,190] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '459', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpr4b8a0qz', '--error-file', '/tmp/tmpuuhn8851']
[2022-06-20 01:04:38,190] {standard_task_runner.py:80} INFO - Job 459: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:04:38,344] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:04:38,559] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:04:38,610] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:04:38,628] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 01:04:38,629] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:04:38,680] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T040438, end_date=20220620T040438
[2022-06-20 01:04:38,759] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:04:38,885] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:10:59,693] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:10:59,731] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:10:59,731] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:10:59,732] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:10:59,732] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:10:59,771] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:10:59,794] {standard_task_runner.py:52} INFO - Started process 68800 to run task
[2022-06-20 01:10:59,812] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '474', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp654tnjqs', '--error-file', '/tmp/tmp030u83i_']
[2022-06-20 01:10:59,813] {standard_task_runner.py:80} INFO - Job 474: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:10:59,977] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:11:00,239] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:11:00,279] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:11:00,290] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 01:11:00,292] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:11:00,394] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T041059, end_date=20220620T041100
[2022-06-20 01:11:00,473] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:11:00,600] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:16:04,952] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:16:04,983] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:16:04,983] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:16:04,983] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:16:04,983] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:16:05,018] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:16:05,036] {standard_task_runner.py:52} INFO - Started process 71960 to run task
[2022-06-20 01:16:05,049] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '489', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpkkct50q8', '--error-file', '/tmp/tmph8cex5m3']
[2022-06-20 01:16:05,050] {standard_task_runner.py:80} INFO - Job 489: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:16:05,183] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:16:05,348] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:16:05,402] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:16:05,411] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 01:16:05,413] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:16:05,512] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T041604, end_date=20220620T041605
[2022-06-20 01:16:05,630] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:16:05,790] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:17:40,718] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:17:40,747] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:17:40,747] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:17:40,747] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:17:40,748] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:17:40,774] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:17:40,790] {standard_task_runner.py:52} INFO - Started process 73705 to run task
[2022-06-20 01:17:40,799] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '503', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpr8uduwpj', '--error-file', '/tmp/tmpcoynwsil']
[2022-06-20 01:17:40,799] {standard_task_runner.py:80} INFO - Job 503: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:17:40,901] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:17:41,061] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:17:41,083] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:17:41,091] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 01:17:41,093] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:17:41,191] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T041740, end_date=20220620T041741
[2022-06-20 01:17:41,250] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:17:41,367] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:25:14,162] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:25:14,197] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:25:14,198] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:25:14,198] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:25:14,198] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:25:14,233] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:25:14,247] {standard_task_runner.py:52} INFO - Started process 79104 to run task
[2022-06-20 01:25:14,252] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '520', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp0ae4tjgd', '--error-file', '/tmp/tmpd1vrdv19']
[2022-06-20 01:25:14,253] {standard_task_runner.py:80} INFO - Job 520: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:25:14,368] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:25:14,533] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:25:14,566] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:25:14,576] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 01:25:14,589] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:25:14,663] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T042514, end_date=20220620T042514
[2022-06-20 01:25:14,749] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:25:14,880] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:26:35,736] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:26:35,772] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:26:35,773] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:26:35,773] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:26:35,773] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:26:35,808] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:26:35,826] {standard_task_runner.py:52} INFO - Started process 80591 to run task
[2022-06-20 01:26:35,832] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '540', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpb0hc_pd_', '--error-file', '/tmp/tmp1eo31grj']
[2022-06-20 01:26:35,832] {standard_task_runner.py:80} INFO - Job 540: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:26:35,950] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:26:36,145] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:26:36,173] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:26:36,184] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 01:26:36,186] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:26:36,267] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T042635, end_date=20220620T042636
[2022-06-20 01:26:36,327] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:26:36,440] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:27:54,729] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:27:54,766] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:27:54,766] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:27:54,767] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:27:54,767] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:27:54,800] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:27:54,818] {standard_task_runner.py:52} INFO - Started process 82050 to run task
[2022-06-20 01:27:54,827] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '551', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpoglk5qgs', '--error-file', '/tmp/tmphz7_hm0q']
[2022-06-20 01:27:54,827] {standard_task_runner.py:80} INFO - Job 551: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:27:55,003] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:27:55,189] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:27:55,209] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:27:55,219] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 01:27:55,221] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:27:55,281] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T042754, end_date=20220620T042755
[2022-06-20 01:27:55,342] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:27:55,475] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:32:33,720] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:32:33,753] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:32:33,754] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:32:33,754] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:32:33,754] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:32:33,800] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:32:33,815] {standard_task_runner.py:52} INFO - Started process 84034 to run task
[2022-06-20 01:32:33,824] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '567', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpxq7dn21y', '--error-file', '/tmp/tmpd_1m4ep5']
[2022-06-20 01:32:33,825] {standard_task_runner.py:80} INFO - Job 567: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:32:33,939] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:32:34,118] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:32:34,141] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:32:34,151] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-20 01:32:34,154] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:32:34,196] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T043233, end_date=20220620T043234
[2022-06-20 01:32:34,238] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:32:34,376] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:45:10,512] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:45:10,536] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:45:10,536] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:45:10,536] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:45:10,537] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:45:10,568] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:45:10,588] {standard_task_runner.py:52} INFO - Started process 87276 to run task
[2022-06-20 01:45:10,595] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '586', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmph2077oc0', '--error-file', '/tmp/tmpg8rcui3k']
[2022-06-20 01:45:10,596] {standard_task_runner.py:80} INFO - Job 586: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:45:10,745] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:45:10,960] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:45:11,000] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:45:11,021] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 01:45:11,090] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T044510, end_date=20220620T044511
[2022-06-20 01:45:11,176] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:45:11,282] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:46:56,966] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:46:57,000] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:46:57,001] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:46:57,002] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:46:57,002] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:46:57,037] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:46:57,057] {standard_task_runner.py:52} INFO - Started process 88560 to run task
[2022-06-20 01:46:57,071] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '598', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpu3jwifso', '--error-file', '/tmp/tmp0ymz155s']
[2022-06-20 01:46:57,072] {standard_task_runner.py:80} INFO - Job 598: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:46:57,239] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:46:57,431] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:46:57,483] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:46:57,495] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 01:46:57,606] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T044656, end_date=20220620T044657
[2022-06-20 01:46:57,684] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:46:57,766] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:50:27,722] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:50:27,751] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:50:27,752] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:50:27,752] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:50:27,752] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:50:27,777] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:50:27,793] {standard_task_runner.py:52} INFO - Started process 89924 to run task
[2022-06-20 01:50:27,800] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '601', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpupdao7mw', '--error-file', '/tmp/tmp6oxyg4vv']
[2022-06-20 01:50:27,801] {standard_task_runner.py:80} INFO - Job 601: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 01:50:27,894] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:50:28,064] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:50:28,088] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:50:28,098] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 01:50:28,102] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 01:50:28,185] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T045027, end_date=20220620T045028
[2022-06-20 01:50:28,295] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:50:28,449] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 02:25:22,553] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:25:22,576] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:25:22,576] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:25:22,576] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 02:25:22,577] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:25:22,598] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 02:25:22,608] {standard_task_runner.py:52} INFO - Started process 96880 to run task
[2022-06-20 02:25:22,614] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '624', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpc6ntotev', '--error-file', '/tmp/tmpexggqs5r']
[2022-06-20 02:25:22,615] {standard_task_runner.py:80} INFO - Job 624: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 02:25:22,688] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 02:25:22,784] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 02:25:22,801] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 02:25:22,805] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 02:25:22,806] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 02:25:22,848] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T052522, end_date=20220620T052522
[2022-06-20 02:25:22,904] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 02:25:22,961] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 02:27:31,610] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:27:31,631] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:27:31,632] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:27:31,632] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 02:27:31,632] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:27:31,649] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 02:27:31,656] {standard_task_runner.py:52} INFO - Started process 98478 to run task
[2022-06-20 02:27:31,660] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '634', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp5k5gicqt', '--error-file', '/tmp/tmpuipmme5c']
[2022-06-20 02:27:31,660] {standard_task_runner.py:80} INFO - Job 634: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 02:27:31,726] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 02:27:31,818] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 02:27:31,830] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 02:27:31,839] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 02:27:31,840] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 02:27:31,883] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T052731, end_date=20220620T052731
[2022-06-20 02:27:31,912] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 02:27:31,968] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 02:29:03,576] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:29:03,592] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:29:03,592] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:29:03,592] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 02:29:03,592] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:29:03,610] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 02:29:03,618] {standard_task_runner.py:52} INFO - Started process 100419 to run task
[2022-06-20 02:29:03,622] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '651', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmppdn61dm2', '--error-file', '/tmp/tmp58oahtv_']
[2022-06-20 02:29:03,623] {standard_task_runner.py:80} INFO - Job 651: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 02:29:03,692] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 02:29:03,791] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 02:29:03,804] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 02:29:03,809] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 02:29:03,811] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 02:29:03,828] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T052903, end_date=20220620T052903
[2022-06-20 02:29:03,873] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 02:29:03,931] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 03:25:16,435] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:25:16,452] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:25:16,452] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:25:16,452] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 03:25:16,452] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:25:16,472] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 03:25:16,479] {standard_task_runner.py:52} INFO - Started process 110729 to run task
[2022-06-20 03:25:16,486] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '670', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpaobfc9on', '--error-file', '/tmp/tmpvro9er0l']
[2022-06-20 03:25:16,486] {standard_task_runner.py:80} INFO - Job 670: Subtask create_tables_stages.criar_Stage_Products
                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2022-06-20 03:39:03,185] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:39:03,228] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:39:03,229] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:39:03,229] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 03:39:03,229] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:39:03,261] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 03:39:03,273] {standard_task_runner.py:52} INFO - Started process 8676 to run task
[2022-06-20 03:39:03,280] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '705', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpdp2gw48_', '--error-file', '/tmp/tmpi3itwkz5']
[2022-06-20 03:39:03,280] {standard_task_runner.py:80} INFO - Job 705: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 03:39:03,417] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 03:39:03,584] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 03:39:03,608] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 03:39:03,617] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 03:39:03,618] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 03:39:03,722] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T063903, end_date=20220620T063903
[2022-06-20 03:39:03,819] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 03:39:03,927] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 04:37:53,556] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 04:37:53,586] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 04:37:53,586] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 04:37:53,586] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 04:37:53,587] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 04:37:53,619] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 04:37:53,635] {standard_task_runner.py:52} INFO - Started process 19097 to run task
[2022-06-20 04:37:53,642] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '726', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpvskds14h', '--error-file', '/tmp/tmp2tnq_28a']
[2022-06-20 04:37:53,642] {standard_task_runner.py:80} INFO - Job 726: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 04:37:53,773] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 04:37:53,975] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 04:37:54,015] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 04:37:54,033] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                id_products SERIAL PRIMARY KEY,                      
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 04:37:54,081] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T073753, end_date=20220620T073754
[2022-06-20 04:37:54,140] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 04:37:54,257] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 05:29:33,464] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 05:29:33,493] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 05:29:33,494] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 05:29:33,494] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 05:29:33,494] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 05:29:33,519] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 05:29:33,532] {standard_task_runner.py:52} INFO - Started process 30962 to run task
[2022-06-20 05:29:33,540] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '750', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmps261aakc', '--error-file', '/tmp/tmpepm6erkb']
[2022-06-20 05:29:33,540] {standard_task_runner.py:80} INFO - Job 750: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 05:29:33,662] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 05:29:33,852] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 05:29:33,876] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 05:29:33,889] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode INT NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 05:29:33,962] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T082933, end_date=20220620T082933
[2022-06-20 05:29:34,036] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 05:29:34,145] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:29:55,083] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:29:55,097] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:29:55,097] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:29:55,097] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:29:55,097] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:29:55,115] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:29:55,122] {standard_task_runner.py:52} INFO - Started process 43619 to run task
[2022-06-20 11:29:55,126] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '768', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpvmwqgpr2', '--error-file', '/tmp/tmpgogn1e7a']
[2022-06-20 11:29:55,126] {standard_task_runner.py:80} INFO - Job 768: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 11:29:55,194] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:29:55,290] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:29:55,305] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:29:55,313] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode INT NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 11:29:55,315] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 11:29:55,374] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T142955, end_date=20220620T142955
[2022-06-20 11:29:55,421] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:29:55,490] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:33:08,750] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:33:08,762] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:33:08,762] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:33:08,763] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:33:08,763] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:33:08,785] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:33:08,791] {standard_task_runner.py:52} INFO - Started process 45577 to run task
[2022-06-20 11:33:08,794] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '783', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpw5qsjlyz', '--error-file', '/tmp/tmppcdv4vus']
[2022-06-20 11:33:08,794] {standard_task_runner.py:80} INFO - Job 783: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 11:33:08,855] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:33:08,939] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:33:08,952] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:33:08,956] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode INT NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 11:33:08,957] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 11:33:09,016] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T143308, end_date=20220620T143309
[2022-06-20 11:33:09,046] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:33:09,101] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:39:13,541] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:39:13,559] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:39:13,559] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:39:13,559] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:39:13,559] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:39:13,576] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:39:13,583] {standard_task_runner.py:52} INFO - Started process 48626 to run task
[2022-06-20 11:39:13,586] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpgb2uzdsu', '--error-file', '/tmp/tmpds34ddp1']
[2022-06-20 11:39:13,587] {standard_task_runner.py:80} INFO - Job 7: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 11:39:13,656] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:39:13,767] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:39:13,815] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 86, in get_conn
    conn = deepcopy(self.connection or self.get_connection(conn_id))
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/models/connection.py", line 430, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `***` isn't defined
[2022-06-20 11:39:13,820] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T143913, end_date=20220620T143913
[2022-06-20 11:39:13,834] {standard_task_runner.py:92} ERROR - Failed to execute job 7 for task create_tables_stages.criar_Stage_Products (The conn_id `***` isn't defined; 48626)
[2022-06-20 11:39:13,883] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-20 11:39:13,975] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:41:39,732] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:41:39,753] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:41:39,754] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:41:39,754] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:41:39,754] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:41:39,771] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:41:39,778] {standard_task_runner.py:52} INFO - Started process 49908 to run task
[2022-06-20 11:41:39,783] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp27f3z8ld', '--error-file', '/tmp/tmpkvr1it5k']
[2022-06-20 11:41:39,784] {standard_task_runner.py:80} INFO - Job 12: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 11:41:39,848] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:41:39,942] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:41:40,017] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 86, in get_conn
    conn = deepcopy(self.connection or self.get_connection(conn_id))
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/models/connection.py", line 430, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `***` isn't defined
[2022-06-20 11:41:40,022] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T144139, end_date=20220620T144140
[2022-06-20 11:41:40,041] {standard_task_runner.py:92} ERROR - Failed to execute job 12 for task create_tables_stages.criar_Stage_Products (The conn_id `***` isn't defined; 49908)
[2022-06-20 11:41:40,074] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-20 11:41:40,133] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:43:51,657] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:43:51,672] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:43:51,672] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:43:51,672] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:43:51,672] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:43:51,690] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:43:51,696] {standard_task_runner.py:52} INFO - Started process 51131 to run task
[2022-06-20 11:43:51,701] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpmf4_pl5w', '--error-file', '/tmp/tmpux8hae3u']
[2022-06-20 11:43:51,702] {standard_task_runner.py:80} INFO - Job 22: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 11:43:51,760] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:43:51,854] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:43:51,870] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:43:51,876] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode INT NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 11:43:51,904] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T144351, end_date=20220620T144351
[2022-06-20 11:43:51,953] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:43:52,008] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:46:09,343] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:46:09,357] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:46:09,357] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:46:09,357] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:46:09,357] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:46:09,374] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:46:09,379] {standard_task_runner.py:52} INFO - Started process 52559 to run task
[2022-06-20 11:46:09,383] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpil85ou6u', '--error-file', '/tmp/tmpb73jsd5d']
[2022-06-20 11:46:09,383] {standard_task_runner.py:80} INFO - Job 37: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 11:46:09,452] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:46:09,558] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:46:09,570] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:46:09,579] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode INT NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 11:46:09,580] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 11:46:09,614] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T144609, end_date=20220620T144609
[2022-06-20 11:46:09,675] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:46:09,743] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:08:15,588] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:08:15,603] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:08:15,603] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:08:15,603] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:08:15,603] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:08:15,620] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:08:15,626] {standard_task_runner.py:52} INFO - Started process 57331 to run task
[2022-06-20 12:08:15,630] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '54', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpmwypqwcd', '--error-file', '/tmp/tmp2kpq2hon']
[2022-06-20 12:08:15,631] {standard_task_runner.py:80} INFO - Job 54: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 12:08:15,699] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:08:15,807] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:08:15,821] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:08:15,827] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 12:08:15,828] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 12:08:15,852] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T150815, end_date=20220620T150815
[2022-06-20 12:08:15,883] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:08:15,967] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:24:55,425] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:24:55,457] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:24:55,457] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:24:55,458] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:24:55,458] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:24:55,491] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:24:55,503] {standard_task_runner.py:52} INFO - Started process 9154 to run task
[2022-06-20 12:24:55,509] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '72', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpfmqe7r3z', '--error-file', '/tmp/tmpcbjudmc4']
[2022-06-20 12:24:55,510] {standard_task_runner.py:80} INFO - Job 72: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 12:24:55,631] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:24:55,790] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:24:55,813] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:24:55,821] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 12:24:55,823] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 12:24:55,870] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T152455, end_date=20220620T152455
[2022-06-20 12:24:55,925] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:24:56,073] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:27:37,329] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:27:37,355] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:27:37,355] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:27:37,355] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:27:37,355] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:27:37,383] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:27:37,397] {standard_task_runner.py:52} INFO - Started process 11524 to run task
[2022-06-20 12:27:37,403] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '90', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp6s7o49r6', '--error-file', '/tmp/tmp6ydlhc31']
[2022-06-20 12:27:37,403] {standard_task_runner.py:80} INFO - Job 90: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 12:27:37,529] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:27:37,709] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:27:37,733] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:27:37,741] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 12:27:37,743] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 12:27:37,793] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T152737, end_date=20220620T152737
[2022-06-20 12:27:37,862] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:27:37,979] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:39:45,676] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:39:45,702] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:39:45,702] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:39:45,703] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:39:45,703] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:39:45,730] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:39:45,745] {standard_task_runner.py:52} INFO - Started process 14592 to run task
[2022-06-20 12:39:45,752] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '109', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpr_831kc6', '--error-file', '/tmp/tmpkfs95fk7']
[2022-06-20 12:39:45,753] {standard_task_runner.py:80} INFO - Job 109: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 12:39:45,868] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:39:46,044] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:39:46,064] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:39:46,072] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 12:39:46,147] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T153945, end_date=20220620T153946
[2022-06-20 12:39:46,210] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:39:46,301] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:56:49,837] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:56:49,861] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:56:49,861] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:56:49,861] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:56:49,862] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:56:49,884] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:56:49,900] {standard_task_runner.py:52} INFO - Started process 17808 to run task
[2022-06-20 12:56:49,910] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '123', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpb1vdvuuw', '--error-file', '/tmp/tmp382j48ie']
[2022-06-20 12:56:49,910] {standard_task_runner.py:80} INFO - Job 123: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 12:56:50,019] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:56:50,183] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:56:50,204] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:56:50,213] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 12:56:50,215] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 12:56:50,314] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T155649, end_date=20220620T155650
[2022-06-20 12:56:50,363] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:56:50,467] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 13:00:03,755] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:00:03,780] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:00:03,780] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:00:03,780] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 13:00:03,780] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:00:03,807] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 13:00:03,823] {standard_task_runner.py:52} INFO - Started process 19720 to run task
[2022-06-20 13:00:03,829] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '143', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp5e08hk5v', '--error-file', '/tmp/tmpa2zi8px0']
[2022-06-20 13:00:03,830] {standard_task_runner.py:80} INFO - Job 143: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 13:00:03,969] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 13:00:04,163] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 13:00:04,191] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 13:00:04,199] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 13:00:04,200] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 13:00:04,233] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T160003, end_date=20220620T160004
[2022-06-20 13:00:04,283] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 13:00:04,420] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 13:45:20,453] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:45:20,478] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:45:20,478] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:45:20,478] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 13:45:20,479] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:45:20,504] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 13:45:20,519] {standard_task_runner.py:52} INFO - Started process 29090 to run task
[2022-06-20 13:45:20,526] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '165', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp8nzmgvtn', '--error-file', '/tmp/tmpvzpnlbyg']
[2022-06-20 13:45:20,527] {standard_task_runner.py:80} INFO - Job 165: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 13:45:20,649] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 13:45:20,822] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 13:45:20,844] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 13:45:20,853] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 13:45:20,855] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 13:45:20,933] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T164520, end_date=20220620T164520
[2022-06-20 13:45:20,986] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 13:45:21,091] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:00:11,094] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:00:11,128] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:00:11,128] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:00:11,128] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:00:11,128] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:00:11,173] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:00:11,193] {standard_task_runner.py:52} INFO - Started process 33077 to run task
[2022-06-20 14:00:11,219] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '184', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp0308go2g', '--error-file', '/tmp/tmpz00i2v2z']
[2022-06-20 14:00:11,219] {standard_task_runner.py:80} INFO - Job 184: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 14:00:11,426] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:00:11,666] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:00:11,689] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:00:11,701] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 14:00:11,703] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 14:00:11,845] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T170011, end_date=20220620T170011
[2022-06-20 14:00:11,907] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:00:11,994] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:07:57,148] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:07:57,181] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:07:57,182] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:07:57,182] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:07:57,182] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:07:57,214] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:07:57,230] {standard_task_runner.py:52} INFO - Started process 36460 to run task
[2022-06-20 14:07:57,237] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '201', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp6pcmfpta', '--error-file', '/tmp/tmpcmr1q_ye']
[2022-06-20 14:07:57,238] {standard_task_runner.py:80} INFO - Job 201: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 14:07:57,365] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:07:57,553] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:07:57,574] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:07:57,582] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 14:07:57,584] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 14:07:57,643] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T170757, end_date=20220620T170757
[2022-06-20 14:07:57,703] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:07:57,780] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:15:19,489] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:15:19,520] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:15:19,521] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:15:19,521] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:15:19,521] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:15:19,554] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:15:19,569] {standard_task_runner.py:52} INFO - Started process 39205 to run task
[2022-06-20 14:15:19,577] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '220', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp72mw04j0', '--error-file', '/tmp/tmpc_qy2l4o']
[2022-06-20 14:15:19,578] {standard_task_runner.py:80} INFO - Job 220: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 14:15:19,722] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:15:19,898] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:15:19,922] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:15:19,929] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 14:15:19,930] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 14:15:19,964] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T171519, end_date=20220620T171519
[2022-06-20 14:15:20,033] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:15:20,114] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:16:23,862] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:16:23,889] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:16:23,889] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:16:23,889] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:16:23,889] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:16:23,915] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:16:23,928] {standard_task_runner.py:52} INFO - Started process 40698 to run task
[2022-06-20 14:16:23,935] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '234', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpklmq_ica', '--error-file', '/tmp/tmpgd9ogg9o']
[2022-06-20 14:16:23,936] {standard_task_runner.py:80} INFO - Job 234: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 14:16:24,046] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:16:24,237] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:16:24,258] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:16:24,266] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 14:16:24,275] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 14:16:24,356] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T171623, end_date=20220620T171624
[2022-06-20 14:16:24,429] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:16:24,540] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:26:50,841] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:26:50,872] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:26:50,872] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:26:50,873] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:26:50,873] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:26:50,912] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:26:50,928] {standard_task_runner.py:52} INFO - Started process 43919 to run task
[2022-06-20 14:26:50,942] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '256', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp9juxq4b_', '--error-file', '/tmp/tmp981b3tf0']
[2022-06-20 14:26:50,943] {standard_task_runner.py:80} INFO - Job 256: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 14:26:51,116] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:26:51,308] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:26:51,330] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:26:51,342] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 14:26:51,344] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 14:26:51,412] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T172650, end_date=20220620T172651
[2022-06-20 14:26:51,488] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:26:51,572] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:31:44,488] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:31:44,536] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:31:44,537] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:31:44,538] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:31:44,538] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:31:44,600] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:31:44,620] {standard_task_runner.py:52} INFO - Started process 46199 to run task
[2022-06-20 14:31:44,635] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '274', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp4sff2ptz', '--error-file', '/tmp/tmp3khaew5s']
[2022-06-20 14:31:44,636] {standard_task_runner.py:80} INFO - Job 274: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 14:31:44,772] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:31:44,936] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:31:44,956] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:31:44,969] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 14:31:45,034] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T173144, end_date=20220620T173145
[2022-06-20 14:31:45,093] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:31:45,172] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:34:11,499] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:34:11,528] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:34:11,529] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:34:11,529] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:34:11,529] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:34:11,559] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:34:11,575] {standard_task_runner.py:52} INFO - Started process 47948 to run task
[2022-06-20 14:34:11,583] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '289', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpg9xtcies', '--error-file', '/tmp/tmpgmlnybi3']
[2022-06-20 14:34:11,584] {standard_task_runner.py:80} INFO - Job 289: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 14:34:11,732] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:34:11,952] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:34:11,997] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:34:12,009] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 14:34:12,079] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T173411, end_date=20220620T173412
[2022-06-20 14:34:12,163] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:34:12,323] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:37:52,925] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:37:52,962] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:37:52,962] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:37:52,963] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:37:52,963] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:37:52,994] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:37:53,010] {standard_task_runner.py:52} INFO - Started process 50670 to run task
[2022-06-20 14:37:53,016] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '305', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp1kf4hbuz', '--error-file', '/tmp/tmpl9km48w8']
[2022-06-20 14:37:53,017] {standard_task_runner.py:80} INFO - Job 305: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 14:37:53,153] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:37:53,345] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:37:53,378] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:37:53,390] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 14:37:53,468] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T173752, end_date=20220620T173753
[2022-06-20 14:37:53,553] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:37:53,677] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:46:35,992] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:46:36,021] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:46:36,021] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:46:36,021] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:46:36,021] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:46:36,052] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:46:36,066] {standard_task_runner.py:52} INFO - Started process 54122 to run task
[2022-06-20 14:46:36,073] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '320', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpdejz8c2t', '--error-file', '/tmp/tmpqbs_aihp']
[2022-06-20 14:46:36,074] {standard_task_runner.py:80} INFO - Job 320: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 14:46:36,202] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:46:36,376] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:46:36,407] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:46:36,419] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 14:46:36,464] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T174635, end_date=20220620T174636
[2022-06-20 14:46:36,530] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:46:36,661] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:33:19,716] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:33:19,755] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:33:19,756] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:33:19,756] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:33:19,756] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:33:19,798] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:33:19,813] {standard_task_runner.py:52} INFO - Started process 60608 to run task
[2022-06-20 15:33:19,822] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '337', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp4xplk830', '--error-file', '/tmp/tmp9wrwbc2e']
[2022-06-20 15:33:19,823] {standard_task_runner.py:80} INFO - Job 337: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 15:33:19,917] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:33:20,071] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:33:20,093] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:33:20,101] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 15:33:20,192] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T183319, end_date=20220620T183320
[2022-06-20 15:33:20,275] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:33:20,383] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:35:25,008] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:35:25,034] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:35:25,034] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:35:25,034] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:35:25,035] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:35:25,064] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:35:25,079] {standard_task_runner.py:52} INFO - Started process 62215 to run task
[2022-06-20 15:35:25,085] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '356', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpsqfahu1f', '--error-file', '/tmp/tmpn5jrps2p']
[2022-06-20 15:35:25,086] {standard_task_runner.py:80} INFO - Job 356: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 15:35:25,205] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:35:25,380] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:35:25,412] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:35:25,423] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 15:35:25,503] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T183525, end_date=20220620T183525
[2022-06-20 15:35:25,584] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:35:25,712] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:41:45,638] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:41:45,674] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:41:45,675] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:41:45,675] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:41:45,675] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:41:45,712] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:41:45,734] {standard_task_runner.py:52} INFO - Started process 64652 to run task
[2022-06-20 15:41:45,757] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '375', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp2mslb8z2', '--error-file', '/tmp/tmpe9ivwr6n']
[2022-06-20 15:41:45,758] {standard_task_runner.py:80} INFO - Job 375: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 15:41:45,920] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:41:46,100] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:41:46,127] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:41:46,140] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 15:41:46,141] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 15:41:46,228] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T184145, end_date=20220620T184146
[2022-06-20 15:41:46,285] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:41:46,425] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:51:27,286] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:51:27,308] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:51:27,308] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:51:27,308] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:51:27,308] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:51:27,332] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:51:27,347] {standard_task_runner.py:52} INFO - Started process 67470 to run task
[2022-06-20 15:51:27,354] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '391', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpewimsua4', '--error-file', '/tmp/tmputptjpyv']
[2022-06-20 15:51:27,355] {standard_task_runner.py:80} INFO - Job 391: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 15:51:27,477] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:51:27,691] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:51:27,733] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:51:27,744] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 15:51:27,789] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T185127, end_date=20220620T185127
[2022-06-20 15:51:27,846] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:51:27,978] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:09:22,537] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:09:22,572] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:09:22,574] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:09:22,574] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:09:22,575] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:09:22,614] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:09:22,630] {standard_task_runner.py:52} INFO - Started process 74413 to run task
[2022-06-20 16:09:22,636] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '418', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpwxwphh43', '--error-file', '/tmp/tmpt1fr6k8u']
[2022-06-20 16:09:22,637] {standard_task_runner.py:80} INFO - Job 418: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 16:09:22,793] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:09:23,044] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:09:23,073] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:09:23,086] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 16:09:23,125] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T190922, end_date=20220620T190923
[2022-06-20 16:09:23,196] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:09:23,335] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:13:44,847] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:13:44,885] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:13:44,885] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:13:44,885] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:13:44,885] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:13:44,911] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:13:44,924] {standard_task_runner.py:52} INFO - Started process 76375 to run task
[2022-06-20 16:13:44,930] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '431', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpx1hiiwv_', '--error-file', '/tmp/tmpoa9kfyw8']
[2022-06-20 16:13:44,931] {standard_task_runner.py:80} INFO - Job 431: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 16:13:45,025] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:13:45,168] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:13:45,192] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:13:45,201] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 16:13:45,289] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T191344, end_date=20220620T191345
[2022-06-20 16:13:45,346] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:13:45,504] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:15:24,265] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:15:24,298] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:15:24,299] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:15:24,299] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:15:24,299] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:15:24,333] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:15:24,351] {standard_task_runner.py:52} INFO - Started process 77955 to run task
[2022-06-20 16:15:24,365] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '451', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp8vhkun0v', '--error-file', '/tmp/tmp4ci9i68h']
[2022-06-20 16:15:24,366] {standard_task_runner.py:80} INFO - Job 451: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 16:15:24,587] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:15:24,949] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:15:24,980] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:15:24,990] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 16:15:24,992] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 16:15:25,044] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T191524, end_date=20220620T191525
[2022-06-20 16:15:25,108] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:15:25,208] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:16:00,285] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:16:00,325] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:16:00,326] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:16:00,326] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:16:00,326] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:16:00,356] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:16:00,372] {standard_task_runner.py:52} INFO - Started process 78850 to run task
[2022-06-20 16:16:00,379] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '459', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpm7ls69kj', '--error-file', '/tmp/tmpwqthca7y']
[2022-06-20 16:16:00,380] {standard_task_runner.py:80} INFO - Job 459: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 16:16:00,473] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:16:00,603] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:16:00,622] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:16:00,629] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 16:16:00,703] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T191600, end_date=20220620T191600
[2022-06-20 16:16:00,751] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:16:00,839] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:29:36,714] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:29:36,747] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:29:36,748] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:29:36,748] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:29:36,748] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:29:36,781] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:29:36,795] {standard_task_runner.py:52} INFO - Started process 81830 to run task
[2022-06-20 16:29:36,804] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '480', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpjnc4p47v', '--error-file', '/tmp/tmpx8urku1m']
[2022-06-20 16:29:36,805] {standard_task_runner.py:80} INFO - Job 480: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 16:29:36,965] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:29:37,147] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:29:37,173] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:29:37,181] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 16:29:37,184] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-20 16:29:37,218] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T192936, end_date=20220620T192937
[2022-06-20 16:29:37,301] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:29:37,386] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:31:51,313] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:31:51,377] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:31:51,378] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:31:51,378] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:31:51,378] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:31:51,446] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:31:51,473] {standard_task_runner.py:52} INFO - Started process 83663 to run task
[2022-06-20 16:31:51,486] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '494', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp_kgm6q0k', '--error-file', '/tmp/tmpnz7_5z54']
[2022-06-20 16:31:51,487] {standard_task_runner.py:80} INFO - Job 494: Subtask create_tables_stages.criar_Stage_Products
[2022-06-20 16:31:51,616] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:31:51,787] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:31:51,810] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:31:51,820] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productcode VARCHAR(40) NOT NULL,
                productname VARCHAR(40) NOT NULL,
                productline VARCHAR(20) NOT NULL,
                productvendor VARCHAR(25) NOT NULL,
                productdescription VARCHAR(200) NOT NULL
                )
            , parameters: None
[2022-06-20 16:31:51,858] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220619T000000, start_date=20220620T193151, end_date=20220620T193151
[2022-06-20 16:31:51,949] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:31:52,063] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
