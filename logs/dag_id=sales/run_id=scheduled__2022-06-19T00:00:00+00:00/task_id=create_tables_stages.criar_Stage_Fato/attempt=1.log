[2022-06-19 23:39:46,935] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:39:46,957] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:39:46,957] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:39:46,957] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-19 23:39:46,957] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:39:46,978] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-19 23:39:46,988] {standard_task_runner.py:52} INFO - Started process 28175 to run task
[2022-06-19 23:39:46,994] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '195', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpx41w_gje', '--error-file', '/tmp/tmpojcl996i']
[2022-06-19 23:39:46,995] {standard_task_runner.py:80} INFO - Job 195: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-19 23:39:47,108] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-19 23:39:47,316] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-19 23:39:47,337] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-19 23:39:47,347] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-19 23:39:47,350] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-19 23:39:47,386] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T023946, end_date=20220620T023947
[2022-06-19 23:39:47,449] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-19 23:39:47,545] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-19 23:42:09,793] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:42:09,824] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:42:09,824] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:42:09,824] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-19 23:42:09,825] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:42:09,854] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-19 23:42:09,869] {standard_task_runner.py:52} INFO - Started process 30267 to run task
[2022-06-19 23:42:09,876] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '214', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpsxozhuis', '--error-file', '/tmp/tmpq3mc8six']
[2022-06-19 23:42:09,877] {standard_task_runner.py:80} INFO - Job 214: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-19 23:42:10,010] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-19 23:42:10,207] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-19 23:42:10,246] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-19 23:42:10,263] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-19 23:42:10,265] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-19 23:42:10,298] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T024209, end_date=20220620T024210
[2022-06-19 23:42:10,393] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-19 23:42:10,612] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-19 23:48:41,656] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:48:41,684] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:48:41,684] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:48:41,684] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-19 23:48:41,685] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:48:41,714] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-19 23:48:41,732] {standard_task_runner.py:52} INFO - Started process 32840 to run task
[2022-06-19 23:48:41,739] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '228', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp6zn8jwpr', '--error-file', '/tmp/tmpm1rkm0m6']
[2022-06-19 23:48:41,740] {standard_task_runner.py:80} INFO - Job 228: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-19 23:48:41,860] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-19 23:48:42,015] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-19 23:48:42,036] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-19 23:48:42,045] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-19 23:48:42,046] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-19 23:48:42,141] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T024841, end_date=20220620T024842
[2022-06-19 23:48:42,193] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-19 23:48:42,284] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:03:58,342] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:03:58,373] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:03:58,374] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:03:58,374] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:03:58,374] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:03:58,403] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:03:58,418] {standard_task_runner.py:52} INFO - Started process 35973 to run task
[2022-06-20 00:03:58,424] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '243', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpn1ond751', '--error-file', '/tmp/tmpq146ohw0']
[2022-06-20 00:03:58,425] {standard_task_runner.py:80} INFO - Job 243: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:03:58,567] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:03:58,750] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:03:58,779] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:03:58,791] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:03:58,796] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:03:58,840] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T030358, end_date=20220620T030358
[2022-06-20 00:03:58,924] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:03:59,023] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:05:08,521] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:05:08,568] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:05:08,568] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:05:08,568] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:05:08,569] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:05:08,606] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:05:08,622] {standard_task_runner.py:52} INFO - Started process 37311 to run task
[2022-06-20 00:05:08,636] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '260', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp7xrmojzo', '--error-file', '/tmp/tmprhoxop8q']
[2022-06-20 00:05:08,637] {standard_task_runner.py:80} INFO - Job 260: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:05:08,787] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:05:08,998] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:05:09,032] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:05:09,040] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:05:09,042] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:05:09,076] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T030508, end_date=20220620T030509
[2022-06-20 00:05:09,171] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:05:09,266] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:06:59,023] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:06:59,048] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:06:59,048] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:06:59,048] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:06:59,049] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:06:59,076] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:06:59,089] {standard_task_runner.py:52} INFO - Started process 38879 to run task
[2022-06-20 00:06:59,098] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '269', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpt_r_7h8z', '--error-file', '/tmp/tmpc4ejeyyc']
[2022-06-20 00:06:59,099] {standard_task_runner.py:80} INFO - Job 269: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:06:59,205] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:06:59,346] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:06:59,366] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:06:59,373] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:06:59,374] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:06:59,423] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T030659, end_date=20220620T030659
[2022-06-20 00:06:59,468] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:06:59,572] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:25:32,761] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:25:32,788] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:25:32,788] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:25:32,788] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:25:32,789] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:25:32,822] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:25:32,836] {standard_task_runner.py:52} INFO - Started process 42804 to run task
[2022-06-20 00:25:32,842] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '281', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpazzpk5yg', '--error-file', '/tmp/tmp7z210hhv']
[2022-06-20 00:25:32,843] {standard_task_runner.py:80} INFO - Job 281: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:25:32,938] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:25:33,068] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:25:33,087] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:25:33,093] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:25:33,095] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:25:33,121] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T032532, end_date=20220620T032533
[2022-06-20 00:25:33,175] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:25:33,263] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:26:28,913] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:26:28,953] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:26:28,954] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:26:28,954] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:26:28,954] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:26:28,988] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:26:29,004] {standard_task_runner.py:52} INFO - Started process 44140 to run task
[2022-06-20 00:26:29,012] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '301', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpw2ksyisz', '--error-file', '/tmp/tmptww8lgw0']
[2022-06-20 00:26:29,013] {standard_task_runner.py:80} INFO - Job 301: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:26:29,163] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:26:29,366] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:26:29,443] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:26:29,454] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:26:29,456] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:26:29,503] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T032628, end_date=20220620T032629
[2022-06-20 00:26:29,591] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:26:29,676] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:29:31,749] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:29:31,770] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:29:31,770] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:29:31,770] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:29:31,770] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:29:31,790] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:29:31,803] {standard_task_runner.py:52} INFO - Started process 45849 to run task
[2022-06-20 00:29:31,809] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '315', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpcps9hu8j', '--error-file', '/tmp/tmpfzc_jrq0']
[2022-06-20 00:29:31,810] {standard_task_runner.py:80} INFO - Job 315: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:29:31,914] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:29:32,062] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:29:32,081] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:29:32,087] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:29:32,089] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:29:32,146] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T032931, end_date=20220620T032932
[2022-06-20 00:29:32,182] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:29:32,280] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:30:44,997] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:30:45,020] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:30:45,021] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:30:45,021] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:30:45,021] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:30:45,043] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:30:45,055] {standard_task_runner.py:52} INFO - Started process 47258 to run task
[2022-06-20 00:30:45,062] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '331', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmprn3hjo86', '--error-file', '/tmp/tmpa09h69kr']
[2022-06-20 00:30:45,063] {standard_task_runner.py:80} INFO - Job 331: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:30:45,158] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:30:45,294] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:30:45,315] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:30:45,322] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:30:45,339] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:30:45,383] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T033044, end_date=20220620T033045
[2022-06-20 00:30:45,436] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:30:45,555] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:32:32,924] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:32:32,943] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:32:32,943] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:32:32,944] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:32:32,944] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:32:32,964] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:32:32,976] {standard_task_runner.py:52} INFO - Started process 48932 to run task
[2022-06-20 00:32:32,981] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '343', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp969i931i', '--error-file', '/tmp/tmpc_o3_az4']
[2022-06-20 00:32:32,982] {standard_task_runner.py:80} INFO - Job 343: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:32:33,075] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:32:33,251] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:32:33,276] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:32:33,285] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:32:33,287] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:32:33,325] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T033232, end_date=20220620T033233
[2022-06-20 00:32:33,396] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:32:33,558] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:34:14,379] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:34:14,403] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:34:14,404] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:34:14,404] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:34:14,404] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:34:14,430] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:34:14,443] {standard_task_runner.py:52} INFO - Started process 50541 to run task
[2022-06-20 00:34:14,451] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '360', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpki1i5hgp', '--error-file', '/tmp/tmp58x1cpxg']
[2022-06-20 00:34:14,451] {standard_task_runner.py:80} INFO - Job 360: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:34:14,572] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:34:14,746] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:34:14,768] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:34:14,777] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:34:14,779] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:34:14,834] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T033414, end_date=20220620T033414
[2022-06-20 00:34:14,906] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:34:15,015] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:46:08,128] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:46:08,155] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:46:08,155] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:46:08,155] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:46:08,155] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:46:08,185] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:46:08,201] {standard_task_runner.py:52} INFO - Started process 53709 to run task
[2022-06-20 00:46:08,209] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '376', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpz_hd0_ct', '--error-file', '/tmp/tmplm39b4m7']
[2022-06-20 00:46:08,209] {standard_task_runner.py:80} INFO - Job 376: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:46:08,338] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:46:08,506] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:46:08,531] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:46:08,542] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:46:08,545] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:46:08,587] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T034608, end_date=20220620T034608
[2022-06-20 00:46:08,663] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:46:08,792] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:51:27,669] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:51:27,711] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:51:27,712] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:51:27,712] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:51:27,712] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:51:27,761] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:51:27,773] {standard_task_runner.py:52} INFO - Started process 56238 to run task
[2022-06-20 00:51:27,780] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '390', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpr13mh8ec', '--error-file', '/tmp/tmpa76zg7i7']
[2022-06-20 00:51:27,781] {standard_task_runner.py:80} INFO - Job 390: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:51:27,915] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:51:28,138] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:51:28,163] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:51:28,173] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:51:28,176] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:51:28,207] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T035127, end_date=20220620T035128
[2022-06-20 00:51:28,276] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:51:28,431] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:56:51,033] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:56:51,081] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:56:51,081] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:56:51,081] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:56:51,081] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:56:51,127] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:56:51,145] {standard_task_runner.py:52} INFO - Started process 58408 to run task
[2022-06-20 00:56:51,165] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '411', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpzsqb_281', '--error-file', '/tmp/tmp553m1rgp']
[2022-06-20 00:56:51,166] {standard_task_runner.py:80} INFO - Job 411: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 00:56:51,304] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:56:51,489] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:56:51,516] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:56:51,523] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 00:56:51,530] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 00:56:51,595] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T035651, end_date=20220620T035651
[2022-06-20 00:56:51,649] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:56:51,734] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:00:51,642] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:00:51,674] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:00:51,675] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:00:51,675] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:00:51,675] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:00:51,712] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:00:51,727] {standard_task_runner.py:52} INFO - Started process 60359 to run task
[2022-06-20 01:00:51,739] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '427', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpibjlbyxp', '--error-file', '/tmp/tmpma1bqoub']
[2022-06-20 01:00:51,740] {standard_task_runner.py:80} INFO - Job 427: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:00:51,910] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:00:52,138] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:00:52,165] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:00:52,183] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 01:00:52,186] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:00:52,239] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T040051, end_date=20220620T040052
[2022-06-20 01:00:52,312] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:00:52,455] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:03:16,598] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:03:16,638] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:03:16,640] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:03:16,640] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:03:16,640] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:03:16,671] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:03:16,686] {standard_task_runner.py:52} INFO - Started process 62522 to run task
[2022-06-20 01:03:16,693] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '440', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpr9e4b4k_', '--error-file', '/tmp/tmp5qvubfht']
[2022-06-20 01:03:16,695] {standard_task_runner.py:80} INFO - Job 440: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:03:16,817] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:03:17,022] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:03:17,058] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:03:17,073] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 01:03:17,076] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:03:17,183] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T040316, end_date=20220620T040317
[2022-06-20 01:03:17,310] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:03:17,487] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:04:38,196] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:04:38,234] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:04:38,235] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:04:38,235] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:04:38,235] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:04:38,271] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:04:38,289] {standard_task_runner.py:52} INFO - Started process 64224 to run task
[2022-06-20 01:04:38,295] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '460', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpsqhzcjr8', '--error-file', '/tmp/tmptuwr9mtd']
[2022-06-20 01:04:38,296] {standard_task_runner.py:80} INFO - Job 460: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:04:38,441] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:04:38,669] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:04:38,725] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:04:38,738] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 01:04:38,745] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:04:38,801] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T040438, end_date=20220620T040438
[2022-06-20 01:04:38,872] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:04:38,952] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:10:59,916] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:10:59,986] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:10:59,987] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:10:59,987] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:10:59,987] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:11:00,051] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:11:00,071] {standard_task_runner.py:52} INFO - Started process 68821 to run task
[2022-06-20 01:11:00,091] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '476', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpwpczt8fy', '--error-file', '/tmp/tmp7xck116n']
[2022-06-20 01:11:00,099] {standard_task_runner.py:80} INFO - Job 476: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:11:00,303] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:11:00,565] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:11:00,590] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:11:00,600] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 01:11:00,602] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:11:00,636] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T041059, end_date=20220620T041100
[2022-06-20 01:11:00,712] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:11:00,836] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:16:05,046] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:16:05,085] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:16:05,086] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:16:05,086] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:16:05,086] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:16:05,127] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:16:05,144] {standard_task_runner.py:52} INFO - Started process 71998 to run task
[2022-06-20 01:16:05,151] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '490', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpbdaa0odg', '--error-file', '/tmp/tmp2din_4sp']
[2022-06-20 01:16:05,152] {standard_task_runner.py:80} INFO - Job 490: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:16:05,268] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:16:05,699] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:16:05,741] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:16:05,756] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 01:16:05,758] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:16:05,832] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T041605, end_date=20220620T041605
[2022-06-20 01:16:05,975] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:16:06,158] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:17:41,027] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:17:41,060] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:17:41,060] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:17:41,060] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:17:41,060] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:17:41,093] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:17:41,115] {standard_task_runner.py:52} INFO - Started process 73744 to run task
[2022-06-20 01:17:41,125] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '507', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpb2fdzsa3', '--error-file', '/tmp/tmpbhae0qev']
[2022-06-20 01:17:41,126] {standard_task_runner.py:80} INFO - Job 507: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:17:41,277] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:17:41,480] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:17:41,506] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:17:41,517] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 01:17:41,518] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:17:41,560] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T041741, end_date=20220620T041741
[2022-06-20 01:17:41,620] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:17:41,718] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:25:14,494] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:25:14,526] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:25:14,526] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:25:14,527] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:25:14,527] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:25:14,560] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:25:14,581] {standard_task_runner.py:52} INFO - Started process 79139 to run task
[2022-06-20 01:25:14,589] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '524', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmphj22w9b0', '--error-file', '/tmp/tmpib8n7yea']
[2022-06-20 01:25:14,591] {standard_task_runner.py:80} INFO - Job 524: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:25:14,723] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:25:14,917] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:25:14,943] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:25:14,951] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 01:25:14,954] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:25:15,016] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T042514, end_date=20220620T042515
[2022-06-20 01:25:15,097] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:25:15,203] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:26:36,001] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:26:36,038] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:26:36,038] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:26:36,039] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:26:36,039] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:26:36,084] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:26:36,104] {standard_task_runner.py:52} INFO - Started process 80615 to run task
[2022-06-20 01:26:36,117] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '543', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp5wy0wma1', '--error-file', '/tmp/tmpqsgva6pw']
[2022-06-20 01:26:36,118] {standard_task_runner.py:80} INFO - Job 543: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:26:36,263] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:26:36,463] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:26:36,491] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:26:36,499] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 01:26:36,500] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:26:36,553] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T042636, end_date=20220620T042636
[2022-06-20 01:26:36,611] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:26:36,698] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:27:54,937] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:27:54,970] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:27:54,971] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:27:54,971] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:27:54,971] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:27:55,005] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:27:55,022] {standard_task_runner.py:52} INFO - Started process 82074 to run task
[2022-06-20 01:27:55,033] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '553', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpor30efzk', '--error-file', '/tmp/tmpsqpxngf7']
[2022-06-20 01:27:55,034] {standard_task_runner.py:80} INFO - Job 553: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:27:55,172] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:27:55,349] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:27:55,372] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:27:55,384] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float
                )
            , parameters: None
[2022-06-20 01:27:55,387] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:27:55,480] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T042754, end_date=20220620T042755
[2022-06-20 01:27:55,563] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:27:55,646] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:32:33,821] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:32:33,852] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:32:33,853] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:32:33,853] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:32:33,853] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:32:33,883] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:32:33,897] {standard_task_runner.py:52} INFO - Started process 84039 to run task
[2022-06-20 01:32:33,904] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '568', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpw286_g3_', '--error-file', '/tmp/tmpp1g9tb_z']
[2022-06-20 01:32:33,905] {standard_task_runner.py:80} INFO - Job 568: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:32:34,023] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:32:34,215] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:32:34,241] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:32:34,255] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30),    
                productname VARCHAR(40),    
                orderdate date,
                requireddate date,        
                lastname VARCHAR(30),    
                quantityordered int,
                priceeach float,
                buyprice float,
                orderLineNumber int
                )
            , parameters: None
[2022-06-20 01:32:34,259] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:32:34,381] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T043233, end_date=20220620T043234
[2022-06-20 01:32:34,480] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:32:34,576] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:45:10,687] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:45:10,745] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:45:10,745] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:45:10,745] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:45:10,746] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:45:10,801] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:45:10,818] {standard_task_runner.py:52} INFO - Started process 87307 to run task
[2022-06-20 01:45:10,832] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '588', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpr8isnunh', '--error-file', '/tmp/tmpd04mg0cf']
[2022-06-20 01:45:10,834] {standard_task_runner.py:80} INFO - Job 588: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:45:10,973] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:45:11,162] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:45:11,185] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:45:11,195] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 01:45:11,287] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T044510, end_date=20220620T044511
[2022-06-20 01:45:11,362] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:45:11,458] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:46:56,705] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:46:56,730] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:46:56,730] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:46:56,730] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:46:56,730] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:46:56,759] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:46:56,775] {standard_task_runner.py:52} INFO - Started process 88527 to run task
[2022-06-20 01:46:56,788] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '596', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp4etdzebo', '--error-file', '/tmp/tmpxpsvpq2r']
[2022-06-20 01:46:56,789] {standard_task_runner.py:80} INFO - Job 596: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:46:56,922] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:46:57,109] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:46:57,141] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:46:57,149] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 01:46:57,211] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T044656, end_date=20220620T044657
[2022-06-20 01:46:57,287] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:46:57,401] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:50:28,031] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:50:28,060] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:50:28,061] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:50:28,061] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:50:28,061] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:50:28,091] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:50:28,111] {standard_task_runner.py:52} INFO - Started process 89947 to run task
[2022-06-20 01:50:28,123] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '605', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpythu_72w', '--error-file', '/tmp/tmpsmvnuann']
[2022-06-20 01:50:28,124] {standard_task_runner.py:80} INFO - Job 605: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 01:50:28,263] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:50:28,459] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:50:28,492] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:50:28,500] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 01:50:28,503] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 01:50:28,613] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T045028, end_date=20220620T045028
[2022-06-20 01:50:28,696] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:50:28,780] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 02:25:22,504] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:25:22,518] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:25:22,518] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:25:22,519] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 02:25:22,519] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:25:22,538] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 02:25:22,546] {standard_task_runner.py:52} INFO - Started process 96867 to run task
[2022-06-20 02:25:22,549] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '623', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp6afhxwjh', '--error-file', '/tmp/tmpohkzqn_b']
[2022-06-20 02:25:22,550] {standard_task_runner.py:80} INFO - Job 623: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 02:25:22,617] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 02:25:22,710] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 02:25:22,724] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 02:25:22,727] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 02:25:22,728] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 02:25:22,775] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T052522, end_date=20220620T052522
[2022-06-20 02:25:22,804] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 02:25:22,901] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 02:27:31,663] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:27:31,677] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:27:31,677] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:27:31,677] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 02:27:31,677] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:27:31,694] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 02:27:31,700] {standard_task_runner.py:52} INFO - Started process 98505 to run task
[2022-06-20 02:27:31,704] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '635', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpzr6lyhuk', '--error-file', '/tmp/tmpeh96u9ig']
[2022-06-20 02:27:31,704] {standard_task_runner.py:80} INFO - Job 635: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 02:27:31,777] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 02:27:31,871] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 02:27:31,885] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 02:27:31,889] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 02:27:31,890] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 02:27:31,913] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T052731, end_date=20220620T052731
[2022-06-20 02:27:31,961] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 02:27:32,025] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 02:29:03,623] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:29:03,637] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:29:03,637] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:29:03,637] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 02:29:03,637] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:29:03,649] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 02:29:03,656] {standard_task_runner.py:52} INFO - Started process 100423 to run task
[2022-06-20 02:29:03,659] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '653', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpweysurhj', '--error-file', '/tmp/tmp7t086dqc']
[2022-06-20 02:29:03,659] {standard_task_runner.py:80} INFO - Job 653: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 02:29:03,731] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 02:29:03,834] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 02:29:03,847] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 02:29:03,854] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 02:29:03,858] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 02:29:03,878] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T052903, end_date=20220620T052903
[2022-06-20 02:29:03,911] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 02:29:04,013] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 03:25:16,377] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:25:16,392] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:25:16,393] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:25:16,393] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 03:25:16,393] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:25:16,418] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 03:25:16,427] {standard_task_runner.py:52} INFO - Started process 110723 to run task
[2022-06-20 03:25:16,430] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '673', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpegt8u_jv', '--error-file', '/tmp/tmpkg6gasue']
[2022-06-20 03:25:16,433] {standard_task_runner.py:80} INFO - Job 673: Subtask create_tables_stages.criar_Stage_Fato
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2022-06-20 03:39:03,287] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:39:03,340] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:39:03,341] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:39:03,341] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 03:39:03,341] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:39:03,373] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 03:39:03,384] {standard_task_runner.py:52} INFO - Started process 8688 to run task
[2022-06-20 03:39:03,397] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '706', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpm0u7elmp', '--error-file', '/tmp/tmp6b_k427d']
[2022-06-20 03:39:03,398] {standard_task_runner.py:80} INFO - Job 706: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 03:39:03,530] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 03:39:03,703] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 03:39:03,725] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 03:39:03,736] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 03:39:03,738] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 03:39:03,777] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T063903, end_date=20220620T063903
[2022-06-20 03:39:03,853] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 03:39:03,998] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 04:37:53,902] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 04:37:53,936] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 04:37:53,937] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 04:37:53,939] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 04:37:53,939] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 04:37:53,975] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 04:37:53,988] {standard_task_runner.py:52} INFO - Started process 19132 to run task
[2022-06-20 04:37:53,996] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '729', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpjq5umuvb', '--error-file', '/tmp/tmpy_svkp17']
[2022-06-20 04:37:54,001] {standard_task_runner.py:80} INFO - Job 729: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 04:37:54,149] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 04:37:54,348] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 04:37:54,373] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 04:37:54,382] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 04:37:54,455] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T073753, end_date=20220620T073754
[2022-06-20 04:37:54,532] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 04:37:54,618] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 05:29:33,542] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 05:29:33,573] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 05:29:33,574] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 05:29:33,574] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 05:29:33,574] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 05:29:33,603] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 05:29:33,620] {standard_task_runner.py:52} INFO - Started process 30971 to run task
[2022-06-20 05:29:33,635] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '751', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp0ewxxf7q', '--error-file', '/tmp/tmpcd83tjb3']
[2022-06-20 05:29:33,636] {standard_task_runner.py:80} INFO - Job 751: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 05:29:33,780] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 05:29:33,964] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 05:29:33,993] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 05:29:34,001] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 05:29:34,080] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T082933, end_date=20220620T082934
[2022-06-20 05:29:34,126] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 05:29:34,229] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:29:55,177] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:29:55,194] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:29:55,194] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:29:55,195] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:29:55,195] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:29:55,212] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:29:55,219] {standard_task_runner.py:52} INFO - Started process 43637 to run task
[2022-06-20 11:29:55,224] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '770', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpclo1s62r', '--error-file', '/tmp/tmpeltg5wj_']
[2022-06-20 11:29:55,225] {standard_task_runner.py:80} INFO - Job 770: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 11:29:55,291] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:29:55,382] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:29:55,396] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:29:55,401] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 11:29:55,401] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 11:29:55,434] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T142955, end_date=20220620T142955
[2022-06-20 11:29:55,479] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:29:55,559] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:33:08,935] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:33:08,950] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:33:08,950] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:33:08,950] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:33:08,950] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:33:08,967] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:33:08,974] {standard_task_runner.py:52} INFO - Started process 45601 to run task
[2022-06-20 11:33:08,980] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '787', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp5inodihd', '--error-file', '/tmp/tmplpob7m2r']
[2022-06-20 11:33:08,980] {standard_task_runner.py:80} INFO - Job 787: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 11:33:09,040] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:33:09,132] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:33:09,145] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:33:09,150] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 11:33:09,151] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 11:33:09,167] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T143308, end_date=20220620T143309
[2022-06-20 11:33:09,193] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:33:09,299] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:39:13,390] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:39:13,406] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:39:13,406] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:39:13,406] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:39:13,407] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:39:13,428] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:39:13,436] {standard_task_runner.py:52} INFO - Started process 48593 to run task
[2022-06-20 11:39:13,439] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp0kb2379b', '--error-file', '/tmp/tmph10naqfl']
[2022-06-20 11:39:13,440] {standard_task_runner.py:80} INFO - Job 5: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 11:39:13,525] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:39:13,625] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:39:13,674] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 86, in get_conn
    conn = deepcopy(self.connection or self.get_connection(conn_id))
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/models/connection.py", line 430, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `***` isn't defined
[2022-06-20 11:39:13,682] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T143913, end_date=20220620T143913
[2022-06-20 11:39:13,702] {standard_task_runner.py:92} ERROR - Failed to execute job 5 for task create_tables_stages.criar_Stage_Fato (The conn_id `***` isn't defined; 48593)
[2022-06-20 11:39:13,735] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-20 11:39:13,813] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:41:39,782] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:41:39,800] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:41:39,800] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:41:39,800] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:41:39,800] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:41:39,820] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:41:39,826] {standard_task_runner.py:52} INFO - Started process 49911 to run task
[2022-06-20 11:41:39,831] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp690_g6i9', '--error-file', '/tmp/tmpnnzf5x65']
[2022-06-20 11:41:39,831] {standard_task_runner.py:80} INFO - Job 13: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 11:41:39,892] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:41:39,995] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:41:40,043] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 86, in get_conn
    conn = deepcopy(self.connection or self.get_connection(conn_id))
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/models/connection.py", line 430, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `***` isn't defined
[2022-06-20 11:41:40,051] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T144139, end_date=20220620T144140
[2022-06-20 11:41:40,066] {standard_task_runner.py:92} ERROR - Failed to execute job 13 for task create_tables_stages.criar_Stage_Fato (The conn_id `***` isn't defined; 49911)
[2022-06-20 11:41:40,081] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-20 11:41:40,172] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:43:51,785] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:43:51,801] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:43:51,801] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:43:51,801] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:43:51,801] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:43:51,819] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:43:51,828] {standard_task_runner.py:52} INFO - Started process 51160 to run task
[2022-06-20 11:43:51,833] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpu0s7y9er', '--error-file', '/tmp/tmpf2g7eks6']
[2022-06-20 11:43:51,834] {standard_task_runner.py:80} INFO - Job 24: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 11:43:51,917] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:43:52,013] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:43:52,025] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:43:52,029] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 11:43:52,066] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T144351, end_date=20220620T144352
[2022-06-20 11:43:52,124] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:43:52,187] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:46:09,483] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:46:09,500] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:46:09,500] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:46:09,501] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:46:09,501] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:46:09,523] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:46:09,530] {standard_task_runner.py:52} INFO - Started process 52584 to run task
[2022-06-20 11:46:09,534] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpdk5926_2', '--error-file', '/tmp/tmpbuua6733']
[2022-06-20 11:46:09,534] {standard_task_runner.py:80} INFO - Job 40: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 11:46:09,606] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:46:09,708] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:46:09,720] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:46:09,726] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 11:46:09,727] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 11:46:09,775] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T144609, end_date=20220620T144609
[2022-06-20 11:46:09,832] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:46:09,898] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:08:15,769] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:08:15,788] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:08:15,788] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:08:15,788] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:08:15,788] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:08:15,807] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:08:15,814] {standard_task_runner.py:52} INFO - Started process 57359 to run task
[2022-06-20 12:08:15,819] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '58', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpr1348hfb', '--error-file', '/tmp/tmpn4mmtnyc']
[2022-06-20 12:08:15,820] {standard_task_runner.py:80} INFO - Job 58: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 12:08:15,892] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:08:15,991] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:08:16,003] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:08:16,007] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 12:08:16,007] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 12:08:16,029] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T150815, end_date=20220620T150816
[2022-06-20 12:08:16,071] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:08:16,130] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:24:55,773] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:24:55,802] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:24:55,803] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:24:55,803] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:24:55,803] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:24:55,837] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:24:55,851] {standard_task_runner.py:52} INFO - Started process 9189 to run task
[2022-06-20 12:24:55,861] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '76', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpnp_hhup2', '--error-file', '/tmp/tmp5uympxem']
[2022-06-20 12:24:55,862] {standard_task_runner.py:80} INFO - Job 76: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 12:24:55,989] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:24:56,155] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:24:56,180] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:24:56,190] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 12:24:56,192] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 12:24:56,263] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T152455, end_date=20220620T152456
[2022-06-20 12:24:56,313] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:24:56,390] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:27:37,405] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:27:37,438] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:27:37,438] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:27:37,439] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:27:37,439] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:27:37,470] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:27:37,490] {standard_task_runner.py:52} INFO - Started process 11535 to run task
[2022-06-20 12:27:37,497] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '91', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpsyy7_jnh', '--error-file', '/tmp/tmpknw5vcaf']
[2022-06-20 12:27:37,497] {standard_task_runner.py:80} INFO - Job 91: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 12:27:37,635] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:27:37,787] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:27:37,809] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:27:37,817] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 12:27:37,819] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 12:27:37,866] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T152737, end_date=20220620T152737
[2022-06-20 12:27:37,911] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:27:38,031] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:39:45,846] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:39:45,878] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:39:45,878] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:39:45,879] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:39:45,879] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:39:45,910] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:39:45,923] {standard_task_runner.py:52} INFO - Started process 14614 to run task
[2022-06-20 12:39:45,930] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '111', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpldmxjkt3', '--error-file', '/tmp/tmp16rug76j']
[2022-06-20 12:39:45,931] {standard_task_runner.py:80} INFO - Job 111: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 12:39:46,063] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:39:46,213] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:39:46,236] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:39:46,244] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 12:39:46,304] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T153945, end_date=20220620T153946
[2022-06-20 12:39:46,348] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:39:46,443] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:56:50,247] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:56:50,276] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:56:50,277] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:56:50,277] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:56:50,277] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:56:50,312] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:56:50,325] {standard_task_runner.py:52} INFO - Started process 17880 to run task
[2022-06-20 12:56:50,332] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '128', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp3l3uijqm', '--error-file', '/tmp/tmpmits3lcu']
[2022-06-20 12:56:50,333] {standard_task_runner.py:80} INFO - Job 128: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 12:56:50,453] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:56:50,619] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:56:50,641] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:56:50,657] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 12:56:50,659] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 12:56:50,719] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T155650, end_date=20220620T155650
[2022-06-20 12:56:50,790] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:56:50,880] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 13:00:04,113] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:00:04,150] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:00:04,151] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:00:04,151] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 13:00:04,151] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:00:04,188] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 13:00:04,204] {standard_task_runner.py:52} INFO - Started process 19817 to run task
[2022-06-20 13:00:04,210] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '147', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp22xyi1l_', '--error-file', '/tmp/tmpet5rju53']
[2022-06-20 13:00:04,211] {standard_task_runner.py:80} INFO - Job 147: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 13:00:04,336] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 13:00:04,538] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 13:00:04,557] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 13:00:04,565] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 13:00:04,567] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 13:00:04,629] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T160004, end_date=20220620T160004
[2022-06-20 13:00:04,666] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 13:00:04,752] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 13:45:20,623] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:45:20,655] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:45:20,656] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:45:20,656] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 13:45:20,656] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:45:20,685] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 13:45:20,701] {standard_task_runner.py:52} INFO - Started process 29111 to run task
[2022-06-20 13:45:20,708] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '166', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpi64_y1xz', '--error-file', '/tmp/tmpgrz0htl_']
[2022-06-20 13:45:20,709] {standard_task_runner.py:80} INFO - Job 166: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 13:45:20,828] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 13:45:20,999] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 13:45:21,020] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 13:45:21,031] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 13:45:21,033] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 13:45:21,091] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T164520, end_date=20220620T164521
[2022-06-20 13:45:21,165] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 13:45:21,241] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:00:10,827] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:00:10,853] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:00:10,853] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:00:10,853] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:00:10,854] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:00:10,882] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:00:10,894] {standard_task_runner.py:52} INFO - Started process 33054 to run task
[2022-06-20 14:00:10,908] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '181', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpn8oc_91c', '--error-file', '/tmp/tmp2_esjsxd']
[2022-06-20 14:00:10,909] {standard_task_runner.py:80} INFO - Job 181: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 14:00:11,031] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:00:11,376] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:00:11,408] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:00:11,432] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 14:00:11,554] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T170010, end_date=20220620T170011
[2022-06-20 14:00:11,641] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:00:11,745] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:07:57,060] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:07:57,096] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:07:57,096] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:07:57,097] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:07:57,097] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:07:57,125] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:07:57,140] {standard_task_runner.py:52} INFO - Started process 36450 to run task
[2022-06-20 14:07:57,154] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '200', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmprjubddz4', '--error-file', '/tmp/tmpu5b23yq8']
[2022-06-20 14:07:57,155] {standard_task_runner.py:80} INFO - Job 200: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 14:07:57,279] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:07:57,452] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:07:57,479] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:07:57,490] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 14:07:57,566] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T170757, end_date=20220620T170757
[2022-06-20 14:07:57,641] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:07:57,735] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:15:19,193] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:15:19,221] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:15:19,222] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:15:19,222] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:15:19,222] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:15:19,247] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:15:19,259] {standard_task_runner.py:52} INFO - Started process 39175 to run task
[2022-06-20 14:15:19,264] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '217', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmptyefvwqx', '--error-file', '/tmp/tmp22k7kc6t']
[2022-06-20 14:15:19,264] {standard_task_runner.py:80} INFO - Job 217: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 14:15:19,357] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:15:19,509] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:15:19,530] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:15:19,538] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 14:15:19,539] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 14:15:19,582] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T171519, end_date=20220620T171519
[2022-06-20 14:15:19,637] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:15:19,748] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:16:23,934] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:16:23,965] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:16:23,965] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:16:23,965] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:16:23,966] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:16:23,992] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:16:24,006] {standard_task_runner.py:52} INFO - Started process 40715 to run task
[2022-06-20 14:16:24,013] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '236', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpzxr0s0vt', '--error-file', '/tmp/tmp7169l6pr']
[2022-06-20 14:16:24,014] {standard_task_runner.py:80} INFO - Job 236: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 14:16:24,144] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:16:24,340] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:16:24,362] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:16:24,371] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 14:16:24,429] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T171623, end_date=20220620T171624
[2022-06-20 14:16:24,506] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:16:24,630] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:26:50,950] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:26:51,002] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:26:51,003] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:26:51,003] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:26:51,003] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:26:51,052] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:26:51,074] {standard_task_runner.py:52} INFO - Started process 43937 to run task
[2022-06-20 14:26:51,090] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '257', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp1m7_xkll', '--error-file', '/tmp/tmpg4jgrelg']
[2022-06-20 14:26:51,091] {standard_task_runner.py:80} INFO - Job 257: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 14:26:51,269] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:26:51,432] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:26:51,450] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:26:51,457] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 14:26:51,492] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T172650, end_date=20220620T172651
[2022-06-20 14:26:51,539] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:26:51,618] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:31:44,289] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:31:44,323] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:31:44,324] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:31:44,324] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:31:44,324] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:31:44,357] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:31:44,381] {standard_task_runner.py:52} INFO - Started process 46173 to run task
[2022-06-20 14:31:44,388] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '272', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmphw7zb6be', '--error-file', '/tmp/tmpw0f4_p16']
[2022-06-20 14:31:44,390] {standard_task_runner.py:80} INFO - Job 272: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 14:31:44,523] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:31:44,729] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:31:44,752] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:31:44,758] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 14:31:44,847] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T173144, end_date=20220620T173144
[2022-06-20 14:31:44,931] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:31:45,030] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:34:11,264] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:34:11,292] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:34:11,293] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:34:11,293] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:34:11,293] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:34:11,317] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:34:11,330] {standard_task_runner.py:52} INFO - Started process 47927 to run task
[2022-06-20 14:34:11,336] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '286', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpl5kj4ju3', '--error-file', '/tmp/tmpzp0_7ovq']
[2022-06-20 14:34:11,337] {standard_task_runner.py:80} INFO - Job 286: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 14:34:11,451] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:34:11,602] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:34:11,628] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:34:11,647] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 14:34:11,709] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T173411, end_date=20220620T173411
[2022-06-20 14:34:11,795] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:34:11,973] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:37:53,118] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:37:53,159] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:37:53,159] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:37:53,159] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:37:53,159] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:37:53,200] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:37:53,216] {standard_task_runner.py:52} INFO - Started process 50688 to run task
[2022-06-20 14:37:53,232] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '307', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmplcy_7eg2', '--error-file', '/tmp/tmpg9y4kf9a']
[2022-06-20 14:37:53,233] {standard_task_runner.py:80} INFO - Job 307: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 14:37:53,371] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:37:53,535] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:37:53,556] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:37:53,566] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 14:37:53,609] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T173753, end_date=20220620T173753
[2022-06-20 14:37:53,679] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:37:53,774] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:46:36,246] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:46:36,275] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:46:36,275] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:46:36,276] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:46:36,276] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:46:36,308] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:46:36,322] {standard_task_runner.py:52} INFO - Started process 54140 to run task
[2022-06-20 14:46:36,334] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '323', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp5v5mxrmi', '--error-file', '/tmp/tmpt78ewwfm']
[2022-06-20 14:46:36,335] {standard_task_runner.py:80} INFO - Job 323: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 14:46:36,473] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:46:36,649] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:46:36,672] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:46:36,680] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 14:46:36,784] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T174636, end_date=20220620T174636
[2022-06-20 14:46:36,836] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:46:36,951] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:33:19,957] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:33:19,982] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:33:19,982] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:33:19,982] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:33:19,982] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:33:20,013] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:33:20,029] {standard_task_runner.py:52} INFO - Started process 60621 to run task
[2022-06-20 15:33:20,036] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '340', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmple0_s87t', '--error-file', '/tmp/tmpgb248qwo']
[2022-06-20 15:33:20,037] {standard_task_runner.py:80} INFO - Job 340: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 15:33:20,161] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:33:20,355] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:33:20,374] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:33:20,380] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 15:33:20,458] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T183319, end_date=20220620T183320
[2022-06-20 15:33:20,530] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:33:20,631] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:35:25,169] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:35:25,200] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:35:25,200] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:35:25,200] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:35:25,200] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:35:25,228] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:35:25,244] {standard_task_runner.py:52} INFO - Started process 62235 to run task
[2022-06-20 15:35:25,256] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '358', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpfpeo_4yh', '--error-file', '/tmp/tmppl42a__g']
[2022-06-20 15:35:25,257] {standard_task_runner.py:80} INFO - Job 358: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 15:35:25,386] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:35:25,562] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:35:25,583] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:35:25,592] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 15:35:25,632] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T183525, end_date=20220620T183525
[2022-06-20 15:35:25,679] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:35:25,802] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:41:45,741] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:41:45,797] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:41:45,797] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:41:45,797] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:41:45,798] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:41:45,835] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:41:45,850] {standard_task_runner.py:52} INFO - Started process 64664 to run task
[2022-06-20 15:41:45,859] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '376', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpg7q5un2b', '--error-file', '/tmp/tmp61rp40u6']
[2022-06-20 15:41:45,860] {standard_task_runner.py:80} INFO - Job 376: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 15:41:46,009] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:41:46,236] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:41:46,263] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:41:46,273] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 15:41:46,277] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 15:41:46,349] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T184145, end_date=20220620T184146
[2022-06-20 15:41:46,415] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:41:46,545] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:51:27,435] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:51:27,468] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:51:27,469] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:51:27,469] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:51:27,469] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:51:27,501] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:51:27,517] {standard_task_runner.py:52} INFO - Started process 67480 to run task
[2022-06-20 15:51:27,524] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '393', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp6bzb9wyq', '--error-file', '/tmp/tmpxr7of713']
[2022-06-20 15:51:27,525] {standard_task_runner.py:80} INFO - Job 393: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 15:51:27,673] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:51:27,895] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:51:27,918] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:51:27,926] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 15:51:27,981] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T185127, end_date=20220620T185127
[2022-06-20 15:51:28,066] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:51:28,183] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:09:22,410] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:09:22,466] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:09:22,467] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:09:22,467] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:09:22,467] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:09:22,514] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:09:22,531] {standard_task_runner.py:52} INFO - Started process 74396 to run task
[2022-06-20 16:09:22,542] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '417', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpcbasyp69', '--error-file', '/tmp/tmpoabq9asf']
[2022-06-20 16:09:22,543] {standard_task_runner.py:80} INFO - Job 417: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 16:09:22,702] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:09:22,941] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:09:22,981] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:09:22,993] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 16:09:23,081] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T190922, end_date=20220620T190923
[2022-06-20 16:09:23,134] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:09:23,288] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:13:44,932] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:13:44,953] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:13:44,953] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:13:44,953] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:13:44,953] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:13:44,981] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:13:44,993] {standard_task_runner.py:52} INFO - Started process 76406 to run task
[2022-06-20 16:13:44,999] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '432', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpqzljwepe', '--error-file', '/tmp/tmplwrsmqs9']
[2022-06-20 16:13:45,000] {standard_task_runner.py:80} INFO - Job 432: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 16:13:45,100] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:13:45,277] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:13:45,300] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:13:45,314] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 16:13:45,353] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T191344, end_date=20220620T191345
[2022-06-20 16:13:45,414] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:13:45,569] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:15:24,754] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:15:24,800] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:15:24,801] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:15:24,801] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:15:24,801] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:15:24,844] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:15:24,858] {standard_task_runner.py:52} INFO - Started process 77999 to run task
[2022-06-20 16:15:24,867] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '454', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp567djwi5', '--error-file', '/tmp/tmpw4m7ymik']
[2022-06-20 16:15:24,869] {standard_task_runner.py:80} INFO - Job 454: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 16:15:25,017] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:15:25,184] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:15:25,204] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:15:25,213] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 16:15:25,215] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 16:15:25,246] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T191524, end_date=20220620T191525
[2022-06-20 16:15:25,322] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:15:25,410] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:16:00,502] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:16:00,522] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:16:00,522] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:16:00,522] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:16:00,522] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:16:00,546] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:16:00,556] {standard_task_runner.py:52} INFO - Started process 78864 to run task
[2022-06-20 16:16:00,561] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '461', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpdn8vwu8e', '--error-file', '/tmp/tmpky_ls0wo']
[2022-06-20 16:16:00,562] {standard_task_runner.py:80} INFO - Job 461: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 16:16:00,668] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:16:00,817] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:16:00,835] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:16:00,842] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL,
                orderLineNumber int NOT NULL
                )
            , parameters: None
[2022-06-20 16:16:00,915] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T191600, end_date=20220620T191600
[2022-06-20 16:16:00,975] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:16:01,059] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:29:36,639] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:29:36,666] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:29:36,667] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:29:36,667] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:29:36,667] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:29:36,692] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:29:36,705] {standard_task_runner.py:52} INFO - Started process 81819 to run task
[2022-06-20 16:29:36,712] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '479', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp7d9gd8m_', '--error-file', '/tmp/tmpu098y3d8']
[2022-06-20 16:29:36,713] {standard_task_runner.py:80} INFO - Job 479: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 16:29:36,866] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:29:37,059] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:29:37,079] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:29:37,086] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL
                )
            , parameters: None
[2022-06-20 16:29:37,088] {postgres.py:94} INFO - NOTICE:  relation "stg_fato" already exists, skipping

[2022-06-20 16:29:37,136] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T192936, end_date=20220620T192937
[2022-06-20 16:29:37,206] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:29:37,290] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:31:51,736] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:31:51,766] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:31:51,766] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:31:51,766] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:31:51,766] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:31:51,797] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Fato> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:31:51,812] {standard_task_runner.py:52} INFO - Started process 83691 to run task
[2022-06-20 16:31:51,822] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Fato', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '499', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp4lk31e3c', '--error-file', '/tmp/tmphg6e3g91']
[2022-06-20 16:31:51,824] {standard_task_runner.py:80} INFO - Job 499: Subtask create_tables_stages.criar_Stage_Fato
[2022-06-20 16:31:51,970] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Fato scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:31:52,144] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Fato
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:31:52,172] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:31:52,181] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_fato (
                id_fato SERIAL PRIMARY KEY,     
                customername VARCHAR(30) NOT NULL,    
                productname VARCHAR(40) NOT NULL,    
                orderdate date NOT NULL,
                requireddate date NOT NULL,        
                lastname VARCHAR(30) NOT NULL,    
                quantityordered int NOT NULL,
                priceeach float NOT NULL,
                buyprice float NOT NULL
                )
            , parameters: None
[2022-06-20 16:31:52,260] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Fato, execution_date=20220619T000000, start_date=20220620T193151, end_date=20220620T193152
[2022-06-20 16:31:52,316] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:31:52,398] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
