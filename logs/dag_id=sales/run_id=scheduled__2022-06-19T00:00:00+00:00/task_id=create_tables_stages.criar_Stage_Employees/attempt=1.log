[2022-06-19 23:39:47,072] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:39:47,105] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:39:47,105] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:39:47,106] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-19 23:39:47,106] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:39:47,145] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-19 23:39:47,159] {standard_task_runner.py:52} INFO - Started process 28193 to run task
[2022-06-19 23:39:47,166] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '197', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp04baeazl', '--error-file', '/tmp/tmpdjdkd9le']
[2022-06-19 23:39:47,167] {standard_task_runner.py:80} INFO - Job 197: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-19 23:39:47,309] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-19 23:39:47,472] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-19 23:39:47,499] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-19 23:39:47,508] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-19 23:39:47,510] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-19 23:39:47,549] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T023947, end_date=20220620T023947
[2022-06-19 23:39:47,627] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-19 23:39:47,729] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-19 23:42:09,882] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:42:09,915] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:42:09,915] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:42:09,916] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-19 23:42:09,916] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:42:09,954] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-19 23:42:09,969] {standard_task_runner.py:52} INFO - Started process 30276 to run task
[2022-06-19 23:42:09,977] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '215', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpw1umiih1', '--error-file', '/tmp/tmpluf0ml2j']
[2022-06-19 23:42:09,978] {standard_task_runner.py:80} INFO - Job 215: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-19 23:42:10,109] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-19 23:42:10,397] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-19 23:42:10,417] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-19 23:42:10,426] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-19 23:42:10,428] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-19 23:42:10,616] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T024209, end_date=20220620T024210
[2022-06-19 23:42:10,675] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-19 23:42:10,767] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-19 23:48:41,416] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:48:41,451] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-19 23:48:41,453] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:48:41,453] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-19 23:48:41,453] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-19 23:48:41,490] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-19 23:48:41,503] {standard_task_runner.py:52} INFO - Started process 32825 to run task
[2022-06-19 23:48:41,509] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '225', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp137okvfz', '--error-file', '/tmp/tmplw71pk5v']
[2022-06-19 23:48:41,510] {standard_task_runner.py:80} INFO - Job 225: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-19 23:48:41,607] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-19 23:48:41,764] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-19 23:48:41,787] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-19 23:48:41,798] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-19 23:48:41,800] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-19 23:48:41,832] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T024841, end_date=20220620T024841
[2022-06-19 23:48:41,882] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-19 23:48:42,017] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:03:58,142] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:03:58,170] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:03:58,170] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:03:58,171] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:03:58,171] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:03:58,199] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:03:58,216] {standard_task_runner.py:52} INFO - Started process 35962 to run task
[2022-06-20 00:03:58,223] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '242', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp4j2i8qkv', '--error-file', '/tmp/tmp8jjigqej']
[2022-06-20 00:03:58,224] {standard_task_runner.py:80} INFO - Job 242: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:03:58,352] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:03:58,509] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:03:58,540] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:03:58,575] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:03:58,579] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:03:58,614] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T030358, end_date=20220620T030358
[2022-06-20 00:03:58,682] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:03:58,784] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:05:08,348] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:05:08,372] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:05:08,372] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:05:08,373] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:05:08,373] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:05:08,411] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:05:08,426] {standard_task_runner.py:52} INFO - Started process 37294 to run task
[2022-06-20 00:05:08,434] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '258', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpastcpu7s', '--error-file', '/tmp/tmpah46nmfs']
[2022-06-20 00:05:08,435] {standard_task_runner.py:80} INFO - Job 258: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:05:08,583] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:05:08,793] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:05:08,820] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:05:08,829] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:05:08,831] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:05:08,865] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T030508, end_date=20220620T030508
[2022-06-20 00:05:08,931] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:05:09,067] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:06:58,953] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:06:58,975] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:06:58,976] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:06:58,976] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:06:58,976] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:06:59,003] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:06:59,015] {standard_task_runner.py:52} INFO - Started process 38870 to run task
[2022-06-20 00:06:59,021] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '268', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp6cwq9cov', '--error-file', '/tmp/tmpn4x9ecxb']
[2022-06-20 00:06:59,021] {standard_task_runner.py:80} INFO - Job 268: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:06:59,125] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:06:59,270] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:06:59,307] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:06:59,315] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:06:59,316] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:06:59,358] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T030658, end_date=20220620T030659
[2022-06-20 00:06:59,395] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:06:59,485] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:25:33,042] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:25:33,067] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:25:33,068] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:25:33,068] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:25:33,068] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:25:33,094] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:25:33,106] {standard_task_runner.py:52} INFO - Started process 42828 to run task
[2022-06-20 00:25:33,112] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '285', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp85gb1boh', '--error-file', '/tmp/tmpnb3rvyc8']
[2022-06-20 00:25:33,113] {standard_task_runner.py:80} INFO - Job 285: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:25:33,214] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:25:33,360] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:25:33,385] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:25:33,391] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:25:33,392] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:25:33,434] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T032533, end_date=20220620T032533
[2022-06-20 00:25:33,486] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:25:33,580] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:26:28,628] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:26:28,662] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:26:28,663] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:26:28,663] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:26:28,663] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:26:28,696] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:26:28,715] {standard_task_runner.py:52} INFO - Started process 44086 to run task
[2022-06-20 00:26:28,723] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '299', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpyqm3usdn', '--error-file', '/tmp/tmp12m1r_2u']
[2022-06-20 00:26:28,723] {standard_task_runner.py:80} INFO - Job 299: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:26:28,848] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:26:29,030] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:26:29,075] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:26:29,083] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:26:29,085] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:26:29,122] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T032628, end_date=20220620T032629
[2022-06-20 00:26:29,181] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:26:29,309] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:29:31,877] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:29:31,908] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:29:31,909] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:29:31,909] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:29:31,909] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:29:31,937] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:29:31,951] {standard_task_runner.py:52} INFO - Started process 45863 to run task
[2022-06-20 00:29:31,957] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '317', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpf8je7bam', '--error-file', '/tmp/tmpou7xui0_']
[2022-06-20 00:29:31,959] {standard_task_runner.py:80} INFO - Job 317: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:29:32,069] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:29:32,218] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:29:32,240] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:29:32,248] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:29:32,251] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:29:32,283] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T032931, end_date=20220620T032932
[2022-06-20 00:29:32,334] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:29:32,419] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:30:44,873] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:30:44,893] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:30:44,893] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:30:44,893] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:30:44,893] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:30:44,914] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:30:44,927] {standard_task_runner.py:52} INFO - Started process 47248 to run task
[2022-06-20 00:30:44,933] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '329', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpeunjhmwv', '--error-file', '/tmp/tmp7huuj5h7']
[2022-06-20 00:30:44,934] {standard_task_runner.py:80} INFO - Job 329: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:30:45,024] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:30:45,161] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:30:45,184] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:30:45,190] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:30:45,191] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:30:45,219] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T033044, end_date=20220620T033045
[2022-06-20 00:30:45,265] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:30:45,380] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:32:32,856] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:32:32,886] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:32:32,886] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:32:32,886] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:32:32,886] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:32:32,908] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:32:32,919] {standard_task_runner.py:52} INFO - Started process 48929 to run task
[2022-06-20 00:32:32,925] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '344', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpwjqn9qsq', '--error-file', '/tmp/tmpkitsvhdc']
[2022-06-20 00:32:32,926] {standard_task_runner.py:80} INFO - Job 344: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:32:33,018] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:32:33,188] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:32:33,215] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:32:33,226] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:32:33,228] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:32:33,267] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T033232, end_date=20220620T033233
[2022-06-20 00:32:33,337] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:32:33,474] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:34:14,535] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:34:14,568] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:34:14,569] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:34:14,569] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:34:14,569] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:34:14,609] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:34:14,628] {standard_task_runner.py:52} INFO - Started process 50559 to run task
[2022-06-20 00:34:14,636] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '362', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpmlwaua8s', '--error-file', '/tmp/tmpehcgbq_p']
[2022-06-20 00:34:14,637] {standard_task_runner.py:80} INFO - Job 362: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:34:14,761] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:34:14,934] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:34:14,967] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:34:14,977] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:34:14,979] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:34:15,018] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T033414, end_date=20220620T033415
[2022-06-20 00:34:15,095] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:34:15,182] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:46:08,299] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:46:08,334] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:46:08,335] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:46:08,335] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:46:08,335] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:46:08,367] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:46:08,382] {standard_task_runner.py:52} INFO - Started process 53725 to run task
[2022-06-20 00:46:08,390] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '378', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp7j_dng3g', '--error-file', '/tmp/tmpqfhf_v9a']
[2022-06-20 00:46:08,391] {standard_task_runner.py:80} INFO - Job 378: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:46:08,527] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:46:08,729] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:46:08,754] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:46:08,763] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:46:08,764] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:46:08,795] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T034608, end_date=20220620T034608
[2022-06-20 00:46:08,843] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:46:08,939] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:51:27,887] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:51:27,928] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:51:27,928] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:51:27,928] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:51:27,929] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:51:27,961] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:51:27,986] {standard_task_runner.py:52} INFO - Started process 56250 to run task
[2022-06-20 00:51:28,001] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '392', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpbv_ne9kn', '--error-file', '/tmp/tmps114rmd5']
[2022-06-20 00:51:28,002] {standard_task_runner.py:80} INFO - Job 392: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:51:28,148] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:51:28,351] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:51:28,382] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:51:28,391] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:51:28,393] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:51:28,462] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T035127, end_date=20220620T035128
[2022-06-20 00:51:28,577] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:51:28,765] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 00:56:50,906] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:56:50,961] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 00:56:50,961] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:56:50,961] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 00:56:50,961] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 00:56:51,005] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 00:56:51,023] {standard_task_runner.py:52} INFO - Started process 58398 to run task
[2022-06-20 00:56:51,035] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '410', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpaq1ynga4', '--error-file', '/tmp/tmplxhhu40j']
[2022-06-20 00:56:51,036] {standard_task_runner.py:80} INFO - Job 410: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 00:56:51,210] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 00:56:51,394] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 00:56:51,423] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 00:56:51,432] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 00:56:51,438] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 00:56:51,472] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T035650, end_date=20220620T035651
[2022-06-20 00:56:51,528] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 00:56:51,667] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:00:51,477] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:00:51,500] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:00:51,500] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:00:51,500] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:00:51,501] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:00:51,529] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:00:51,544] {standard_task_runner.py:52} INFO - Started process 60342 to run task
[2022-06-20 01:00:51,549] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '425', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpoj_r0t96', '--error-file', '/tmp/tmpze6vf5uf']
[2022-06-20 01:00:51,550] {standard_task_runner.py:80} INFO - Job 425: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:00:51,662] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:00:51,857] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:00:51,883] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:00:51,894] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 01:00:51,897] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 01:00:51,933] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T040051, end_date=20220620T040051
[2022-06-20 01:00:52,004] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:00:52,208] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:03:16,774] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:03:16,804] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:03:16,805] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:03:16,805] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:03:16,805] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:03:16,835] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:03:16,850] {standard_task_runner.py:52} INFO - Started process 62541 to run task
[2022-06-20 01:03:16,856] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '442', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpcvh8jaee', '--error-file', '/tmp/tmpj3pj0pee']
[2022-06-20 01:03:16,857] {standard_task_runner.py:80} INFO - Job 442: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:03:17,034] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:03:17,311] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:03:17,340] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:03:17,351] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 01:03:17,354] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 01:03:17,498] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T040316, end_date=20220620T040317
[2022-06-20 01:03:17,558] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:03:17,662] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:04:37,929] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:04:37,956] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:04:37,956] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:04:37,957] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:04:37,957] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:04:37,983] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:04:37,996] {standard_task_runner.py:52} INFO - Started process 64159 to run task
[2022-06-20 01:04:38,004] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '458', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp8ge8raao', '--error-file', '/tmp/tmp0v534_vm']
[2022-06-20 01:04:38,005] {standard_task_runner.py:80} INFO - Job 458: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:04:38,128] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:04:38,335] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:04:38,362] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:04:38,374] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 01:04:38,375] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 01:04:38,411] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T040437, end_date=20220620T040438
[2022-06-20 01:04:38,497] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:04:38,677] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:10:59,525] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:10:59,560] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:10:59,560] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:10:59,560] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:10:59,560] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:10:59,591] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:10:59,606] {standard_task_runner.py:52} INFO - Started process 68790 to run task
[2022-06-20 01:10:59,612] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '473', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp1fmwiogq', '--error-file', '/tmp/tmp3yiymzv9']
[2022-06-20 01:10:59,613] {standard_task_runner.py:80} INFO - Job 473: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:10:59,735] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:10:59,991] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:11:00,024] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:11:00,038] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 01:11:00,041] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 01:11:00,085] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T041059, end_date=20220620T041100
[2022-06-20 01:11:00,196] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:11:00,388] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:16:04,777] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:16:04,853] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:16:04,853] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:16:04,854] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:16:04,854] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:16:04,911] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:16:04,928] {standard_task_runner.py:52} INFO - Started process 71939 to run task
[2022-06-20 01:16:04,936] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '487', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp5mz3ole7', '--error-file', '/tmp/tmpq17l1ng4']
[2022-06-20 01:16:04,937] {standard_task_runner.py:80} INFO - Job 487: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:16:05,069] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:16:05,493] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:16:05,571] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:16:05,582] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 01:16:05,584] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 01:16:05,642] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T041604, end_date=20220620T041605
[2022-06-20 01:16:05,804] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:16:05,957] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:17:40,868] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:17:40,893] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:17:40,893] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:17:40,893] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:17:40,893] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:17:40,927] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:17:40,941] {standard_task_runner.py:52} INFO - Started process 73728 to run task
[2022-06-20 01:17:40,948] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '505', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpmvqpfhye', '--error-file', '/tmp/tmp15oneagc']
[2022-06-20 01:17:40,949] {standard_task_runner.py:80} INFO - Job 505: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:17:41,075] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:17:41,268] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:17:41,300] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:17:41,309] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 01:17:41,311] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 01:17:41,372] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T041740, end_date=20220620T041741
[2022-06-20 01:17:41,441] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:17:41,555] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:25:14,329] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:25:14,357] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:25:14,358] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:25:14,358] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:25:14,358] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:25:14,389] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:25:14,403] {standard_task_runner.py:52} INFO - Started process 79123 to run task
[2022-06-20 01:25:14,411] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '522', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpfgi4s1o3', '--error-file', '/tmp/tmpt3uqkl9x']
[2022-06-20 01:25:14,411] {standard_task_runner.py:80} INFO - Job 522: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:25:14,524] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:25:14,732] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:25:14,755] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:25:14,766] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 01:25:14,767] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 01:25:14,803] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T042514, end_date=20220620T042514
[2022-06-20 01:25:14,869] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:25:15,013] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:26:35,829] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:26:35,857] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:26:35,857] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:26:35,857] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:26:35,858] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:26:35,886] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:26:35,900] {standard_task_runner.py:52} INFO - Started process 80597 to run task
[2022-06-20 01:26:35,909] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '541', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp5astnzpx', '--error-file', '/tmp/tmpjv5rfwqa']
[2022-06-20 01:26:35,910] {standard_task_runner.py:80} INFO - Job 541: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:26:36,048] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:26:36,253] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:26:36,283] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:26:36,300] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 01:26:36,303] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 01:26:36,353] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T042635, end_date=20220620T042636
[2022-06-20 01:26:36,445] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:26:36,550] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:27:54,637] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:27:54,667] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:27:54,667] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:27:54,667] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:27:54,667] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:27:54,717] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:27:54,734] {standard_task_runner.py:52} INFO - Started process 82040 to run task
[2022-06-20 01:27:54,743] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '550', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpgy28w8yz', '--error-file', '/tmp/tmpb9mc790w']
[2022-06-20 01:27:54,744] {standard_task_runner.py:80} INFO - Job 550: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:27:54,914] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:27:55,100] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:27:55,120] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:27:55,129] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 01:27:55,130] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 01:27:55,205] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T042754, end_date=20220620T042755
[2022-06-20 01:27:55,278] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:27:55,396] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:32:33,903] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:32:33,932] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:32:33,932] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:32:33,932] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:32:33,932] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:32:33,959] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:32:33,974] {standard_task_runner.py:52} INFO - Started process 84046 to run task
[2022-06-20 01:32:33,980] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '569', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpxxzquld2', '--error-file', '/tmp/tmpp8qrdv7h']
[2022-06-20 01:32:33,981] {standard_task_runner.py:80} INFO - Job 569: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:32:34,109] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:32:34,319] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:32:34,346] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:32:34,355] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30),
                firstname VARCHAR(30),
                email VARCHAR (40),
                jobtitle VARCHAR(30)
                )
            , parameters: None
[2022-06-20 01:32:34,357] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 01:32:34,411] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T043233, end_date=20220620T043234
[2022-06-20 01:32:34,480] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:32:34,621] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:45:10,438] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:45:10,463] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:45:10,463] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:45:10,463] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:45:10,463] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:45:10,490] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:45:10,505] {standard_task_runner.py:52} INFO - Started process 87270 to run task
[2022-06-20 01:45:10,511] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '587', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpqtx8tgnf', '--error-file', '/tmp/tmpf7n6e8lt']
[2022-06-20 01:45:10,512] {standard_task_runner.py:80} INFO - Job 587: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:45:10,630] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:45:10,869] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:45:10,898] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:45:10,908] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NUL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 01:45:10,910] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 193, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 217, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "NUL"
LINE 5:                 email VARCHAR (40) NOT NUL,
                                               ^

[2022-06-20 01:45:10,949] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T044510, end_date=20220620T044510
[2022-06-20 01:45:10,990] {standard_task_runner.py:92} ERROR - Failed to execute job 587 for task create_tables_stages.criar_Stage_Employees (syntax error at or near "NUL"
LINE 5:                 email VARCHAR (40) NOT NUL,
                                               ^
; 87270)
[2022-06-20 01:45:11,051] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-20 01:45:11,191] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:46:56,875] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:46:56,907] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:46:56,907] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:46:56,907] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:46:56,907] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:46:56,941] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:46:56,960] {standard_task_runner.py:52} INFO - Started process 88544 to run task
[2022-06-20 01:46:56,966] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '597', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmps80u29f5', '--error-file', '/tmp/tmp22h0327v']
[2022-06-20 01:46:56,967] {standard_task_runner.py:80} INFO - Job 597: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:46:57,114] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:46:57,296] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:46:57,319] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:46:57,330] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NUL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 01:46:57,333] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 193, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 217, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "NUL"
LINE 5:                 email VARCHAR (40) NOT NUL,
                                               ^

[2022-06-20 01:46:57,355] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T044656, end_date=20220620T044657
[2022-06-20 01:46:57,383] {standard_task_runner.py:92} ERROR - Failed to execute job 597 for task create_tables_stages.criar_Stage_Employees (syntax error at or near "NUL"
LINE 5:                 email VARCHAR (40) NOT NUL,
                                               ^
; 88544)
[2022-06-20 01:46:57,426] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-20 01:46:57,603] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 01:50:28,113] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:50:28,148] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 01:50:28,149] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:50:28,149] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 01:50:28,149] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 01:50:28,181] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 01:50:28,202] {standard_task_runner.py:52} INFO - Started process 89961 to run task
[2022-06-20 01:50:28,211] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '606', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpsuqlfoye', '--error-file', '/tmp/tmpy0ne3b_r']
[2022-06-20 01:50:28,212] {standard_task_runner.py:80} INFO - Job 606: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 01:50:28,355] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 01:50:28,573] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 01:50:28,599] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 01:50:28,606] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 01:50:28,646] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T045028, end_date=20220620T045028
[2022-06-20 01:50:28,712] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 01:50:28,827] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 02:25:22,403] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:25:22,419] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:25:22,419] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:25:22,419] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 02:25:22,419] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:25:22,433] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 02:25:22,439] {standard_task_runner.py:52} INFO - Started process 96855 to run task
[2022-06-20 02:25:22,442] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '621', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp19yidwf0', '--error-file', '/tmp/tmpaqldqhkk']
[2022-06-20 02:25:22,442] {standard_task_runner.py:80} INFO - Job 621: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 02:25:22,505] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 02:25:22,620] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 02:25:22,635] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 02:25:22,640] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 02:25:22,641] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 02:25:22,657] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T052522, end_date=20220620T052522
[2022-06-20 02:25:22,694] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 02:25:22,773] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 02:27:31,756] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:27:31,770] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:27:31,770] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:27:31,770] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 02:27:31,770] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:27:31,784] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 02:27:31,791] {standard_task_runner.py:52} INFO - Started process 98524 to run task
[2022-06-20 02:27:31,796] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '636', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpn42e18ac', '--error-file', '/tmp/tmpehyfo1qj']
[2022-06-20 02:27:31,797] {standard_task_runner.py:80} INFO - Job 636: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 02:27:31,874] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 02:27:31,964] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 02:27:31,975] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 02:27:31,979] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 02:27:31,980] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 02:27:32,027] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T052731, end_date=20220620T052732
[2022-06-20 02:27:32,053] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 02:27:32,107] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 02:29:03,666] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:29:03,680] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 02:29:03,680] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:29:03,680] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 02:29:03,680] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 02:29:03,695] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 02:29:03,702] {standard_task_runner.py:52} INFO - Started process 100427 to run task
[2022-06-20 02:29:03,707] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '652', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp9zfd25pz', '--error-file', '/tmp/tmpzgbc8bnc']
[2022-06-20 02:29:03,708] {standard_task_runner.py:80} INFO - Job 652: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 02:29:03,781] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 02:29:03,880] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 02:29:03,899] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 02:29:03,905] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 02:29:03,906] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 02:29:03,946] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T052903, end_date=20220620T052903
[2022-06-20 02:29:03,999] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 02:29:04,095] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 03:25:16,486] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:25:16,505] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:25:16,505] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:25:16,505] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 03:25:16,505] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:25:16,524] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 03:25:16,532] {standard_task_runner.py:52} INFO - Started process 110739 to run task
[2022-06-20 03:25:16,540] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '671', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpijfcw11r', '--error-file', '/tmp/tmpwmejgfvx']
[2022-06-20 03:25:16,540] {standard_task_runner.py:80} INFO - Job 671: Subtask create_tables_stages.criar_Stage_Employees
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [2022-06-20 03:39:03,055] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:39:03,096] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 03:39:03,097] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:39:03,097] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 03:39:03,097] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 03:39:03,150] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 03:39:03,169] {standard_task_runner.py:52} INFO - Started process 8670 to run task
[2022-06-20 03:39:03,187] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '704', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp8fga68ap', '--error-file', '/tmp/tmpwk4chj8p']
[2022-06-20 03:39:03,187] {standard_task_runner.py:80} INFO - Job 704: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 03:39:03,327] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 03:39:03,525] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 03:39:03,549] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 03:39:03,564] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 03:39:03,566] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 03:39:03,638] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T063903, end_date=20220620T063903
[2022-06-20 03:39:03,717] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 03:39:03,864] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 04:37:53,464] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 04:37:53,504] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 04:37:53,504] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 04:37:53,505] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 04:37:53,505] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 04:37:53,537] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 04:37:53,551] {standard_task_runner.py:52} INFO - Started process 19091 to run task
[2022-06-20 04:37:53,557] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '725', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp83bx35nh', '--error-file', '/tmp/tmpxexnbxxt']
[2022-06-20 04:37:53,558] {standard_task_runner.py:80} INFO - Job 725: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 04:37:53,706] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 04:37:53,871] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 04:37:53,912] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 04:37:53,929] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                id_emp SERIAL PRIMARY KEY,                     
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 04:37:53,988] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T073753, end_date=20220620T073753
[2022-06-20 04:37:54,056] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 04:37:54,172] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 05:29:33,627] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 05:29:33,662] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 05:29:33,662] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 05:29:33,662] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 05:29:33,662] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 05:29:33,698] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 05:29:33,716] {standard_task_runner.py:52} INFO - Started process 30982 to run task
[2022-06-20 05:29:33,723] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '752', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpd1j0um9b', '--error-file', '/tmp/tmpjk1g9e0c']
[2022-06-20 05:29:33,724] {standard_task_runner.py:80} INFO - Job 752: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 05:29:33,849] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 05:29:34,042] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 05:29:34,064] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 05:29:34,076] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 05:29:34,149] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T082933, end_date=20220620T082934
[2022-06-20 05:29:34,224] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 05:29:34,322] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:29:55,129] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:29:55,146] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:29:55,146] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:29:55,147] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:29:55,147] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:29:55,165] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:29:55,172] {standard_task_runner.py:52} INFO - Started process 43628 to run task
[2022-06-20 11:29:55,179] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '769', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpqz8td6u0', '--error-file', '/tmp/tmp6vlg70hd']
[2022-06-20 11:29:55,180] {standard_task_runner.py:80} INFO - Job 769: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 11:29:55,243] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:29:55,354] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:29:55,367] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:29:55,373] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 11:29:55,374] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 11:29:55,418] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T142955, end_date=20220620T142955
[2022-06-20 11:29:55,470] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:29:55,524] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:33:08,978] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:33:08,997] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:33:08,997] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:33:08,997] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:33:08,997] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:33:09,015] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:33:09,022] {standard_task_runner.py:52} INFO - Started process 45611 to run task
[2022-06-20 11:33:09,028] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '788', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp_msjbnio', '--error-file', '/tmp/tmpnhrigjty']
[2022-06-20 11:33:09,029] {standard_task_runner.py:80} INFO - Job 788: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 11:33:09,096] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:33:09,191] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:33:09,203] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:33:09,208] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 11:33:09,210] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 11:33:09,302] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T143308, end_date=20220620T143309
[2022-06-20 11:33:09,362] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:33:09,419] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:39:13,440] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:39:13,458] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:39:13,458] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:39:13,459] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:39:13,459] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:39:13,481] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:39:13,488] {standard_task_runner.py:52} INFO - Started process 48605 to run task
[2022-06-20 11:39:13,492] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpbu5zkhog', '--error-file', '/tmp/tmp0uoozk5h']
[2022-06-20 11:39:13,493] {standard_task_runner.py:80} INFO - Job 4: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 11:39:13,575] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:39:13,679] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:39:13,719] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 86, in get_conn
    conn = deepcopy(self.connection or self.get_connection(conn_id))
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/models/connection.py", line 430, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `***` isn't defined
[2022-06-20 11:39:13,726] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T143913, end_date=20220620T143913
[2022-06-20 11:39:13,748] {standard_task_runner.py:92} ERROR - Failed to execute job 4 for task create_tables_stages.criar_Stage_Employees (The conn_id `***` isn't defined; 48605)
[2022-06-20 11:39:13,789] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-20 11:39:13,864] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:41:39,880] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:41:39,895] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:41:39,895] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:41:39,895] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:41:39,895] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:41:39,910] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:41:39,916] {standard_task_runner.py:52} INFO - Started process 49921 to run task
[2022-06-20 11:41:39,920] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpajab55jm', '--error-file', '/tmp/tmpcxzsvm8s']
[2022-06-20 11:41:39,920] {standard_task_runner.py:80} INFO - Job 14: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 11:41:39,989] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:41:40,101] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:41:40,175] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 86, in get_conn
    conn = deepcopy(self.connection or self.get_connection(conn_id))
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/models/connection.py", line 430, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `***` isn't defined
[2022-06-20 11:41:40,183] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T144139, end_date=20220620T144140
[2022-06-20 11:41:40,201] {standard_task_runner.py:92} ERROR - Failed to execute job 14 for task create_tables_stages.criar_Stage_Employees (The conn_id `***` isn't defined; 49921)
[2022-06-20 11:41:40,217] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-20 11:41:40,302] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:43:51,747] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:43:51,760] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:43:51,760] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:43:51,760] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:43:51,760] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:43:51,774] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:43:51,780] {standard_task_runner.py:52} INFO - Started process 51142 to run task
[2022-06-20 11:43:51,784] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp71jtj8n0', '--error-file', '/tmp/tmpvfv84c62']
[2022-06-20 11:43:51,784] {standard_task_runner.py:80} INFO - Job 23: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 11:43:51,857] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:43:51,961] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:43:51,980] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:43:51,984] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 11:43:52,025] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T144351, end_date=20220620T144352
[2022-06-20 11:43:52,076] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:43:52,156] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 11:46:09,430] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:46:09,446] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 11:46:09,447] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:46:09,447] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 11:46:09,447] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 11:46:09,467] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 11:46:09,476] {standard_task_runner.py:52} INFO - Started process 52574 to run task
[2022-06-20 11:46:09,480] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '39', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp4c2ebu_i', '--error-file', '/tmp/tmpd7vodvsp']
[2022-06-20 11:46:09,481] {standard_task_runner.py:80} INFO - Job 39: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 11:46:09,565] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 11:46:09,660] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 11:46:09,673] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 11:46:09,680] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 11:46:09,682] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 11:46:09,705] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T144609, end_date=20220620T144609
[2022-06-20 11:46:09,732] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 11:46:09,821] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:08:15,717] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:08:15,735] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:08:15,735] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:08:15,736] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:08:15,736] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:08:15,756] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:08:15,762] {standard_task_runner.py:52} INFO - Started process 57351 to run task
[2022-06-20 12:08:15,771] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '57', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpc0w62qno', '--error-file', '/tmp/tmp_vllqjj7']
[2022-06-20 12:08:15,771] {standard_task_runner.py:80} INFO - Job 57: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 12:08:15,843] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:08:15,945] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:08:15,958] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:08:15,964] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 12:08:15,965] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 12:08:15,988] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T150815, end_date=20220620T150815
[2022-06-20 12:08:16,021] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:08:16,100] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:24:55,514] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:24:55,545] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:24:55,546] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:24:55,546] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:24:55,546] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:24:55,581] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:24:55,595] {standard_task_runner.py:52} INFO - Started process 9160 to run task
[2022-06-20 12:24:55,603] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '73', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpd32hn7f3', '--error-file', '/tmp/tmp51sfgrn9']
[2022-06-20 12:24:55,604] {standard_task_runner.py:80} INFO - Job 73: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 12:24:55,720] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:24:55,899] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:24:55,922] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:24:55,931] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 12:24:55,932] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 12:24:56,003] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T152455, end_date=20220620T152456
[2022-06-20 12:24:56,062] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:24:56,157] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:27:37,258] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:27:37,282] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:27:37,283] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:27:37,283] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:27:37,283] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:27:37,308] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:27:37,321] {standard_task_runner.py:52} INFO - Started process 11503 to run task
[2022-06-20 12:27:37,328] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '89', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpqievfmwp', '--error-file', '/tmp/tmpwg8aflka']
[2022-06-20 12:27:37,329] {standard_task_runner.py:80} INFO - Job 89: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 12:27:37,443] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:27:37,609] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:27:37,631] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:27:37,638] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 12:27:37,639] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 12:27:37,669] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T152737, end_date=20220620T152737
[2022-06-20 12:27:37,740] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:27:37,861] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:39:45,758] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:39:45,791] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:39:45,791] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:39:45,791] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:39:45,791] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:39:45,819] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:39:45,834] {standard_task_runner.py:52} INFO - Started process 14603 to run task
[2022-06-20 12:39:45,841] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '110', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpuwkyo_ww', '--error-file', '/tmp/tmp0xb9w72f']
[2022-06-20 12:39:45,842] {standard_task_runner.py:80} INFO - Job 110: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 12:39:45,954] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:39:46,121] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:39:46,143] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:39:46,152] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 12:39:46,214] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T153945, end_date=20220620T153946
[2022-06-20 12:39:46,259] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:39:46,390] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 12:56:50,159] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:56:50,192] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 12:56:50,192] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:56:50,192] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 12:56:50,192] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 12:56:50,224] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 12:56:50,238] {standard_task_runner.py:52} INFO - Started process 17870 to run task
[2022-06-20 12:56:50,248] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '127', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpesixb84l', '--error-file', '/tmp/tmpuzp6eqa0']
[2022-06-20 12:56:50,249] {standard_task_runner.py:80} INFO - Job 127: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 12:56:50,373] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 12:56:50,531] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 12:56:50,550] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 12:56:50,559] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 12:56:50,561] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 12:56:50,631] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T155650, end_date=20220620T155650
[2022-06-20 12:56:50,700] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 12:56:50,798] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 13:00:04,010] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:00:04,043] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:00:04,044] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:00:04,044] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 13:00:04,044] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:00:04,080] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 13:00:04,095] {standard_task_runner.py:52} INFO - Started process 19806 to run task
[2022-06-20 13:00:04,111] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '146', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp3ylo9yx6', '--error-file', '/tmp/tmpnyhhzpzn']
[2022-06-20 13:00:04,112] {standard_task_runner.py:80} INFO - Job 146: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 13:00:04,244] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 13:00:04,404] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 13:00:04,425] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 13:00:04,433] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 13:00:04,435] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 13:00:04,463] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T160004, end_date=20220620T160004
[2022-06-20 13:00:04,520] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 13:00:04,626] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 13:45:20,534] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:45:20,569] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 13:45:20,569] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:45:20,569] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 13:45:20,569] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 13:45:20,600] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 13:45:20,620] {standard_task_runner.py:52} INFO - Started process 29099 to run task
[2022-06-20 13:45:20,628] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '164', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpjeeluavk', '--error-file', '/tmp/tmp2ubskdda']
[2022-06-20 13:45:20,629] {standard_task_runner.py:80} INFO - Job 164: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 13:45:20,756] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 13:45:20,929] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 13:45:20,950] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 13:45:20,961] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 13:45:20,963] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 13:45:21,009] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T164520, end_date=20220620T164521
[2022-06-20 13:45:21,083] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 13:45:21,180] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:00:10,909] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:00:10,940] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:00:10,941] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:00:10,941] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:00:10,941] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:00:10,971] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:00:10,985] {standard_task_runner.py:52} INFO - Started process 33061 to run task
[2022-06-20 14:00:10,991] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '182', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpw6h16g_k', '--error-file', '/tmp/tmpr8mxcirp']
[2022-06-20 14:00:10,992] {standard_task_runner.py:80} INFO - Job 182: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 14:00:11,232] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:00:11,439] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:00:11,476] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:00:11,493] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 14:00:11,495] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 14:00:11,587] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T170010, end_date=20220620T170011
[2022-06-20 14:00:11,665] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:00:11,792] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:07:56,968] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:07:56,999] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:07:57,000] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:07:57,000] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:07:57,000] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:07:57,030] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:07:57,043] {standard_task_runner.py:52} INFO - Started process 36432 to run task
[2022-06-20 14:07:57,051] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '199', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpr2rc7bxz', '--error-file', '/tmp/tmpzfq3i3tj']
[2022-06-20 14:07:57,053] {standard_task_runner.py:80} INFO - Job 199: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 14:07:57,176] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:07:57,350] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:07:57,376] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:07:57,382] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 14:07:57,384] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 14:07:57,467] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T170756, end_date=20220620T170757
[2022-06-20 14:07:57,548] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:07:57,639] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:15:19,408] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:15:19,438] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:15:19,439] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:15:19,439] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:15:19,439] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:15:19,468] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:15:19,487] {standard_task_runner.py:52} INFO - Started process 39195 to run task
[2022-06-20 14:15:19,500] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '219', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmph9kj18_q', '--error-file', '/tmp/tmp6wdmi6b0']
[2022-06-20 14:15:19,501] {standard_task_runner.py:80} INFO - Job 219: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 14:15:19,624] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:15:19,796] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:15:19,819] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:15:19,827] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 14:15:19,828] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 14:15:19,879] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T171519, end_date=20220620T171519
[2022-06-20 14:15:19,954] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:15:20,045] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:16:23,799] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:16:23,821] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:16:23,821] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:16:23,821] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:16:23,821] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:16:23,845] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:16:23,856] {standard_task_runner.py:52} INFO - Started process 40690 to run task
[2022-06-20 14:16:23,863] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '235', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpfx4kp4x8', '--error-file', '/tmp/tmpewb9cdeq']
[2022-06-20 14:16:23,863] {standard_task_runner.py:80} INFO - Job 235: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 14:16:23,977] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:16:24,142] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:16:24,164] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:16:24,173] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 14:16:24,175] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 14:16:24,208] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T171623, end_date=20220620T171624
[2022-06-20 14:16:24,275] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:16:24,427] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:26:50,687] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:26:50,713] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:26:50,714] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:26:50,714] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:26:50,714] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:26:50,738] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:26:50,752] {standard_task_runner.py:52} INFO - Started process 43904 to run task
[2022-06-20 14:26:50,758] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '254', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpy9510hqg', '--error-file', '/tmp/tmpl4hsm6ws']
[2022-06-20 14:26:50,759] {standard_task_runner.py:80} INFO - Job 254: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 14:26:50,879] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:26:51,125] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:26:51,151] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:26:51,161] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 14:26:51,163] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 14:26:51,200] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T172650, end_date=20220620T172651
[2022-06-20 14:26:51,294] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:26:51,409] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:31:44,378] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:31:44,417] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:31:44,417] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:31:44,418] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:31:44,418] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:31:44,455] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:31:44,469] {standard_task_runner.py:52} INFO - Started process 46183 to run task
[2022-06-20 14:31:44,489] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '273', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp21b10jsh', '--error-file', '/tmp/tmp85xnan20']
[2022-06-20 14:31:44,489] {standard_task_runner.py:80} INFO - Job 273: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 14:31:44,682] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:31:44,853] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:31:44,879] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:31:44,888] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 14:31:44,950] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T173144, end_date=20220620T173144
[2022-06-20 14:31:45,020] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:31:45,108] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:34:11,420] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:34:11,448] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:34:11,448] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:34:11,448] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:34:11,449] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:34:11,475] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:34:11,489] {standard_task_runner.py:52} INFO - Started process 47938 to run task
[2022-06-20 14:34:11,495] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '288', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpgkpq1wcs', '--error-file', '/tmp/tmp0_5a9wls']
[2022-06-20 14:34:11,496] {standard_task_runner.py:80} INFO - Job 288: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 14:34:11,625] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:34:11,901] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:34:11,935] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:34:11,949] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 14:34:12,047] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T173411, end_date=20220620T173412
[2022-06-20 14:34:12,113] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:34:12,248] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:37:53,017] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:37:53,047] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:37:53,048] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:37:53,048] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:37:53,048] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:37:53,081] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:37:53,097] {standard_task_runner.py:52} INFO - Started process 50678 to run task
[2022-06-20 14:37:53,103] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '306', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp3g8knrcm', '--error-file', '/tmp/tmpbizk86dw']
[2022-06-20 14:37:53,104] {standard_task_runner.py:80} INFO - Job 306: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 14:37:53,253] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:37:53,443] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:37:53,469] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:37:53,478] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 14:37:53,549] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T173753, end_date=20220620T173753
[2022-06-20 14:37:53,600] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:37:53,727] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 14:46:36,074] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:46:36,113] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 14:46:36,114] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:46:36,114] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 14:46:36,114] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 14:46:36,151] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 14:46:36,165] {standard_task_runner.py:52} INFO - Started process 54129 to run task
[2022-06-20 14:46:36,171] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '321', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp84vua3g5', '--error-file', '/tmp/tmp03znbmzs']
[2022-06-20 14:46:36,172] {standard_task_runner.py:80} INFO - Job 321: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 14:46:36,271] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 14:46:36,455] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 14:46:36,479] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 14:46:36,507] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 14:46:36,577] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T174636, end_date=20220620T174636
[2022-06-20 14:46:36,667] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 14:46:36,781] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:33:20,127] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:33:20,157] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:33:20,158] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:33:20,158] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:33:20,158] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:33:20,188] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:33:20,204] {standard_task_runner.py:52} INFO - Started process 60640 to run task
[2022-06-20 15:33:20,217] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '342', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp_2_mxw8g', '--error-file', '/tmp/tmp7p26u6f9']
[2022-06-20 15:33:20,218] {standard_task_runner.py:80} INFO - Job 342: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 15:33:20,352] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:33:20,522] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:33:20,544] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:33:20,551] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 15:33:20,635] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T183320, end_date=20220620T183320
[2022-06-20 15:33:20,708] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:33:20,791] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:35:25,085] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:35:25,115] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:35:25,116] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:35:25,116] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:35:25,116] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:35:25,148] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:35:25,164] {standard_task_runner.py:52} INFO - Started process 62225 to run task
[2022-06-20 15:35:25,170] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '357', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpea14wovk', '--error-file', '/tmp/tmpkn1i720j']
[2022-06-20 15:35:25,171] {standard_task_runner.py:80} INFO - Job 357: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 15:35:25,284] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:35:25,472] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:35:25,495] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:35:25,502] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 15:35:25,580] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T183525, end_date=20220620T183525
[2022-06-20 15:35:25,629] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:35:25,752] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:41:45,558] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:41:45,587] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:41:45,587] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:41:45,587] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:41:45,587] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:41:45,616] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:41:45,632] {standard_task_runner.py:52} INFO - Started process 64642 to run task
[2022-06-20 15:41:45,642] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '374', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmppio5d87b', '--error-file', '/tmp/tmplzjfy3l_']
[2022-06-20 15:41:45,643] {standard_task_runner.py:80} INFO - Job 374: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 15:41:45,796] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:41:46,009] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:41:46,034] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:41:46,044] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 15:41:46,047] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 15:41:46,137] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T184145, end_date=20220620T184146
[2022-06-20 15:41:46,228] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:41:46,346] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 15:51:27,211] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:51:27,237] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 15:51:27,238] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:51:27,238] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 15:51:27,238] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 15:51:27,266] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 15:51:27,279] {standard_task_runner.py:52} INFO - Started process 67466 to run task
[2022-06-20 15:51:27,284] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '390', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp96fi01ck', '--error-file', '/tmp/tmp801ibo18']
[2022-06-20 15:51:27,285] {standard_task_runner.py:80} INFO - Job 390: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 15:51:27,382] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 15:51:27,568] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 15:51:27,596] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 15:51:27,614] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 15:51:27,658] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T185127, end_date=20220620T185127
[2022-06-20 15:51:27,739] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 15:51:27,880] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:09:22,195] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:09:22,222] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:09:22,223] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:09:22,223] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:09:22,223] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:09:22,254] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:09:22,268] {standard_task_runner.py:52} INFO - Started process 74377 to run task
[2022-06-20 16:09:22,276] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '415', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpixtkd3re', '--error-file', '/tmp/tmpdewtp34g']
[2022-06-20 16:09:22,277] {standard_task_runner.py:80} INFO - Job 415: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 16:09:22,417] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:09:22,626] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:09:22,648] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:09:22,658] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 16:09:22,702] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T190922, end_date=20220620T190922
[2022-06-20 16:09:22,786] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:09:23,051] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:13:45,059] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:13:45,085] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:13:45,086] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:13:45,086] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:13:45,086] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:13:45,113] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:13:45,126] {standard_task_runner.py:52} INFO - Started process 76416 to run task
[2022-06-20 16:13:45,133] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '435', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpwqyl3u9a', '--error-file', '/tmp/tmpviclep4m']
[2022-06-20 16:13:45,134] {standard_task_runner.py:80} INFO - Job 435: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 16:13:45,271] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:13:45,494] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:13:45,527] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:13:45,535] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 16:13:45,604] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T191345, end_date=20220620T191345
[2022-06-20 16:13:45,676] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:13:45,781] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:15:24,571] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:15:24,646] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:15:24,646] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:15:24,646] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:15:24,647] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:15:24,727] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:15:24,746] {standard_task_runner.py:52} INFO - Started process 77993 to run task
[2022-06-20 16:15:24,758] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '453', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp61m5yumz', '--error-file', '/tmp/tmptzlzipyl']
[2022-06-20 16:15:24,759] {standard_task_runner.py:80} INFO - Job 453: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 16:15:24,929] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:15:25,115] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:15:25,140] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:15:25,153] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 16:15:25,157] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 16:15:25,212] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T191524, end_date=20220620T191525
[2022-06-20 16:15:25,265] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:15:25,366] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:16:00,377] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:16:00,405] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:16:00,406] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:16:00,406] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:16:00,406] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:16:00,428] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:16:00,439] {standard_task_runner.py:52} INFO - Started process 78854 to run task
[2022-06-20 16:16:00,445] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '458', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpwzjkljbf', '--error-file', '/tmp/tmp4rg2j843']
[2022-06-20 16:16:00,446] {standard_task_runner.py:80} INFO - Job 458: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 16:16:00,535] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:16:00,675] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:16:00,695] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:16:00,706] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 16:16:00,745] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T191600, end_date=20220620T191600
[2022-06-20 16:16:00,816] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:16:00,911] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:29:36,550] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:29:36,593] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:29:36,593] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:29:36,593] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:29:36,593] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:29:36,621] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:29:36,634] {standard_task_runner.py:52} INFO - Started process 81814 to run task
[2022-06-20 16:29:36,640] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '478', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpezijs7p0', '--error-file', '/tmp/tmpvnfhsbk4']
[2022-06-20 16:29:36,641] {standard_task_runner.py:80} INFO - Job 478: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 16:29:36,752] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:29:36,946] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:29:36,975] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:29:36,982] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 16:29:36,984] {postgres.py:94} INFO - NOTICE:  relation "stg_emp" already exists, skipping

[2022-06-20 16:29:37,047] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T192936, end_date=20220620T192937
[2022-06-20 16:29:37,102] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:29:37,215] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-20 16:31:51,565] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:31:51,598] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [queued]>
[2022-06-20 16:31:51,598] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:31:51,599] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-20 16:31:51,599] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-20 16:31:51,630] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Employees> on 2022-06-19 00:00:00+00:00
[2022-06-20 16:31:51,647] {standard_task_runner.py:52} INFO - Started process 83674 to run task
[2022-06-20 16:31:51,655] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Employees', 'scheduled__2022-06-19T00:00:00+00:00', '--job-id', '497', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpn8zbtcx5', '--error-file', '/tmp/tmpymz8vd29']
[2022-06-20 16:31:51,656] {standard_task_runner.py:80} INFO - Job 497: Subtask create_tables_stages.criar_Stage_Employees
[2022-06-20 16:31:51,774] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Employees scheduled__2022-06-19T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-20 16:31:51,961] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Employees
AIRFLOW_CTX_EXECUTION_DATE=2022-06-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-19T00:00:00+00:00
[2022-06-20 16:31:51,985] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-20 16:31:51,996] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_emp (
                employeenumber INT NOT NULL,                        
                lastname VARCHAR(30) NOT NULL,
                firstname VARCHAR(30) NOT NULL,
                email VARCHAR (40) NOT NULL,
                jobtitle VARCHAR(30) NOT NULL
                )
            , parameters: None
[2022-06-20 16:31:52,068] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Employees, execution_date=20220619T000000, start_date=20220620T193151, end_date=20220620T193152
[2022-06-20 16:31:52,153] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-20 16:31:52,256] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
