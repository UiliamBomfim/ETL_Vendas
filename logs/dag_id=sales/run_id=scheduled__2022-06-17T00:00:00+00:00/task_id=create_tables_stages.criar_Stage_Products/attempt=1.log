[2022-06-18 11:07:28,754] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:07:28,775] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:07:28,775] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:07:28,775] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:07:28,775] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:07:28,795] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:07:28,806] {standard_task_runner.py:52} INFO - Started process 197754 to run task
[2022-06-18 11:07:28,811] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1371', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp2pyvrgm8', '--error-file', '/tmp/tmpdt5lf_ap']
[2022-06-18 11:07:28,812] {standard_task_runner.py:80} INFO - Job 1371: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 11:07:28,919] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:07:29,098] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:07:29,121] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:07:29,136] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 11:07:29,138] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 11:07:29,189] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T140728, end_date=20220618T140729
[2022-06-18 11:07:29,264] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:07:29,373] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:09:15,868] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:09:15,890] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:09:15,890] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:09:15,890] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:09:15,890] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:09:15,912] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:09:15,923] {standard_task_runner.py:52} INFO - Started process 199288 to run task
[2022-06-18 11:09:15,928] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1381', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmprhizge6w', '--error-file', '/tmp/tmpv4pe9s_s']
[2022-06-18 11:09:15,929] {standard_task_runner.py:80} INFO - Job 1381: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 11:09:16,024] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:09:16,170] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:09:16,191] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:09:16,197] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 11:09:16,198] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 11:09:16,224] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T140915, end_date=20220618T140916
[2022-06-18 11:09:16,302] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:09:16,384] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:30:33,932] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:30:33,966] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:30:33,967] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:30:33,967] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:30:33,967] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:30:34,000] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:30:34,023] {standard_task_runner.py:52} INFO - Started process 206411 to run task
[2022-06-18 11:30:34,030] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp2i6quqpr', '--error-file', '/tmp/tmphkvb6qop']
[2022-06-18 11:30:34,031] {standard_task_runner.py:80} INFO - Job 10: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 11:30:34,171] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:30:34,327] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:30:34,346] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:30:34,350] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 113, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "***" to address: Temporary failure in name resolution

[2022-06-18 11:30:34,371] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T143033, end_date=20220618T143034
[2022-06-18 11:30:34,401] {standard_task_runner.py:92} ERROR - Failed to execute job 10 for task create_tables_stages.criar_Stage_Products (could not translate host name "***" to address: Temporary failure in name resolution
; 206411)
[2022-06-18 11:30:34,445] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-18 11:30:34,534] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:33:59,931] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:33:59,956] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:33:59,956] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:33:59,956] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:33:59,956] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:33:59,980] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:33:59,993] {standard_task_runner.py:52} INFO - Started process 208083 to run task
[2022-06-18 11:33:59,999] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpweaa7yxn', '--error-file', '/tmp/tmpr4q0cjmj']
[2022-06-18 11:33:59,999] {standard_task_runner.py:80} INFO - Job 18: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 11:34:00,119] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:34:00,257] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:34:00,274] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:34:00,283] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 11:34:00,285] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 11:34:00,331] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T143359, end_date=20220618T143400
[2022-06-18 11:34:00,374] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:34:00,452] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:41:53,935] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:41:53,967] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:41:53,968] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:41:53,968] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:41:53,968] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:41:54,003] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:41:54,018] {standard_task_runner.py:52} INFO - Started process 211530 to run task
[2022-06-18 11:41:54,024] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpys80l2_r', '--error-file', '/tmp/tmpzmpxc7gs']
[2022-06-18 11:41:54,025] {standard_task_runner.py:80} INFO - Job 37: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 11:41:54,154] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:41:54,319] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:41:54,345] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:41:54,353] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 11:41:54,355] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 11:41:54,401] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T144153, end_date=20220618T144154
[2022-06-18 11:41:54,444] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:41:54,521] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:45:19,188] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:45:19,219] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:45:19,220] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:45:19,220] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:45:19,220] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:45:19,248] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:45:19,263] {standard_task_runner.py:52} INFO - Started process 213373 to run task
[2022-06-18 11:45:19,270] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '51', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp_3sramq6', '--error-file', '/tmp/tmpsqrkik7v']
[2022-06-18 11:45:19,271] {standard_task_runner.py:80} INFO - Job 51: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 11:45:19,412] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:45:19,575] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:45:19,602] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:45:19,612] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 11:45:19,614] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 11:45:19,643] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T144519, end_date=20220618T144519
[2022-06-18 11:45:19,724] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:45:19,847] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:52:23,242] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:52:23,254] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:52:23,254] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:52:23,254] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:52:23,254] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:52:23,270] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:52:23,277] {standard_task_runner.py:52} INFO - Started process 217097 to run task
[2022-06-18 11:52:23,280] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '70', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpyn8dixch', '--error-file', '/tmp/tmp3te_aodg']
[2022-06-18 11:52:23,281] {standard_task_runner.py:80} INFO - Job 70: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 11:52:23,347] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:52:23,432] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:52:23,445] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:52:23,450] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 11:52:23,468] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T145223, end_date=20220618T145223
[2022-06-18 11:52:23,495] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:52:23,564] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:57:57,586] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:57:57,599] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:57:57,599] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:57:57,600] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:57:57,600] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:57:57,614] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:57:57,621] {standard_task_runner.py:52} INFO - Started process 219243 to run task
[2022-06-18 11:57:57,624] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '84', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpknzfbqx3', '--error-file', '/tmp/tmpvi9j04ar']
[2022-06-18 11:57:57,624] {standard_task_runner.py:80} INFO - Job 84: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 11:57:57,696] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:57:57,794] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:57:57,806] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:57:57,811] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 11:57:57,812] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 11:57:57,844] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T145757, end_date=20220618T145757
[2022-06-18 11:57:57,879] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:57:57,946] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 12:18:28,958] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:18:28,974] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:18:28,974] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:18:28,974] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 12:18:28,974] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:18:28,990] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 12:18:28,997] {standard_task_runner.py:52} INFO - Started process 226542 to run task
[2022-06-18 12:18:29,003] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1400', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpv0q4nakc', '--error-file', '/tmp/tmp8sjv7c9s']
[2022-06-18 12:18:29,004] {standard_task_runner.py:80} INFO - Job 1400: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 12:18:29,072] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 12:18:29,163] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 12:18:29,179] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 12:18:29,183] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 12:18:29,229] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T151828, end_date=20220618T151829
[2022-06-18 12:18:29,293] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 12:18:29,352] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 12:19:17,131] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:19:17,147] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:19:17,147] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:19:17,147] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 12:19:17,147] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:19:17,166] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 12:19:17,172] {standard_task_runner.py:52} INFO - Started process 227593 to run task
[2022-06-18 12:19:17,176] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1412', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpug_fdyr5', '--error-file', '/tmp/tmpc0q80hz8']
[2022-06-18 12:19:17,177] {standard_task_runner.py:80} INFO - Job 1412: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 12:19:17,254] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 12:19:17,356] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 12:19:17,369] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 12:19:17,373] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 12:19:17,374] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 12:19:17,394] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T151917, end_date=20220618T151917
[2022-06-18 12:19:17,428] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 12:19:17,490] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 12:59:55,036] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:59:55,086] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:59:55,087] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:59:55,087] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 12:59:55,087] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:59:55,127] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 12:59:55,142] {standard_task_runner.py:52} INFO - Started process 8717 to run task
[2022-06-18 12:59:55,148] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1428', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmps55bny_h', '--error-file', '/tmp/tmpmedytojo']
[2022-06-18 12:59:55,150] {standard_task_runner.py:80} INFO - Job 1428: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 12:59:55,275] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 12:59:55,466] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 12:59:55,487] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 12:59:55,494] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 12:59:55,496] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 12:59:55,525] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T155955, end_date=20220618T155955
[2022-06-18 12:59:55,604] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 12:59:55,706] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:02:30,049] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:02:30,095] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:02:30,095] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:02:30,096] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:02:30,096] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:02:30,141] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:02:30,156] {standard_task_runner.py:52} INFO - Started process 10430 to run task
[2022-06-18 13:02:30,170] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1442', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp1ka7hhu6', '--error-file', '/tmp/tmpsvlldypx']
[2022-06-18 13:02:30,170] {standard_task_runner.py:80} INFO - Job 1442: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:02:30,289] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:02:30,448] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:02:30,473] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:02:30,480] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:02:30,482] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 13:02:30,512] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T160230, end_date=20220618T160230
[2022-06-18 13:02:30,577] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:02:30,677] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:13:41,905] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:13:41,930] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:13:41,930] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:13:41,931] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:13:41,931] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:13:41,959] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:13:41,974] {standard_task_runner.py:52} INFO - Started process 13704 to run task
[2022-06-18 13:13:41,981] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1461', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpw2s674ne', '--error-file', '/tmp/tmpf3val8xb']
[2022-06-18 13:13:41,982] {standard_task_runner.py:80} INFO - Job 1461: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:13:42,085] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:13:42,240] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:13:42,263] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:13:42,276] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:13:42,319] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T161341, end_date=20220618T161342
[2022-06-18 13:13:42,395] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:13:42,520] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:22:21,767] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:22:21,799] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:22:21,800] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:22:21,800] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:22:21,800] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:22:21,835] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:22:21,852] {standard_task_runner.py:52} INFO - Started process 16620 to run task
[2022-06-18 13:22:21,862] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1479', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp53zajx_w', '--error-file', '/tmp/tmpj3affezb']
[2022-06-18 13:22:21,863] {standard_task_runner.py:80} INFO - Job 1479: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:22:22,000] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:22:22,218] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:22:22,265] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:22:22,274] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:22:22,281] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 13:22:22,352] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T162221, end_date=20220618T162222
[2022-06-18 13:22:22,409] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:22:22,543] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:24:16,661] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:24:16,685] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:24:16,686] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:24:16,686] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:24:16,686] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:24:16,711] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:24:16,723] {standard_task_runner.py:52} INFO - Started process 18453 to run task
[2022-06-18 13:24:16,731] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1491', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp3fxsuj7z', '--error-file', '/tmp/tmpggfsisf2']
[2022-06-18 13:24:16,731] {standard_task_runner.py:80} INFO - Job 1491: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:24:16,827] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:24:16,976] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:24:17,002] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:24:17,013] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:24:17,015] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 13:24:17,048] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T162416, end_date=20220618T162417
[2022-06-18 13:24:17,101] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:24:17,218] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:28:19,137] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:28:19,165] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:28:19,165] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:28:19,166] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:28:19,166] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:28:19,200] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:28:19,214] {standard_task_runner.py:52} INFO - Started process 20953 to run task
[2022-06-18 13:28:19,221] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1510', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpb9gpcrgd', '--error-file', '/tmp/tmpfvklt1bs']
[2022-06-18 13:28:19,222] {standard_task_runner.py:80} INFO - Job 1510: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:28:19,368] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:28:19,558] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:28:19,589] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:28:19,603] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:28:19,665] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T162819, end_date=20220618T162819
[2022-06-18 13:28:19,717] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:28:19,832] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:32:52,443] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:32:52,479] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:32:52,480] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:32:52,480] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:32:52,480] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:32:52,516] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:32:52,532] {standard_task_runner.py:52} INFO - Started process 23382 to run task
[2022-06-18 13:32:52,547] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1522', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpy3di_00l', '--error-file', '/tmp/tmp88g1cbt7']
[2022-06-18 13:32:52,548] {standard_task_runner.py:80} INFO - Job 1522: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:32:52,652] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:32:52,812] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:32:52,833] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:32:52,842] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:32:52,844] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 13:32:52,877] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T163252, end_date=20220618T163252
[2022-06-18 13:32:52,955] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:32:53,056] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:39:58,945] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:39:58,969] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:39:58,970] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:39:58,970] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:39:58,970] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:39:58,995] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:39:59,008] {standard_task_runner.py:52} INFO - Started process 26957 to run task
[2022-06-18 13:39:59,014] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1539', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpypxfecf9', '--error-file', '/tmp/tmppx9_vwjh']
[2022-06-18 13:39:59,015] {standard_task_runner.py:80} INFO - Job 1539: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:39:59,115] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:39:59,285] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:39:59,318] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:39:59,329] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:39:59,332] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 13:39:59,362] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T163958, end_date=20220618T163959
[2022-06-18 13:39:59,428] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:39:59,531] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:41:55,560] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:41:55,592] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:41:55,593] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:41:55,594] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:41:55,594] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:41:55,623] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:41:55,640] {standard_task_runner.py:52} INFO - Started process 28837 to run task
[2022-06-18 13:41:55,647] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1557', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpf_roilaf', '--error-file', '/tmp/tmplu2ku4sx']
[2022-06-18 13:41:55,648] {standard_task_runner.py:80} INFO - Job 1557: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:41:55,773] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:41:55,990] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:41:56,036] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:41:56,048] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:41:56,064] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 13:41:56,101] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T164155, end_date=20220618T164156
[2022-06-18 13:41:56,224] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:41:56,345] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:43:33,932] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:43:33,955] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:43:33,956] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:43:33,956] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:43:33,956] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:43:33,981] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:43:33,994] {standard_task_runner.py:52} INFO - Started process 30511 to run task
[2022-06-18 13:43:34,000] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1569', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpopc_jhg4', '--error-file', '/tmp/tmps6lfsnok']
[2022-06-18 13:43:34,001] {standard_task_runner.py:80} INFO - Job 1569: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:43:34,101] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:43:34,265] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:43:34,284] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:43:34,292] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:43:34,293] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 13:43:34,323] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T164333, end_date=20220618T164334
[2022-06-18 13:43:34,373] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:43:34,487] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:46:25,779] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:46:25,803] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:46:25,803] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:46:25,803] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:46:25,803] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:46:25,838] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:46:25,854] {standard_task_runner.py:52} INFO - Started process 32081 to run task
[2022-06-18 13:46:25,860] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1584', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmps8kpcafu', '--error-file', '/tmp/tmp9r1us7_7']
[2022-06-18 13:46:25,861] {standard_task_runner.py:80} INFO - Job 1584: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:46:25,978] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:46:26,155] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:46:26,175] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:46:26,182] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:46:26,183] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 13:46:26,249] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T164625, end_date=20220618T164626
[2022-06-18 13:46:26,319] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:46:26,404] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:52:03,485] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:52:03,515] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:52:03,515] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:52:03,515] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:52:03,515] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:52:03,545] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:52:03,561] {standard_task_runner.py:52} INFO - Started process 34103 to run task
[2022-06-18 13:52:03,569] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1602', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp664x832_', '--error-file', '/tmp/tmpj_ax4xf6']
[2022-06-18 13:52:03,570] {standard_task_runner.py:80} INFO - Job 1602: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:52:03,685] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:52:03,850] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:52:03,871] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:52:03,878] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:52:03,880] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 13:52:03,910] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T165203, end_date=20220618T165203
[2022-06-18 13:52:03,983] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:52:04,090] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:56:28,852] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:56:28,878] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:56:28,879] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:56:28,879] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:56:28,879] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:56:28,901] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:56:28,914] {standard_task_runner.py:52} INFO - Started process 36584 to run task
[2022-06-18 13:56:28,920] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1614', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmplplwz1vx', '--error-file', '/tmp/tmp5fhet2st']
[2022-06-18 13:56:28,921] {standard_task_runner.py:80} INFO - Job 1614: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 13:56:29,014] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:56:29,167] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:56:29,196] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:56:29,205] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 13:56:29,207] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 13:56:29,242] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T165628, end_date=20220618T165629
[2022-06-18 13:56:29,298] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:56:29,400] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:00:22,599] {taskinstance.py:1150} INFO - Dependencies not met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [None]>, dependency 'Trigger Rule' FAILED: Task's trigger rule 'all_success' requires all upstream tasks to have succeeded, but found 1 non-success(es). upstream_tasks_state={'total': 1, 'successes': 0, 'skipped': 0, 'failed': 0, 'upstream_failed': 0, 'done': 0}, upstream_task_ids={'transforma_tabela'}
[2022-06-18 14:00:22,601] {local_task_job.py:101} INFO - Task is not able to be run
[2022-06-18 14:00:26,170] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:00:26,203] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:00:26,203] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:00:26,203] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:00:26,203] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:00:26,239] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:00:26,268] {standard_task_runner.py:52} INFO - Started process 39653 to run task
[2022-06-18 14:00:26,277] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpq294qa8z', '--error-file', '/tmp/tmposbgzq73']
[2022-06-18 14:00:26,278] {standard_task_runner.py:80} INFO - Job 15: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 14:00:26,404] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:00:26,596] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:00:26,623] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 14:00:26,627] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 113, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "***" to address: Temporary failure in name resolution

[2022-06-18 14:00:26,644] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T170026, end_date=20220618T170026
[2022-06-18 14:00:26,673] {standard_task_runner.py:92} ERROR - Failed to execute job 15 for task create_tables_stages.criar_Stage_Products (could not translate host name "***" to address: Temporary failure in name resolution
; 39653)
[2022-06-18 14:00:26,731] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-18 14:00:26,803] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:02:58,085] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:02:58,111] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:02:58,111] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:02:58,111] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:02:58,111] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:02:58,148] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:02:58,163] {standard_task_runner.py:52} INFO - Started process 41052 to run task
[2022-06-18 14:02:58,172] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpxvnewecq', '--error-file', '/tmp/tmpyxsrr59h']
[2022-06-18 14:02:58,172] {standard_task_runner.py:80} INFO - Job 22: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 14:02:58,297] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:02:58,476] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:02:58,496] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 14:02:58,503] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 14:02:58,505] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 14:02:58,542] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T170258, end_date=20220618T170258
[2022-06-18 14:02:58,623] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:02:58,714] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:13:57,368] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:13:57,394] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:13:57,395] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:13:57,395] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:13:57,395] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:13:57,419] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:13:57,431] {standard_task_runner.py:52} INFO - Started process 44137 to run task
[2022-06-18 14:13:57,437] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp5zqt1op5', '--error-file', '/tmp/tmpzmzgyar1']
[2022-06-18 14:13:57,438] {standard_task_runner.py:80} INFO - Job 6: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 14:13:57,541] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:13:57,708] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:13:57,730] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 14:13:57,734] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 113, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "***" to address: Temporary failure in name resolution

[2022-06-18 14:13:57,754] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T171357, end_date=20220618T171357
[2022-06-18 14:13:57,783] {standard_task_runner.py:92} ERROR - Failed to execute job 6 for task create_tables_stages.criar_Stage_Products (could not translate host name "***" to address: Temporary failure in name resolution
; 44137)
[2022-06-18 14:13:57,812] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-18 14:13:57,925] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:19:10,444] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:19:10,468] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:19:10,468] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:19:10,468] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:19:10,469] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:19:10,495] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:19:10,507] {standard_task_runner.py:52} INFO - Started process 46609 to run task
[2022-06-18 14:19:10,513] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpj5y6l4yv', '--error-file', '/tmp/tmpv_8afu6n']
[2022-06-18 14:19:10,514] {standard_task_runner.py:80} INFO - Job 15: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 14:19:10,620] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:19:10,751] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:19:10,772] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:19:10,779] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 14:19:10,780] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 14:19:10,843] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T171910, end_date=20220618T171910
[2022-06-18 14:19:10,887] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:19:10,971] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:22:43,892] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:22:43,918] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:22:43,919] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:22:43,919] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:22:43,919] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:22:43,947] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:22:43,963] {standard_task_runner.py:52} INFO - Started process 48325 to run task
[2022-06-18 14:22:43,969] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp5u6wuz8i', '--error-file', '/tmp/tmpd6dsueie']
[2022-06-18 14:22:43,970] {standard_task_runner.py:80} INFO - Job 29: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 14:22:44,103] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:22:44,312] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:22:44,352] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:22:44,368] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 14:22:44,370] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 14:22:44,424] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T172243, end_date=20220618T172244
[2022-06-18 14:22:44,512] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:22:44,660] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:29:07,368] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:29:07,393] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:29:07,393] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:29:07,393] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:29:07,393] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:29:07,417] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:29:07,432] {standard_task_runner.py:52} INFO - Started process 50509 to run task
[2022-06-18 14:29:07,437] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '45', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpvjhzgi8s', '--error-file', '/tmp/tmpsuub523p']
[2022-06-18 14:29:07,438] {standard_task_runner.py:80} INFO - Job 45: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 14:29:07,546] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:29:07,712] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:29:07,735] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:29:07,743] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 14:29:07,745] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 14:29:07,791] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T172907, end_date=20220618T172907
[2022-06-18 14:29:07,856] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:29:07,973] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:46:10,739] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:46:10,765] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:46:10,765] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:46:10,765] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:46:10,765] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:46:10,788] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:46:10,800] {standard_task_runner.py:52} INFO - Started process 54537 to run task
[2022-06-18 14:46:10,806] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpjwzku4y1', '--error-file', '/tmp/tmpapv0rk82']
[2022-06-18 14:46:10,807] {standard_task_runner.py:80} INFO - Job 61: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 14:46:10,907] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:46:11,101] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:46:11,127] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:46:11,135] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 14:46:11,138] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 14:46:11,187] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T174610, end_date=20220618T174611
[2022-06-18 14:46:11,262] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:46:11,376] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:50:58,041] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:50:58,071] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:50:58,071] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:50:58,071] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:50:58,071] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:50:58,101] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:50:58,115] {standard_task_runner.py:52} INFO - Started process 56777 to run task
[2022-06-18 14:50:58,122] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '80', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpy09xzl2j', '--error-file', '/tmp/tmpxb420tn9']
[2022-06-18 14:50:58,123] {standard_task_runner.py:80} INFO - Job 80: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 14:50:58,251] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:50:58,432] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:50:58,462] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:50:58,472] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 14:50:58,473] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 14:50:58,510] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T175058, end_date=20220618T175058
[2022-06-18 14:50:58,587] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:50:58,706] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:53:12,702] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:53:12,725] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:53:12,725] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:53:12,726] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:53:12,726] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:53:12,749] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:53:12,762] {standard_task_runner.py:52} INFO - Started process 58674 to run task
[2022-06-18 14:53:12,768] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '92', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpd8i77ssf', '--error-file', '/tmp/tmpz1lpidem']
[2022-06-18 14:53:12,769] {standard_task_runner.py:80} INFO - Job 92: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 14:53:12,882] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:53:13,026] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:53:13,048] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:53:13,055] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 14:53:13,057] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 14:53:13,098] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T175312, end_date=20220618T175313
[2022-06-18 14:53:13,140] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:53:13,240] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 15:01:47,350] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:01:47,380] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:01:47,381] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:01:47,381] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 15:01:47,381] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:01:47,408] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 15:01:47,423] {standard_task_runner.py:52} INFO - Started process 62133 to run task
[2022-06-18 15:01:47,430] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '109', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmph21bpoik', '--error-file', '/tmp/tmpkl3_0jdu']
[2022-06-18 15:01:47,430] {standard_task_runner.py:80} INFO - Job 109: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 15:01:47,567] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 15:01:47,757] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 15:01:47,785] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 15:01:47,798] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 15:01:47,800] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 15:01:47,860] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T180147, end_date=20220618T180147
[2022-06-18 15:01:47,930] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 15:01:48,080] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 15:06:29,882] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:06:29,919] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:06:29,919] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:06:29,920] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 15:06:29,921] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:06:29,957] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 15:06:29,977] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '127', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpj_4nn3x2', '--error-file', '/tmp/tmpproh8yru']
[2022-06-18 15:06:29,978] {standard_task_runner.py:80} INFO - Job 127: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 15:06:29,970] {standard_task_runner.py:52} INFO - Started process 65042 to run task
[2022-06-18 15:06:30,201] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 15:06:30,551] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 15:06:30,578] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 15:06:30,589] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 15:06:30,592] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 15:06:30,667] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T180629, end_date=20220618T180630
[2022-06-18 15:06:30,767] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 15:06:30,861] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 15:08:08,797] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:08:08,829] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:08:08,830] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:08:08,830] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 15:08:08,830] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:08:08,867] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 15:08:08,884] {standard_task_runner.py:52} INFO - Started process 67048 to run task
[2022-06-18 15:08:08,890] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '141', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpp4v3q4iq', '--error-file', '/tmp/tmpzo4j1g03']
[2022-06-18 15:08:08,891] {standard_task_runner.py:80} INFO - Job 141: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 15:08:08,992] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 15:08:09,135] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 15:08:09,154] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 15:08:09,160] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 15:08:09,162] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 15:08:09,189] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T180808, end_date=20220618T180809
[2022-06-18 15:08:09,265] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 15:08:09,352] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 15:27:08,630] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:27:08,672] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:27:08,673] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:27:08,673] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 15:27:08,673] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:27:08,704] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 15:27:08,719] {standard_task_runner.py:52} INFO - Started process 75611 to run task
[2022-06-18 15:27:08,728] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '157', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp8ol3o8xn', '--error-file', '/tmp/tmprjjx69c4']
[2022-06-18 15:27:08,729] {standard_task_runner.py:80} INFO - Job 157: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 15:27:08,844] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 15:27:09,273] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 15:27:09,310] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 15:27:09,327] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 15:27:09,333] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 15:27:09,391] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T182708, end_date=20220618T182709
[2022-06-18 15:27:09,501] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 15:27:09,888] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 15:29:49,083] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:29:49,129] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:29:49,130] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:29:49,130] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 15:29:49,130] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:29:49,158] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Products> on 2022-06-17 00:00:00+00:00
[2022-06-18 15:29:49,172] {standard_task_runner.py:52} INFO - Started process 79033 to run task
[2022-06-18 15:29:49,179] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Products', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '175', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp55u24ln9', '--error-file', '/tmp/tmpmuogupat']
[2022-06-18 15:29:49,180] {standard_task_runner.py:80} INFO - Job 175: Subtask create_tables_stages.criar_Stage_Products
[2022-06-18 15:29:49,290] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Products scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 15:29:49,461] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Products
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 15:29:49,481] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 15:29:49,489] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_products (
                productname VARCHAR(40),
                productline VARCHAR(20),
                productvendor VARCHAR(25),
                productdescription VARCHAR(200)
                )
            , parameters: None
[2022-06-18 15:29:49,491] {postgres.py:94} INFO - NOTICE:  relation "stg_products" already exists, skipping

[2022-06-18 15:29:49,522] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Products, execution_date=20220617T000000, start_date=20220618T182949, end_date=20220618T182949
[2022-06-18 15:29:49,593] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 15:29:49,730] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
