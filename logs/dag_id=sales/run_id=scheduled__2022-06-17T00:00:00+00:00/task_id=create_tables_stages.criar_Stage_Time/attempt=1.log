[2022-06-18 11:07:28,886] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:07:28,912] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:07:28,912] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:07:28,913] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:07:28,913] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:07:28,937] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:07:28,949] {standard_task_runner.py:52} INFO - Started process 197769 to run task
[2022-06-18 11:07:28,956] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1374', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpned1ul74', '--error-file', '/tmp/tmpswym_evz']
[2022-06-18 11:07:28,956] {standard_task_runner.py:80} INFO - Job 1374: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 11:07:29,081] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:07:29,246] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:07:29,270] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:07:29,279] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 11:07:29,280] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 11:07:29,309] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T140728, end_date=20220618T140729
[2022-06-18 11:07:29,369] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:07:29,473] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:09:15,931] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:09:15,952] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:09:15,953] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:09:15,953] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:09:15,953] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:09:15,978] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:09:15,990] {standard_task_runner.py:52} INFO - Started process 199294 to run task
[2022-06-18 11:09:15,997] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1382', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpbxhyclqa', '--error-file', '/tmp/tmp5ebcypw4']
[2022-06-18 11:09:15,998] {standard_task_runner.py:80} INFO - Job 1382: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 11:09:16,101] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:09:16,246] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:09:16,262] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:09:16,270] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 11:09:16,271] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 11:09:16,292] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T140915, end_date=20220618T140916
[2022-06-18 11:09:16,371] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:09:16,451] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:30:34,026] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:30:34,063] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:30:34,064] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:30:34,064] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:30:34,064] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:30:34,099] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:30:34,115] {standard_task_runner.py:52} INFO - Started process 206440 to run task
[2022-06-18 11:30:34,122] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpfq1668_5', '--error-file', '/tmp/tmpq5er61f7']
[2022-06-18 11:30:34,123] {standard_task_runner.py:80} INFO - Job 11: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 11:30:34,251] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:30:34,419] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:30:34,440] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:30:34,444] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 113, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "***" to address: Temporary failure in name resolution

[2022-06-18 11:30:34,469] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T143034, end_date=20220618T143034
[2022-06-18 11:30:34,498] {standard_task_runner.py:92} ERROR - Failed to execute job 11 for task create_tables_stages.criar_Stage_Time (could not translate host name "***" to address: Temporary failure in name resolution
; 206440)
[2022-06-18 11:30:34,541] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-18 11:30:34,609] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:33:59,802] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:33:59,827] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:33:59,828] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:33:59,828] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:33:59,828] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:33:59,849] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:33:59,861] {standard_task_runner.py:52} INFO - Started process 208073 to run task
[2022-06-18 11:33:59,868] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp_e9s3jm_', '--error-file', '/tmp/tmp1se0u4_z']
[2022-06-18 11:33:59,869] {standard_task_runner.py:80} INFO - Job 16: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 11:33:59,964] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:34:00,128] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:34:00,150] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:34:00,156] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 11:34:00,157] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 11:34:00,183] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T143359, end_date=20220618T143400
[2022-06-18 11:34:00,240] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:34:00,327] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:41:53,759] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:41:53,792] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:41:53,792] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:41:53,792] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:41:53,792] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:41:53,824] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:41:53,840] {standard_task_runner.py:52} INFO - Started process 211498 to run task
[2022-06-18 11:41:53,847] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp5mqlzzi8', '--error-file', '/tmp/tmpojs2etpj']
[2022-06-18 11:41:53,850] {standard_task_runner.py:80} INFO - Job 35: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 11:41:53,966] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:41:54,157] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:41:54,177] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:41:54,185] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 11:41:54,186] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 11:41:54,237] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T144153, end_date=20220618T144154
[2022-06-18 11:41:54,302] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:41:54,397] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:45:19,026] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:45:19,057] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:45:19,057] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:45:19,057] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:45:19,058] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:45:19,086] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:45:19,100] {standard_task_runner.py:52} INFO - Started process 213331 to run task
[2022-06-18 11:45:19,106] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '49', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpha87tpd8', '--error-file', '/tmp/tmp5z7gnmqo']
[2022-06-18 11:45:19,107] {standard_task_runner.py:80} INFO - Job 49: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 11:45:19,216] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:45:19,385] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:45:19,420] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:45:19,428] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 11:45:19,429] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 11:45:19,457] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T144519, end_date=20220618T144519
[2022-06-18 11:45:19,519] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:45:19,617] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:52:23,163] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:52:23,177] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:52:23,178] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:52:23,178] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:52:23,178] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:52:23,189] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:52:23,194] {standard_task_runner.py:52} INFO - Started process 217084 to run task
[2022-06-18 11:52:23,198] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '68', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpuot8zyy5', '--error-file', '/tmp/tmpfq2dwqfs']
[2022-06-18 11:52:23,199] {standard_task_runner.py:80} INFO - Job 68: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 11:52:23,257] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:52:23,347] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:52:23,358] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:52:23,362] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 11:52:23,394] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T145223, end_date=20220618T145223
[2022-06-18 11:52:23,449] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:52:23,510] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 11:57:57,630] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:57:57,646] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 11:57:57,646] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:57:57,646] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 11:57:57,647] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 11:57:57,664] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 11:57:57,675] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '83', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpynymptr3', '--error-file', '/tmp/tmptripc62t']
[2022-06-18 11:57:57,671] {standard_task_runner.py:52} INFO - Started process 219252 to run task
[2022-06-18 11:57:57,675] {standard_task_runner.py:80} INFO - Job 83: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 11:57:57,747] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 11:57:57,836] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 11:57:57,848] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 11:57:57,853] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 11:57:57,854] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 11:57:57,897] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T145757, end_date=20220618T145757
[2022-06-18 11:57:57,929] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 11:57:57,993] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 12:18:28,869] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:18:28,884] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:18:28,885] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:18:28,885] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 12:18:28,885] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:18:28,901] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 12:18:28,909] {standard_task_runner.py:52} INFO - Started process 226532 to run task
[2022-06-18 12:18:28,914] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1398', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpy2zmf421', '--error-file', '/tmp/tmp64fvow4u']
[2022-06-18 12:18:28,914] {standard_task_runner.py:80} INFO - Job 1398: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 12:18:28,981] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 12:18:29,075] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 12:18:29,088] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 12:18:29,092] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 12:18:29,109] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T151828, end_date=20220618T151829
[2022-06-18 12:18:29,166] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 12:18:29,231] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 12:19:17,086] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:19:17,103] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:19:17,103] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:19:17,103] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 12:19:17,103] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:19:17,120] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 12:19:17,128] {standard_task_runner.py:52} INFO - Started process 227590 to run task
[2022-06-18 12:19:17,134] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1411', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpilptugjd', '--error-file', '/tmp/tmpkevadjw8']
[2022-06-18 12:19:17,134] {standard_task_runner.py:80} INFO - Job 1411: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 12:19:17,208] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 12:19:17,318] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 12:19:17,330] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 12:19:17,339] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 12:19:17,340] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 12:19:17,360] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T151917, end_date=20220618T151917
[2022-06-18 12:19:17,386] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 12:19:17,447] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 12:59:55,239] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:59:55,272] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 12:59:55,273] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:59:55,274] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 12:59:55,274] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 12:59:55,311] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 12:59:55,330] {standard_task_runner.py:52} INFO - Started process 8727 to run task
[2022-06-18 12:59:55,339] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1431', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpcjqo6arr', '--error-file', '/tmp/tmprvp8ug9_']
[2022-06-18 12:59:55,340] {standard_task_runner.py:80} INFO - Job 1431: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 12:59:55,481] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 12:59:55,655] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 12:59:55,679] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 12:59:55,688] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 12:59:55,689] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 12:59:55,717] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T155955, end_date=20220618T155955
[2022-06-18 12:59:55,762] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 12:59:55,862] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:02:30,171] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:02:30,199] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:02:30,200] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:02:30,200] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:02:30,200] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:02:30,241] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:02:30,256] {standard_task_runner.py:52} INFO - Started process 10462 to run task
[2022-06-18 13:02:30,265] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1443', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp664sfzo1', '--error-file', '/tmp/tmpfl07bphx']
[2022-06-18 13:02:30,266] {standard_task_runner.py:80} INFO - Job 1443: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:02:30,364] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:02:30,524] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:02:30,544] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:02:30,550] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS Stg_Time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:02:30,552] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 13:02:30,580] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T160230, end_date=20220618T160230
[2022-06-18 13:02:30,637] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:02:30,743] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:13:41,725] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:13:41,754] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:13:41,754] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:13:41,754] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:13:41,754] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:13:41,783] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:13:41,806] {standard_task_runner.py:52} INFO - Started process 13669 to run task
[2022-06-18 13:13:41,814] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1459', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp05vy3k0w', '--error-file', '/tmp/tmpxcvbb5a4']
[2022-06-18 13:13:41,815] {standard_task_runner.py:80} INFO - Job 1459: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:13:41,932] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:13:42,094] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:13:42,114] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:13:42,122] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:13:42,158] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T161341, end_date=20220618T161342
[2022-06-18 13:13:42,231] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:13:42,313] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:22:21,680] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:22:21,709] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:22:21,709] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:22:21,709] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:22:21,709] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:22:21,740] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:22:21,754] {standard_task_runner.py:52} INFO - Started process 16613 to run task
[2022-06-18 13:22:21,761] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1478', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp7fj6ubfs', '--error-file', '/tmp/tmp6616pzz8']
[2022-06-18 13:22:21,761] {standard_task_runner.py:80} INFO - Job 1478: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:22:21,895] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:22:22,090] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:22:22,115] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:22:22,127] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:22:22,133] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 13:22:22,180] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T162221, end_date=20220618T162222
[2022-06-18 13:22:22,256] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:22:22,421] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:24:16,875] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:24:16,904] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:24:16,905] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:24:16,905] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:24:16,905] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:24:16,931] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:24:16,946] {standard_task_runner.py:52} INFO - Started process 18467 to run task
[2022-06-18 13:24:16,952] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1494', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpfv6u0992', '--error-file', '/tmp/tmpsk40kigx']
[2022-06-18 13:24:16,952] {standard_task_runner.py:80} INFO - Job 1494: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:24:17,070] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:24:17,229] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:24:17,251] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:24:17,259] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:24:17,261] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 13:24:17,320] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T162416, end_date=20220618T162417
[2022-06-18 13:24:17,369] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:24:17,460] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:28:18,934] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:28:18,962] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:28:18,963] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:28:18,963] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:28:18,963] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:28:18,987] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:28:18,997] {standard_task_runner.py:52} INFO - Started process 20940 to run task
[2022-06-18 13:28:19,003] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1508', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp_ntssqzs', '--error-file', '/tmp/tmpqp82pn_2']
[2022-06-18 13:28:19,004] {standard_task_runner.py:80} INFO - Job 1508: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:28:19,100] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:28:19,257] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:28:19,284] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:28:19,297] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:28:19,350] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T162818, end_date=20220618T162819
[2022-06-18 13:28:19,420] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:28:19,532] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:32:52,624] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:32:52,647] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:32:52,647] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:32:52,648] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:32:52,648] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:32:52,672] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:32:52,685] {standard_task_runner.py:52} INFO - Started process 23390 to run task
[2022-06-18 13:32:52,691] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1524', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmp28g67tww', '--error-file', '/tmp/tmp8fzp51w7']
[2022-06-18 13:32:52,692] {standard_task_runner.py:80} INFO - Job 1524: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:32:52,802] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:32:52,968] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:32:52,991] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:32:52,997] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:32:53,000] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 13:32:53,061] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T163252, end_date=20220618T163253
[2022-06-18 13:32:53,145] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:32:53,237] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:39:59,014] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:39:59,036] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:39:59,037] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:39:59,037] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:39:59,037] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:39:59,060] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:39:59,074] {standard_task_runner.py:52} INFO - Started process 26961 to run task
[2022-06-18 13:39:59,082] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1540', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpxh6b6548', '--error-file', '/tmp/tmpv7xxasjc']
[2022-06-18 13:39:59,083] {standard_task_runner.py:80} INFO - Job 1540: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:39:59,188] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:39:59,373] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:39:59,395] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:39:59,408] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:39:59,409] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 13:39:59,464] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T163959, end_date=20220618T163959
[2022-06-18 13:39:59,534] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:39:59,644] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:41:55,484] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:41:55,508] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:41:55,509] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:41:55,509] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:41:55,509] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:41:55,537] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:41:55,551] {standard_task_runner.py:52} INFO - Started process 28830 to run task
[2022-06-18 13:41:55,558] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1556', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpfv6xqadq', '--error-file', '/tmp/tmpngpckq14']
[2022-06-18 13:41:55,560] {standard_task_runner.py:80} INFO - Job 1556: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:41:55,684] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:41:55,869] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:41:55,896] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:41:55,945] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:41:55,955] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 13:41:56,017] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T164155, end_date=20220618T164156
[2022-06-18 13:41:56,140] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:41:56,260] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:43:34,000] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:43:34,024] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:43:34,025] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:43:34,025] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:43:34,025] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:43:34,048] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:43:34,062] {standard_task_runner.py:52} INFO - Started process 30515 to run task
[2022-06-18 13:43:34,069] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1570', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpiau2gj8_', '--error-file', '/tmp/tmp3c8y_syr']
[2022-06-18 13:43:34,070] {standard_task_runner.py:80} INFO - Job 1570: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:43:34,183] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:43:34,350] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:43:34,372] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:43:34,378] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:43:34,380] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 13:43:34,411] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T164334, end_date=20220618T164334
[2022-06-18 13:43:34,482] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:43:34,565] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:46:25,857] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:46:25,888] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:46:25,889] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:46:25,889] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:46:25,889] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:46:25,920] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:46:25,935] {standard_task_runner.py:52} INFO - Started process 32085 to run task
[2022-06-18 13:46:25,946] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1585', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpdq2a0r0r', '--error-file', '/tmp/tmp12vkiq2b']
[2022-06-18 13:46:25,947] {standard_task_runner.py:80} INFO - Job 1585: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:46:26,063] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:46:26,223] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:46:26,244] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:46:26,252] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:46:26,254] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 13:46:26,289] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T164625, end_date=20220618T164626
[2022-06-18 13:46:26,359] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:46:26,470] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:52:03,405] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:52:03,433] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:52:03,433] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:52:03,434] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:52:03,434] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:52:03,461] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:52:03,475] {standard_task_runner.py:52} INFO - Started process 34093 to run task
[2022-06-18 13:52:03,485] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1601', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpt8mo1p0f', '--error-file', '/tmp/tmpoghbgl36']
[2022-06-18 13:52:03,486] {standard_task_runner.py:80} INFO - Job 1601: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:52:03,603] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:52:03,771] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:52:03,791] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:52:03,798] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:52:03,800] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 13:52:03,830] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T165203, end_date=20220618T165203
[2022-06-18 13:52:03,896] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:52:03,992] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 13:56:28,922] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:56:28,943] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 13:56:28,943] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:56:28,944] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 13:56:28,944] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 13:56:28,966] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 13:56:28,979] {standard_task_runner.py:52} INFO - Started process 36587 to run task
[2022-06-18 13:56:28,985] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '1615', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpvdx8f1ih', '--error-file', '/tmp/tmpxt_k6gay']
[2022-06-18 13:56:28,986] {standard_task_runner.py:80} INFO - Job 1615: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 13:56:29,088] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 13:56:29,259] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 13:56:29,288] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 13:56:29,296] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 13:56:29,297] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 13:56:29,327] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T165628, end_date=20220618T165629
[2022-06-18 13:56:29,399] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 13:56:29,493] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:00:22,514] {taskinstance.py:1150} INFO - Dependencies not met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [None]>, dependency 'Trigger Rule' FAILED: Task's trigger rule 'all_success' requires all upstream tasks to have succeeded, but found 1 non-success(es). upstream_tasks_state={'total': 1, 'successes': 0, 'skipped': 0, 'failed': 0, 'upstream_failed': 0, 'done': 0}, upstream_task_ids={'transforma_tabela'}
[2022-06-18 14:00:22,520] {local_task_job.py:101} INFO - Task is not able to be run
[2022-06-18 14:00:26,051] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:00:26,084] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:00:26,085] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:00:26,085] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:00:26,085] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:00:26,130] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:00:26,151] {standard_task_runner.py:52} INFO - Started process 39618 to run task
[2022-06-18 14:00:26,177] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp_nf8t9rm', '--error-file', '/tmp/tmplwhh7ymc']
[2022-06-18 14:00:26,178] {standard_task_runner.py:80} INFO - Job 16: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 14:00:26,324] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:00:26,502] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:00:26,541] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 14:00:26,548] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 113, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "***" to address: Temporary failure in name resolution

[2022-06-18 14:00:26,573] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T170026, end_date=20220618T170026
[2022-06-18 14:00:26,605] {standard_task_runner.py:92} ERROR - Failed to execute job 16 for task create_tables_stages.criar_Stage_Time (could not translate host name "***" to address: Temporary failure in name resolution
; 39618)
[2022-06-18 14:00:26,660] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-18 14:00:26,775] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:02:58,264] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:02:58,304] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:02:58,305] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:02:58,305] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:02:58,305] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:02:58,338] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:02:58,353] {standard_task_runner.py:52} INFO - Started process 41068 to run task
[2022-06-18 14:02:58,361] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpj4q9lkus', '--error-file', '/tmp/tmpy2t_7zfv']
[2022-06-18 14:02:58,361] {standard_task_runner.py:80} INFO - Job 24: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 14:02:58,485] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:02:58,631] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:02:58,652] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 14:02:58,658] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 14:02:58,659] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 14:02:58,716] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T170258, end_date=20220618T170258
[2022-06-18 14:02:58,779] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:02:58,862] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:13:57,594] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:13:57,628] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:13:57,629] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:13:57,629] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:13:57,629] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:13:57,661] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:13:57,678] {standard_task_runner.py:52} INFO - Started process 44164 to run task
[2022-06-18 14:13:57,682] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/dag copy.py', '--cfg-path', '/tmp/tmpg03x8dmg', '--error-file', '/tmp/tmpuy1yisyq']
[2022-06-18 14:13:57,683] {standard_task_runner.py:80} INFO - Job 8: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 14:13:57,816] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:13:57,979] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:13:57,999] {base.py:68} INFO - Using connection ID '***_default' for task execution.
[2022-06-18 14:13:58,003] {taskinstance.py:1890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/hooks/dbapi.py", line 186, in run
    with closing(self.get_conn()) as conn:
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/airflow/providers/postgres/hooks/postgres.py", line 113, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/uiliam/sandbox/lib/python3.9/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "***" to address: Temporary failure in name resolution

[2022-06-18 14:13:58,025] {taskinstance.py:1396} INFO - Marking task as FAILED. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T171357, end_date=20220618T171358
[2022-06-18 14:13:58,049] {standard_task_runner.py:92} ERROR - Failed to execute job 8 for task create_tables_stages.criar_Stage_Time (could not translate host name "***" to address: Temporary failure in name resolution
; 44164)
[2022-06-18 14:13:58,103] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-18 14:13:58,196] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:19:10,514] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:19:10,547] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:19:10,547] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:19:10,547] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:19:10,548] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:19:10,575] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:19:10,588] {standard_task_runner.py:52} INFO - Started process 46618 to run task
[2022-06-18 14:19:10,596] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpa4hpk4a8', '--error-file', '/tmp/tmpcc25ky1f']
[2022-06-18 14:19:10,597] {standard_task_runner.py:80} INFO - Job 16: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 14:19:10,702] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:19:10,834] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:19:10,852] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:19:10,859] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 14:19:10,861] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 14:19:10,900] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T171910, end_date=20220618T171910
[2022-06-18 14:19:10,968] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:19:11,043] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:22:43,971] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:22:44,005] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:22:44,006] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:22:44,006] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:22:44,006] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:22:44,044] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:22:44,059] {standard_task_runner.py:52} INFO - Started process 48331 to run task
[2022-06-18 14:22:44,068] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '31', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpuyv19ta2', '--error-file', '/tmp/tmpe9ho2kal']
[2022-06-18 14:22:44,069] {standard_task_runner.py:80} INFO - Job 31: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 14:22:44,233] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:22:44,425] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:22:44,466] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:22:44,478] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 14:22:44,479] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 14:22:44,566] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T172243, end_date=20220618T172244
[2022-06-18 14:22:44,651] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:22:44,749] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:29:07,435] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:29:07,462] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:29:07,462] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:29:07,462] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:29:07,463] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:29:07,493] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:29:07,507] {standard_task_runner.py:52} INFO - Started process 50515 to run task
[2022-06-18 14:29:07,515] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '47', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp3ck6do18', '--error-file', '/tmp/tmpsmm8tchj']
[2022-06-18 14:29:07,516] {standard_task_runner.py:80} INFO - Job 47: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 14:29:07,645] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:29:07,809] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:29:07,832] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:29:07,841] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 14:29:07,843] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 14:29:07,897] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T172907, end_date=20220618T172907
[2022-06-18 14:29:07,969] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:29:08,093] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:46:10,875] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:46:10,904] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:46:10,905] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:46:10,905] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:46:10,906] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:46:10,936] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:46:10,952] {standard_task_runner.py:52} INFO - Started process 54547 to run task
[2022-06-18 14:46:10,961] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '64', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmptekkfkcj', '--error-file', '/tmp/tmpwfpe_5yk']
[2022-06-18 14:46:10,962] {standard_task_runner.py:80} INFO - Job 64: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 14:46:11,099] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:46:11,322] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:46:11,351] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:46:11,361] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 14:46:11,363] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 14:46:11,426] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T174610, end_date=20220618T174611
[2022-06-18 14:46:11,502] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:46:11,593] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:50:57,960] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:50:57,988] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:50:57,989] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:50:57,989] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:50:57,989] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:50:58,019] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:50:58,035] {standard_task_runner.py:52} INFO - Started process 56763 to run task
[2022-06-18 14:50:58,042] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '79', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpcbyzethr', '--error-file', '/tmp/tmp87p0lzwz']
[2022-06-18 14:50:58,043] {standard_task_runner.py:80} INFO - Job 79: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 14:50:58,166] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:50:58,326] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:50:58,355] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:50:58,371] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 14:50:58,374] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 14:50:58,416] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T175057, end_date=20220618T175058
[2022-06-18 14:50:58,499] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:50:58,606] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 14:53:12,641] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:53:12,661] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 14:53:12,661] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:53:12,661] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 14:53:12,661] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 14:53:12,683] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 14:53:12,694] {standard_task_runner.py:52} INFO - Started process 58650 to run task
[2022-06-18 14:53:12,699] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '89', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmppfk8g_7u', '--error-file', '/tmp/tmpw_xlpfjv']
[2022-06-18 14:53:12,700] {standard_task_runner.py:80} INFO - Job 89: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 14:53:12,796] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 14:53:12,950] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 14:53:12,974] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 14:53:12,981] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 14:53:12,982] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 14:53:13,006] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T175312, end_date=20220618T175313
[2022-06-18 14:53:13,073] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 14:53:13,178] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 15:01:47,117] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:01:47,153] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:01:47,154] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:01:47,154] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 15:01:47,154] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:01:47,182] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 15:01:47,194] {standard_task_runner.py:52} INFO - Started process 62120 to run task
[2022-06-18 15:01:47,200] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '106', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp6kqxsoem', '--error-file', '/tmp/tmpo8h16a88']
[2022-06-18 15:01:47,201] {standard_task_runner.py:80} INFO - Job 106: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 15:01:47,300] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 15:01:47,454] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 15:01:47,479] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 15:01:47,491] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 15:01:47,493] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 15:01:47,521] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T180147, end_date=20220618T180147
[2022-06-18 15:01:47,613] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 15:01:47,728] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 15:06:29,731] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:06:29,757] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:06:29,757] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:06:29,757] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 15:06:29,758] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:06:29,785] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 15:06:29,798] {standard_task_runner.py:52} INFO - Started process 65028 to run task
[2022-06-18 15:06:29,804] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '125', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmplxxsfugl', '--error-file', '/tmp/tmpz6ly_05z']
[2022-06-18 15:06:29,805] {standard_task_runner.py:80} INFO - Job 125: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 15:06:29,925] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 15:06:30,173] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 15:06:30,227] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 15:06:30,238] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 15:06:30,251] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 15:06:30,297] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T180629, end_date=20220618T180630
[2022-06-18 15:06:30,382] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 15:06:30,582] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 15:08:08,889] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:08:08,916] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:08:08,916] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:08:08,916] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 15:08:08,916] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:08:08,942] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 15:08:08,954] {standard_task_runner.py:52} INFO - Started process 67078 to run task
[2022-06-18 15:08:08,961] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '142', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmpodwmyn92', '--error-file', '/tmp/tmpcun8pqma']
[2022-06-18 15:08:08,961] {standard_task_runner.py:80} INFO - Job 142: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 15:08:09,059] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 15:08:09,207] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 15:08:09,230] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 15:08:09,237] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 15:08:09,238] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 15:08:09,288] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T180808, end_date=20220618T180809
[2022-06-18 15:08:09,334] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 15:08:09,423] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 15:27:08,728] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:27:08,755] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:27:08,755] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:27:08,756] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 15:27:08,756] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:27:08,789] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 15:27:08,803] {standard_task_runner.py:52} INFO - Started process 75616 to run task
[2022-06-18 15:27:08,834] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '158', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp2vuyef9e', '--error-file', '/tmp/tmph1b23iwj']
[2022-06-18 15:27:08,835] {standard_task_runner.py:80} INFO - Job 158: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 15:27:08,963] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 15:27:09,153] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 15:27:09,195] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 15:27:09,204] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 15:27:09,214] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 15:27:09,256] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T182708, end_date=20220618T182709
[2022-06-18 15:27:09,354] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 15:27:09,720] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-18 15:29:49,253] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:29:49,283] {taskinstance.py:1160} INFO - Dependencies all met for <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [queued]>
[2022-06-18 15:29:49,283] {taskinstance.py:1357} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:29:49,283] {taskinstance.py:1358} INFO - Starting attempt 1 of 1
[2022-06-18 15:29:49,283] {taskinstance.py:1359} INFO - 
--------------------------------------------------------------------------------
[2022-06-18 15:29:49,314] {taskinstance.py:1378} INFO - Executing <Task(PostgresOperator): create_tables_stages.criar_Stage_Time> on 2022-06-17 00:00:00+00:00
[2022-06-18 15:29:49,330] {standard_task_runner.py:52} INFO - Started process 79045 to run task
[2022-06-18 15:29:49,337] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'sales', 'create_tables_stages.criar_Stage_Time', 'scheduled__2022-06-17T00:00:00+00:00', '--job-id', '177', '--raw', '--subdir', 'DAGS_FOLDER/sales.py', '--cfg-path', '/tmp/tmp7xzj_wwq', '--error-file', '/tmp/tmpykjj3nvg']
[2022-06-18 15:29:49,338] {standard_task_runner.py:80} INFO - Job 177: Subtask create_tables_stages.criar_Stage_Time
[2022-06-18 15:29:49,470] {task_command.py:370} INFO - Running <TaskInstance: sales.create_tables_stages.criar_Stage_Time scheduled__2022-06-17T00:00:00+00:00 [running]> on host uiliam-Vostro-15-3515
[2022-06-18 15:29:49,674] {taskinstance.py:1570} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=sales
AIRFLOW_CTX_TASK_ID=create_tables_stages.criar_Stage_Time
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-17T00:00:00+00:00
[2022-06-18 15:29:49,699] {base.py:68} INFO - Using connection ID '***' for task execution.
[2022-06-18 15:29:49,707] {dbapi.py:213} INFO - Running statement: 
                CREATE TABLE IF NOT EXISTS stg_time (
                orderdate date,
                requireddate date,
                shippeddate date
                    )
            , parameters: None
[2022-06-18 15:29:49,713] {postgres.py:94} INFO - NOTICE:  relation "stg_time" already exists, skipping

[2022-06-18 15:29:49,744] {taskinstance.py:1396} INFO - Marking task as SUCCESS. dag_id=sales, task_id=create_tables_stages.criar_Stage_Time, execution_date=20220617T000000, start_date=20220618T182949, end_date=20220618T182949
[2022-06-18 15:29:49,831] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-06-18 15:29:49,932] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
